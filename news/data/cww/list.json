{
    "data": [
        {
            "title": "阿里吴泳铭：AGI只是起点，超级人工智能ASI才是终极目标",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">9月24日，在杭州召开的云栖大会上，阿里巴巴集团CEO、阿里云智能集团董事长兼CEO吴泳铭发表主旨演讲，他认为实现通用人工智能AGI已是确定性事件，但这只是起点，终极目标是发展出能自我迭代、全面超越人类的超级人工智能ASI。</span></p><p style=\"text-align:center\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250924/1758705024740081842.png\" title=\"1758705024740081842.png\"/></p><p style=\"text-indent:2em;\">吴泳铭首次系统阐述了通往ASI的三阶段演进路线：</p><p style=\"text-indent:2em;\">第一阶段：“智能涌现”，AI通过学习海量人类知识具备泛化智能。</p><p style=\"text-indent:2em;\">第二阶段：“自主行动”，AI掌握工具使用和编程能力以“辅助人”，这是行业当前所处的阶段。</p><p style=\"text-indent:2em;\">第三阶段：“自我迭代”，AI通过连接物理世界并实现自学习，最终实现“超越人”。</p><p style=\"text-indent:2em;\">为实现这一目标，吴泳铭明确了阿里云的战略路径。阿里云作为“全栈人工智能服务商”，将通过两大核心路径实施AI战略：第一，通义千问坚定开源开放路线，致力于打造“AI时代的Android”；其二，构建作为“下一代计算机”的超级AI云，为全球提供智能算力网络。</p><p style=\"text-indent:2em;\">为支撑这一宏大愿景，吴泳铭表示，阿里巴巴正在积极推进三年3800亿的AI基础设施建设计划，并将会持续追加更大的投入。根据远期规划，为了迎接ASI时代的到来，对比2022年这个GenAI的元年，2032年阿里云全球数据中心的能耗规模将提升10倍。</p></div>",
            "pub_date": "2025-10-31 08:40:34",
            "link": "http://www.cww.net.cn/article?id=604140",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "中兴通讯超边AI智能体方案，让智能发生在最需要的地方",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">工业智能化浪潮下，传统产线改造面临效率与成本无法兼顾的全新挑战，传统方案部署周期长、定制成本高、改造停工与运维负担成痛点。中兴通讯首家推出基于AI推理的超边AI智能体方案及超边AI智能体ZXCTN 810C，一台设备即可完成AI推理、数据传输等功能，设备即插即用，无缝适配园区机柜，破解边缘智能“部署难、成本高”的困局。该方案在中兴河源工厂实际部署表明，功耗比传统方案降低60%，质检准确率提升75%，运营成本降低近30%。除了工业质检，该创新方案还可运用于安防、交通、矿山、环境监测等行业场景，通过整合现有设备与系统资源，内置AI算力助力客户将刚性生产变柔性智造，抛弃重资产实现轻运营，为千行百业提供最佳智能支持。</span></p><p style=\"text-indent: 2em; text-align: center;\"><video class=\"edui-upload-video video-js vjs-default-skin video-js\" controls=\"\" height=\"280\" preload=\"none\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/video/20251011/1760173957193066550.mp4\" width=\"420\"><source src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/video/20251011/1760173957193066550.mp4\" type=\"video/mp4\"/></video></p></div>",
            "pub_date": "2025-10-31 08:40:33",
            "link": "http://www.cww.net.cn/article?id=604457",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "大推理时代新型智算推理集群建设的思考与实践",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<strong style=\"text-indent: 2em; visibility: visible;\">人工智能的高速发展持续推高算力需求，DeepSeek等</strong>大模型的轻量化和低成本部署模式进一步激发了边缘推理应用爆发，加速了“大推理”时代的到来。新时代智能推理集群的发展仍面临新型算力架构技术和产业尚不成熟、端到端软硬协同优化能力存在短板、智算生态多而不优且互不兼容等问题。中国移动在新型智算推理集群建设方面已取得系列进展，建议产业各方进一步完善智能算力资源布局，持续加大核心技术攻关，深化产业合作和创新应用探索，共同推动我国新型智算技术和产业发展成熟。</p><p style=\"text-indent:2em;\"><strong>DeepSeek引爆大推理时代</strong></p><p style=\"text-indent:2em;\">近年来，全球人工智能高速发展，国内外高科技企业纷纷构建万卡甚至十万卡智算中心，发布千亿甚至万亿规模参数大模型，通过“大模型+大算力+大数据”的堆叠，不断探索模型能力上限，“百模大战”如火如荼，整个人工智能产业聚焦“大训练”，多模态、长上下文等各种模型能力的竞争进入白热化。</p><p style=\"text-indent:2em;\">今年2月，我国自主研发的大模型DeepSeek火爆全球，多项指标性能追平甚至超越国外先进大模型，在美西方国家对我国人工智能产业链全方位制约的背景下，成功走出了一条低成本、高性能的“突围之路”,甚至被认为是人工智能领域的最大“黑马”和“国运级别的产品”。DeepSeek通过“算法模型创新+算网设施优化+开源开放战略”的组合拳，在提升底层算网资源的使用效率的同时，大幅降低了大模型对算网资源的需求，推动了AI平权，加速了智能体、智能机器人等AI应用的普惠化发展。未来三年，中国智能算力规模总量将增长2.5倍，年均复合增速近40%，而推理算力的年增速将是训练算力的近4倍，预计2028年推理类算力规模将首次反超训练算力，一个崭新的“大推理”时代已经到来。</p><p style=\"text-indent:2em;\">大推理时代智能算力将呈现出新的发展趋势：一是算力性能走向极致，大模型的发展持续推高算力需求，催生超节点等超高密度、超高算效的新型算力架构；二是智算格局发生变化，智能算力加速从集中走向分布，高性能推理集群、一体机等多样化推理算力形态不断涌现；三是垂直优化成为关键，DeepSeek开创了软硬件联合优化的模型发展新途径，驱动算网基础设施、模型和算法的更深层次协同和联合优化。</p><p style=\"text-indent:2em;\"><strong style=\"text-align: center; text-indent: 2em;\">大推理时代新型推理集群建设面临的问题和挑战</strong></p><p style=\"text-indent:2em;\"><strong>超节点类新型算力架构在技术和产业上尚不成熟</strong></p><p style=\"text-indent:2em;\">随着稀疏MoE架构大模型逐渐成为主流，GPU卡间存在大量TP、EP等高频次、大带宽、低延时通信需求，较大的scale-up域对于提升模型训推性能至关重要。当前传统单机8卡智算服务器Scale-up域局限在8张GPU卡之间，且单机显存容量带宽和容量存在天花板效应，不利于大模型的运行效率和集群算能算效的提升。因此，产业界正在积极开展超节点服务器的研究，通过建立高带宽低延迟的卡间互联网络，扩大高带宽域规模，降低通信时间占比，提高推理时延性能。NVIDIA推出NVL72等超节点，华为推出CloudMatrix384超节点产品，国内其他服务器厂商的也都发布了初代超节点产品。但是目前业内超节点产品都面临诸多问题，首先是技术成熟度和开放度不足，相比于已经迭代数年的传统单机8卡智算服务器，其复杂度大大增加，尤其是卡间互联多为单厂商封闭性技术，开放度不足，且相关产品可靠性未经过大规模商用验证；其次，业内厂商发布的超节点多为初代产品，其研发成本高、定制化程度强，造成目前超节点产品价格高昂；最后，超节点产品单机柜的最大功耗可达百千瓦级别，普遍采用冷板液冷设计，与数据机房的配套耦合性较高，传统数据机房往往难以满足其部署需求，改造成本较高。</p><p style=\"text-indent:2em;\"><strong>端到端软硬协同优化能力存在短板</strong></p><p style=\"text-indent:2em;\">模型推理关注性能与成本两大关键指标，推理性能影响到服务响应速度和用户体验，推理成本则决定了推理应用的规模化落地速度。高性能、低成本的推理一方面依赖于具备超强算力的智算硬件，另一方面更依赖于智算基础软件极致压榨硬件潜能。当前，尽管国产硬件在算力密度、能效比等指标上已取得突破，但在端到端软硬协同优化能力上还存在网络通信存在瓶颈、推理引擎性能不高、编译器运行时优化能力不强、高性能计算库缺失等系列问题，导致硬件与软件之间无法实现高效协同，严重制约了硬件性能的释放，使得推理性能难以达到理想水平，成为阻碍人工智能应用大规模落地与高质量发展的关键瓶颈。</p><p style=\"text-indent:2em;\">我国智算生态多而不优、互不兼容</p><p style=\"text-indent:2em;\">当前我国智算厂商围绕各自硬件纷纷构建包含编译器、算子库、训推框架等在内的基础软件系统，各自为栈、互不兼容，形成一个个碎片化的生态竖井。一方面，国产智算厂商依赖功能类似的基础软件系统将模型和应用锁定至各自生态竖井之上，致使模型与应用难以跨架构迁移部署，形成一个个“算力孤岛”，谁都无法发展壮大。另一方面，众多国产基础软件与CUDA差距显著，存在算子覆盖不全、编程模型不完备等问题，开发者基于国产硬件构建模型及应用或将其由CUDA向国产化体系迁移需重构代码，开发工作量大、时间长、成本高，进一步降低模型及应用向国产化生态迁移意愿，导致国产智算易陷入“差而不用、不用更差”的怪圈，良性生态难以构建。</p><p style=\"text-indent:2em;\"><strong>中国移动在推理集群建设方面的实践和进展</strong></p><p style=\"text-indent:2em;\">为应对AI工作负载对互联架构提出的独特挑战，中国移动与产业界启动开放的全向智感互联标准（Omni-directional Intelligent Sensing Express Architecture，OISA）的协议制定工作，核心设计哲学可精炼地概括为一种先“减”后“加”的双重策略。其“减法”在于系统性地剥离传统网络协议栈中为通用性而设计的冗余部分，例如动态路由、MAC学习等复杂机制。这些机制在AI集群的确定性流量模型下不仅毫无必要，反而会引入额外的延迟和硬件复杂度。通过此番精简，OISA构建了一个极致轻量化的协议基础。在此基础上，OISA继而施行其“加法”策略，即在精简后的协议栈上，有针对性地集成专为AI工作负载设计的硬件加速引擎和高级运维特性，从而实现对性能的深度优化，最终打造出一个既简约又强大的专用互联解决方案。</p><p style=\"text-indent:2em;\">体系化推进推理资源布局建设</p><p style=\"text-indent:2em;\">中国移动积极落实AI+发展战略，匹配市场发展节凑，统筹考虑资源覆盖和效益效率，提前开展推理资源规划布局。基于推理业务特征，推理资源部署采用“低成本区域+热点区域”相结合原则，按照“N+31+X”的目标架构布局：N节点为集中化全国节点，在西部低成本中心集中化部署，承载海量高并发推理业务；31节点为分布式省级节点，在省级节点属地部署，承载中型企业的中心推理需求；X节点为分布式边缘节点，承载中小企业本地推理需求。最终目标是建成“中心集约、边缘泛在、覆盖全网”的体系化推理资源，满足公司内外部推理资源需求。</p><p style=\"text-indent:2em;\">构建新型智算推理软硬件全栈技术体系</p><p style=\"text-indent:2em;\">中国移动构建了包括算网资源层、基础软件层、推理平台层、MaaS平台层和应用层五层架构在内的新型智算推理技术体系（如图1），提出了包括全向智感互联OISA、全调度以太网GSE、算力原生等系列原创技术并推动成熟。</p><p style=\"text-align:center\"><img alt=\"图片\" class=\"rich_pages wxw-img\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/20251009/1759972339365028593.png\"/></p><p style=\"text-indent:2em;\">图1 中国移动新型智算推理技术体系</p><p style=\"text-indent:2em;\">算网资源层，为推理服务提供计算、存储和网络等算力能力底座，采用云化架构，提供资源编排调度和运维管理功能，实现资源虚拟化和算力池化能力。在卡间互联方面，中国移动原创提出全向智感互联OISA协议体系，定义物理层、数据层、事务层标准，统一报文格式、多语义融合、多层次流控重传等关键技术，实现超节点内多GPU芯片的对等全互联, 目前已联合50余家上下游合作伙伴成立协同创新平台，发布OISA 2.0协议版本。在高性能存储方面，制定高性能融合存储创新系统架构，支持多协议融合互通、TB/s级高吞吐性能和热冷素具自动分级能力，提升智算数据处理效率。在机间网络方面，原创提出全调度以太网GSE技术，通过创新报文容器级负载均衡提升网络吞吐，动态全局调度队列（DGSQ）授权机制避免多打一拥塞、微秒级故障无损收敛提升网络可靠性等机制提升网络性能。</p><p style=\"text-indent:2em;\">基础软件层，提供推理芯片配套的基础软件栈和高性能计算及通信算子库，实现对推理芯片算力的调用。提供RAG数据库和高性能数据库，解决大模型推理的时效性问题。中国移动原创提出算力原生技术，并打造了“芯合”异构超融合基础软件栈，实现多样算力一体适配，应用一次开发，跨芯部署迁移，破解智算应用跨架构迁移优化难题。目前，“芯合”软件栈已支持泛AI应用在8家厂商芯片上随需开发和跨架构迁移，迁移时间小于20秒。</p><p style=\"text-indent:2em;\">推理平台层，提供模型预处理和推理引擎等功能。模型预处理通过模型压缩、算子融合等优化技术将模型配置成满足业务部署要求的模型。推理引擎是推理性能优化的载体，其将训练好的模型引入实际应用阶段，实现推理任务调度和性能优化，增加推理集群的资源利用率，降低推理成本，提升大模型推理的用户体验。中国移动打造“芯合”跨架构推理引擎，通过统一的算子库、通信库和运行时抽象，实现推理引擎与多模型和多后端的适配和推理优化。当前，推理引擎已实现Deepseek R1可从英伟达平台迁移至华为硬件上，推理吞吐量提升1.2倍，首字延迟降低48%。</p><p style=\"text-indent:2em;\">MaaS平台层和应用层，汇聚模型、能力、智能体等资源，一方面提供以AI为核心的研发、运营、测试等全环节工具链和开发环境，显著提升AI开发创新效率；另一方面提供AI一站式落地的模型服务和覆盖多样化场景的AI应用服务。</p><p style=\"text-indent:2em;\">牵引推动我国多元化智算生态繁荣发展</p><p style=\"text-indent:2em;\">中国移动充分发挥链长作用，积极推动国产推理芯片生态建设。为加快国产推理芯片落地应用，中国移动建立了国产推理芯片评估评测平台，对多家国产推理芯片开展了评估评测，推动了国产推理芯片技术成熟，同时引入了至少4家国产推理芯片。为加快推动异构芯片训推迁移适配和异构芯片混推，中国移动自研了芯合跨架构推理引擎，可预先适配异构硬件后端，向上保证模型一次适配、灵活异构部署，实现国产大模型在国产推理芯片上的应用。</p><p style=\"text-indent:2em;\">新型智算推理集群发展建议</p><p style=\"text-indent:2em;\">为充分把握大推理时代的智能算力发展的新机遇，推动我国新型智算推理集群的高质量发展，提出以下三方面发展建议。第一，加快完善智能算力资源布局，构建“中心集约、边缘泛在、中训边推、训推一体”的全国一体化智算供给体系。第二，持续加大智能算力核心技术攻关，打造自主可控的新型智算技术“中国方案”。第三，深化产业合作，开拓我国智算生态健康发展的新格局。</p><p style=\"text-indent:2em;\"><br/></p></div>",
            "pub_date": "2025-10-31 08:35:31",
            "link": "http://www.cww.net.cn/article?id=604400",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "国内首个标准大模型“同道”升级，标准化工作迈入智能化新时代",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">在数字浪潮席卷全球的今天，人工智能正以前所未有的深度与广度重塑各行各业的发展格局。10月14日，国内首个标准大模型——“同道”重磅升级，互联网版正式上线，推动我国标准化事业迈入AI驱动的新阶段。</span></p><p style=\"text-indent:2em;\"><strong>精准发力，“同道”根除行业顽疾</strong></p><p style=\"text-indent:2em;\">长期以来，标准化工作至关重要，却却始终面临“检索难、撰写慢、应用弱”的现实困境。面对海量标准文本，标准化工作者常如大海捞针，难以精准定位所需信息；标准编制语言规范性要求高，人工撰写易出疏漏；而在标准实施环节，解读不到位、应用不深入等问题也屡见不鲜。这些“疑难杂症”，如同无形的壁垒，制约着标准化价值的充分释放。</p><p style=\"text-indent:2em;\">在这一背景下，“同道”应运而生。作为落实工业和信息化部《2025年工业和信息化标准工作要点》中“探索推进‘人工智能+标准化’”战略部署的关键举措，中国电子技术标准化研究院依托多年积累的海量标准数据资源，开展核心技术攻关，成功研发出这款专为标准化领域打造的大模型产品。它不仅是技术的突破，更是对传统工作模式的系统性重构。</p><p style=\"text-indent:2em;\">“同道”之名，取自“车同轨、书同文”，亦有“志同道合”之意。在这个万物互联、智能驱动的时代，标准的力量从未如此重要，而“同道”的出现，正为这份力量注入新的动能。</p><p style=\"text-indent:2em;\"><strong>技术驱动，打造标准全周期智能服务</strong></p><p style=\"text-indent:2em;\">据中国电子技术标准化研究院相关负责人介绍，“同道”标准大模型互联网版，以“同道问答—同道编写—同道解读—同道认证”四大核心功能为支柱，构建起覆盖标准全生命周期的智能化服务体系，真正实现了从“人找标准”到“标准找人”、“经验驱动”到“智能驱动”的跃迁。</p><p style=\"text-indent:2em;\">【同道问答】如同一位随时在线的行业专家，凭借其强大的知识库和智能分析能力，能够迅速响应、精准解答。只需描述问题，即可获得专业、权威的回复，极大提升了信息获取的效率与准确性。</p><p style=\"text-indent:2em;\">【同道编写】展现出强大的创造力与规范性保障能力。它不仅能根据用户需求智能生成标准草案初稿，大幅缩短前期准备时间；更能对文本进行智能润色与内容扩展，在确保语言严谨、格式规范的同时，使技术条款更加详实、逻辑更加严密。过去需要数日甚至数周的人工撰写任务，如今在AI的辅助下，可在短时间内高效完成，让标准工作者从重复性劳动中解放出来，专注于更具创造性的核心工作。</p><p style=\"text-indent:2em;\">标准的价值在于应用，而应用的前提是理解。【同道解读】提供了深度解析服务。它不仅能从政策背景、利益相关方、技术要点等多个维度进行剖析，还能结合实际场景提出切实可行的应用建议，并智能推荐相关标准文件，形成知识网络，助力用户真正“读懂标准、用好标准”。</p><p style=\"text-indent:2em;\">【同道认证】在标准落地的关键环节提供了强有力的智能支撑。该功能兼容多种认证模板，可对认证企业提交的文件进行快速解析、匹配与核查，智能判断其是否符合认证标准要求，并给出风险提示与处置建议。这一能力不仅提升了认证工作的效率与一致性，更能助推企业快速践行先进标准。</p><p style=\"text-indent:2em;\"><strong>开放协同，拓宽标准应用新场景</strong></p><p style=\"text-indent:2em;\">此次上线的“同道”标准大模型互联网版，最大亮点在于其开放性与便捷性。“同道”不仅支持不同格式文件的多模态交互，更做到了使用全程无需下载安装，用户可通过网页端、移动端等多种渠道即点即用，真正实现了“随时随地，触手可及”的标准化服务体验。</p><p style=\"text-indent:2em;\">展望未来，中国电子技术标准化研究院表示，将以“深化能力、拓展边界、共建生态”为发展主线，持续推动“同道”标准大模型的迭代升级，通过数据共享、能力互补、场景共创，让AI真正成为连接标准与产业、技术、应用的桥梁。</p><p style=\"text-indent:2em;\"><br/></p></div>",
            "pub_date": "2025-10-31 08:35:30",
            "link": "http://www.cww.net.cn/article?id=604576",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "马斯克：Grok 5模型有望实现通用人工智能的突破",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">据媒体报道，特斯拉与SpaceX首席执行官埃隆·马斯克在社交平台X上表示，其旗下人工智能公司xAI正在研发的Grok 5模型有望实现通用人工智能（AGI）的重大突破。</span></p><p style=\"text-indent:2em;\">这一看法显著区别于他以往的态度。马斯克坦言，此前自己从未将Grok系列与AGI直接联系起来。</p><p style=\"text-indent:2em;\">据他透露，Grok 5模型的训练预计将在未来几周内启动。作为xAI的旗舰产品，Grok系列一直以其实时信息处理能力受到关注，而此次更新版本更被寄予厚望。</p><p style=\"text-indent:2em;\">行业分析认为，若Grok 5能够实现AGI，将代表人工智能实现从专用领域向通用认知能力的质的飞跃。</p><p style=\"text-indent:2em;\">尽管目前Grok 5的具体技术细节尚未公开，但马斯克强调该模型将采用全新的架构设计。与现有AI系统相比，AGI具有理解、学习并跨领域应用知识的能力，被广泛视为人工智能发展的终极目标。科技界正在密切关注xAI能否在竞争日益激烈的大模型赛道中实现突破。</p><p style=\"text-indent:2em;\"><br/></p></div>",
            "pub_date": "2025-10-31 08:30:47",
            "link": "http://www.cww.net.cn/article?id=603965",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "中兴通讯Co-Sight2.0登顶GAIA开源智能体排行榜",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">在被誉为“AI界GitHub”的Hugging Face平台上发布的 GAIA 评测基准最新榜单中，中兴通讯开源的“Co-Sight超级智能体2.0”再次已以84.39%的综合成绩位列全球第一，成为拿下该榜榜首的中国超级智能体。GAIA榜单由Meta、Hugging Face与AutoGPT联合发布，采用封闭测试集与自动评分机制，结果可复现、可审计，已被多家顶尖机构与国际会议广泛引用，是评估通用AI智能体综合能力的权威基准。</span></p><p style=\"text-align:center\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250928/1759025636634044308.png\" title=\"1759025636634044308.png\"/></p><p style=\"text-indent:2em;\">中兴通讯“Co-Sight超级智能体2.0”具备多项核心能力，旨在为企业提供高效、安全、易部署的智能体解决方案。其数字团队协同能力采用多智能体协同架构，通过DAG任务引擎调度“数字员工”，显著提升复杂任务的自动化处理水平。在自我进化方面，该系统构建了闭环机制，通过执行结果自我复盘持续优化任务规划，并能够自动生成代码、调用工具，基于执行轨迹实现工具的自主迭代演进。为满足金融、运营商等高安全要求场景，Co-Sight2.0提供了企业级安全可信保障，所有工具执行操作均在沙箱环境中完成，并支持完善的日志追溯、权限管控、合规审计及多来源交叉校验功能。此外，该平台支持一键部署，已在GitHub及焕新社区同步开源，提供包括完整API、预训练模型及Docker镜像，支持快速在本地或云端启动“数字团队”。</p><p style=\"text-indent:2em;\">Co-Sight超级智能体2.0相比1.0版本，实现了三大关键升级：全链路可信计算框架，在工作流中内置端到端的可信保障机制，显著提升大语言模型（LLM）处理信息的信噪比，从源头确保输出结果的精准性、一致性和可追溯性。涌现式能力进化引擎，能动态合成、优化工具，并将成功经验沉淀为可复用策略知识库，驱动智能体能力持续自我进化与完善。中兴通讯率先开源了业界首个开放式三层交互协议，通过标准化人机协同、多智能体协作及知识共享的接口规范，为构建开放、互操作的智能体生态奠定了关键基础。</p><p style=\"text-indent:2em;\">当前Co-Sight超级智能体已在焕新社区和国际主流社区同步开源，可以进行下载使用。</p></div>",
            "pub_date": "2025-10-31 08:30:47",
            "link": "http://www.cww.net.cn/article?id=604267",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "信通院：2024年我国人工智能产业规模超9000亿元",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">当前，我国人工智能产业蓬勃发展，正处于规模化应用落地的关键阶段。模型能力持续提升、产品形态不断丰富、应用范围逐步拓展，加快推动人工智能从技术“实验”走向行业“实践”。系统性开展人工智能产业监测，量化分析产业规模，对科学有序推动我国人工智能产业高质量发展具有重要意义，是一项重要的基础性工作。</span></p><p style=\"text-indent:2em;\">在9月23日召开的2025人工智能产业及赋能新型工业化大会上，中国信息通信研究院（简称“中国信通院”）副总工程师王爱华发布我国人工智能产业规模测算成果。经测算，2024年我国人工智能产业规模已超9000亿元，同比增长24%。截至2025年9月，人工智能企业数量超5300家，全球占比达到15%，形成覆盖基础底座、模型框架、行业应用的完整产业体系。</p><p style=\"text-indent:2em;\">人工智能产业具有边界范围广、产品演化快，与传统行业加速融合的特点。中国信通院成立专项研究团队，联合产学研各界协同攻关，组织多轮研讨论证，推动相关标准研制，在充分吸收借鉴现有产业统计和规模测算方法的基础上，提出人工智能产业规模测算方法体系。</p><p style=\"text-indent:2em;\">据了解，该测算方法坚持标准引领，基于公开可获取数据、一手调研数据，聚焦人工智能代表企业、重点产品，通过“定边界”“筛企业”“算系数”“测规模”四步，实现我国人工智能全产业链和分区域产业规模测算。</p><p style=\"text-indent:2em;\"><br/></p></div>",
            "pub_date": "2025-10-31 08:25:40",
            "link": "http://www.cww.net.cn/article?id=604320",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "信通院张蔚敏：大模型时代的具身智能：智机融合价值、现状与挑战",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">随着“具身智能”“智能机器人”于2025年首次写入政府工作报告，具身智能、智能机器人、人形机器人等诸多新概念、新名词越来越多地出现在大众面前。这些看起来晦涩难懂的科技热词，或许很快就将走入商业场景，甚至我们的家庭。它们的定义是什么，相互之间有怎样的关联，未来发展前景如何？中国信息通信研究院（简称“中国信通院”）《专家谈》栏目开辟“机器人”系列专题，邀请多位业界资深专家多视角探讨我国人工智能+机器人的发展形势。本期邀请到中国信通院人工智能研究所安全与具身智能部副主任张蔚敏，围绕如何理解具身智能、具身智能赋能新型工业化的核心价值、具身智能的智能水平所处阶段以及在迈向大规模应用中的技术瓶颈和破解路径等展开深度解读。</span></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">一、如何理解具身智能？</strong></p><p style=\"text-indent:2em;\">具身智能是一种智能理论和范式，强调智能行为依赖于身体和环境的互动，具有鲜明的身体性和情境性。而机器人则是这一理论在工程实践中的载体和试验田。智能机器人和人形机器人都是具身智能的分支。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">二、具身智能如何重塑制造业核心环节？</strong></p><p style=\"text-indent:2em;\">先前，机器人已经借助人工智能技术逐渐摆脱固定机械操作的束缚，提升了自动化作业能力。但主要适用于结构化、确定性的场景，在面对复杂、变化多的生产环境时，柔性不足、适应性差的问题依然突出。具身智能的发展，让机器人等物理实体能够自主感知、计划和执行任务，具备了多功能、多任务的灵活作业能力。可以说，具身智能为解决工业生产中“柔性不足、频繁换线”两大难题，提供了新的解决方案，也契合我国制造业小批量、多品种的新制造形态发展需求。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">三、具身智能的智能水平处于什么阶段？</strong></p><p style=\"text-indent:2em;\">智能水平主要由模型能力决定。<strong style=\"box-sizing: border-box;\">端到端视觉语言动作模型（VLA）是作为大家重点探索的方向，还处于“幼儿园”阶段。</strong>拆解来看VLA的三个重要能力，<strong style=\"box-sizing: border-box;\">一是</strong>用视觉看世界的能力，仅能识别有什么物品，但无法理解何处施力，施多大的力。<strong style=\"box-sizing: border-box;\">二是</strong>用语言和人类沟通的能力，更支持明确、具体、结构化的任务指令，例如能理解“拿起一个苹果”，但很难理解“给我一个水果”。<strong style=\"box-sizing: border-box;\">三是</strong>用动作执行任务的能力，现在会做的是移动、抓取和放置等简单技能的组合，且操作对象以刚性物品为主。<strong style=\"box-sizing: border-box;\">本体性能、网络通信等决定了智能在实际任务表现的上限。</strong><strong style=\"box-sizing: border-box;\">一方面，</strong>本体技术还需进一步收敛。以人形机器人为例，目前的技术成熟度还处于早期，完赛率30%的人形机器人马拉松暴露出了电机发热、关节可靠性、本体结构稳定性等硬件限制。<strong style=\"box-sizing: border-box;\">另一方面，</strong>从执行固定程序到自适应场景执行任务，需要综合机器人的算力、网络、成本、能耗等各因素。构建分布式、可泛化具身智能，需要均衡硬件、网络、算力三要素供给代价，才能有望破茧工业线，进入百姓家。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">四、具身智能机器人在迈向大规模应用时，面临的技术瓶颈是什么？</strong></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">一是模型Scalability面临不确定性。</strong>目前还没有足够证据能证明，扩展数据对提升模型的泛化性绝对有用。而且，要让模型具备泛化性，又足够可靠，是系统性工程，涉及数据、训练方法、模型架构等。<strong style=\"box-sizing: border-box;\">二是实际可用的动作数据还远远不够。</strong>现有具身智能数据集无论是开源的、合成的还是真机采集的，都很难规模化使用。数据和本体强绑定、和生产环境强相关，存在严重的数据孤岛现象。在一个数据集上训练好的模型部署到不同的本体型号时，性能表现会大打折扣，即使同一型号本体，在不同实验室或搭建环境下的性能表现也完全不同。<strong style=\"box-sizing: border-box;\">三是要解决全身运动控制问题。</strong>全身关节的协同控制需要在几十毫秒内完成高维动作空间的复杂计算，对关节电机控制性能、运动控制模型的精度和实时性都有较高的要求。另外目前在处理需要精确力控、丰富接触的操作任务时，如整理线束、塑料袋打包等，仍有较大挑战。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">五、如何破解具身智能产业化问题？</strong></p><p style=\"text-indent:2em;\">具身智能的发展特别是人形机器人更需要对其进行有耐心的长期投入和关键布局，建议：</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">一是注重多学科交叉研究，</strong>包括计算机科学、控制科学、认知科学、机器人学等。<strong style=\"box-sizing: border-box;\">只有加强多学科之间的交流与合作、整合各学科的优势资源，才能共同攻克具身智能领域的关键科学问题和技术难题。</strong>中国人工智能产业发展联盟（AIIA）已成立具身智能工作组，以搭建各方合作交流平台为目标，围绕评估规范、产业生态建设、应用推广供需对接、以赛促用等工作任务，推动具身智能产业生态各方协作，加速我国具身智能产业化进程。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">二是重视标准研制和评估反馈机制明确智能能力升级方向。</strong>通过科学、高效、准确的标准化研究，可以有效推动产业技术升级和规模应用。MIIT TC1（工业和信息化部全智能标准化技术委员会） WG6具身智能工作组，从系统研发支撑、系统智能技术、系统集成和系统应用四方面统筹推进国内具身智能产业标准体系建设工作，围绕具身智能智能化分级、数据集质量、接口、训练场、基准测试和重点产品如人形机器人等体系化推进标准化工作。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">三是与产业链上下游协同。</strong><strong style=\"box-sizing: border-box;\">一是</strong>推动实现“数据—模型—本体”的闭环，通过本体沉淀数据，驱动模型迭代升级，进一步强化本体性能跃迁。<strong style=\"box-sizing: border-box;\">二是</strong>形成“需求牵引—应用验证—反馈迭代”的闭环，面向制造、物流、医疗、家庭等重点行业半结构化场景，推动具身智能试点示范。<strong style=\"box-sizing: border-box;\">三是</strong>加深生态协作机制，构建“基础设施—技术服务—产品服务—行业应用”闭环，通过行业联盟、标准化组织等，建立产业链协作机制，推动技术、标准、应用的同步演进。</p><p style=\"text-indent:2em;\"><br/></p></div>",
            "pub_date": "2025-10-31 08:25:39",
            "link": "http://www.cww.net.cn/article?id=604340",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "信通院发布2025人工智能产业十大关键词",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）<span style=\"text-indent: 2em;\">2025年9月23日，2025人工智能产业及赋能新型工业化大会在北京国家会议中心召开。会上，中国信息通信研究院（简称“中国信通院”）正式发布“2025人工智能产业十大关键词”，中国信通院人工智能研究所所长魏凯针对十大关键词反映出的新热点、新趋势进行了深入解读。</span></p><p style=\"text-indent:2em;\">中国信通院自2022年起连续4年发布人工智能十大关键词，获得了产业界的广泛关注，成为追踪行业发展的重要窗口。2025年，立足产业视角，基于广泛专家调研和热点事件统计分析，结合团队研究洞察，梳理发布2025人工智能产业十大关键词。总体来看，2025年人工智能技术、应用、生态三维共振，智能原生的新世界越来越清晰地展现在我们眼前。</p><p style=\"text-align:center\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195540920033538.png\" title=\"1759195540920033538.png\"/></p><p style=\"text-indent:2em;\"><br/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box; font-size: 15px; visibility: visible;\">一、基础超级模型</strong></p><p style=\"text-indent: 2em; text-align: center;\"><strong style=\"box-sizing: border-box;\"><strong style=\"text-indent: 32px; text-wrap: wrap; box-sizing: border-box;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195558824078828.png\" title=\"1759195558824078828.png\"/></strong></strong></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">2025年，基础模型与推理模型双线并进，</strong>技术迭代速度与能力跃升幅度均超预期。根据中国信通院 “方升” 基础模型测试数据，2024年底至2025年8月，大模型综合能力提升超过30%。以GPT-5、Grok4、DeepSeek V3.1、Claude Opus 4.1、 Qwen3-235B-A22B为代表的<strong style=\"box-sizing: border-box;\">头部大模型表现出显著的集成特征</strong>：一是思考+非思考模式合一，根据用户提示词自主选择模型或推理模式；二是理解、推理、数学能力大幅提升；三是内置代码、工具调用等多种AGENT能力。集成多种关键能力的<strong style=\"box-sizing: border-box;\">基础超级模型已出现</strong>，不仅综合能力强，且在真实业务场景中的表现得到进一步强化。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195576469087190.png\" title=\"1759195576469087190.png\"/></p><p style=\"text-indent:2em;\">技术创新是驱动模型能力跃升的核心引擎，<strong style=\"box-sizing: border-box;\">基础超级模型有两个主要技术特点</strong>：一是通过路由融合集成多种关键能力。二是面向智能体的强化学习（Agentic RL）提升真实业务场景表现。<strong style=\"box-sizing: border-box;\">基础超级模型对用户产生三方面重要影响</strong>：一是模型的使用更便利，基础超级模型出现后，模型种类和数量收敛，GPT-5可以根据用户的指令动态选择合适的模型和处理模式，降低用户的使用门槛。二是自主决策工作流和外部工具调用，工作流和工具使用能力集成到基础超级模型内部后，极大程度上增强了工作流工具调用的精准度，使得应用效果更佳。三是对训练数据供应提出新要求，从AGENT应用中采集数据和从物理场景中采集数据成为新的迫切需求。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">二、自主性更强的智能体</strong></p><p style=\"text-indent: 2em; text-align: center;\"><strong style=\"box-sizing: border-box;font-size: 15px;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195595371007283.png\" title=\"1759195595371007283.png\"/></strong></p><p style=\"text-indent:2em;\">2025年，<strong style=\"box-sizing: border-box;\">高度封装的智能体产品通过融合基座模型、MCP服务、智能体沙箱等，进一步释放大模型应用潜能。</strong><strong style=\"box-sizing: border-box;\">一方面，智能体相比大模型可以自主完成复杂任务，但仍不及预期。</strong>中国信通院“方升”智能体基准测试对国内外通用智能体进行了4大类101个具体任务测试，结果显示当前智能体能够自主完成复杂任务，可以获得比单一模型更好的性能表现，但能力仍有很大提升空间。另一方面，智能体产品形态逐步清晰，在消费端和企业端深度赋能，智能体成为数字员工的初级形态。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195611903008027.png\" title=\"1759195611903008027.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">互联互通和长难任务处理仍是当前智能体技术创新的主旋律。一方面，</strong>通信协议成为智能体与外界交互的“桥梁”，加速实现互联互通。Anthropic公司发布的模型上下文协议（MCP）、谷歌式发布的Agent2Agent(A2A)全新开放协议，二者在应用过程中可实现互补协同。<strong style=\"box-sizing: border-box;\">另一方面，</strong>智能体发展还需要提升长时间执行复杂任务的能力。相关研究显示，过去两三年，智能体能完成任务的长度大约每7个月翻一番。未来，智能体将能独立完成大量需要人类数天或数周才能完成的任务，加速开启智能原生应用时代。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">三、走向实训的具身智能</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195634463055839.png\" title=\"1759195634463055839.png\"/></p><p style=\"text-indent:2em;\">具身智能正在加速走出实验室，走向竞技场和训练场，为真正进入场景实战迈出了坚实一步。<strong style=\"box-sizing: border-box;\">本体方面，加快推进在现实场景的部署。</strong>2025年，本体从实验室走到真实赛场、训练场，并逐步推进行业场景的试点验证，在真实场景的实践打磨中推动技术不断进步。<strong style=\"box-sizing: border-box;\">模型方面，与本体结合初步实现现实任务执行。</strong>蔚来世界模型NWM在Banyan 榕车型上全量推送，强化追尾预防及保护和通用障碍物识别能力。智元机器人GO-1端到端VLA模型部署到智元精灵G1上，完成擦桌子、倒水等任务。分层式端到端VLA如Figure AI Helix支持Figure 02学习物流分拣、叠毛巾和洗碗等任务的作业技能。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195649661090014.png\" title=\"1759195649661090014.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">具身智能要从“实训”走向“干活”，仍面临三大挑战：一是高质量数据缺，</strong>行业普遍认为要实现物理智能涌现至少需要百万小时的机器人数据，而当前真正可用数据远远不足；<strong style=\"box-sizing: border-box;\">二是模型泛化难，</strong>任何在训练数据分布外的场景任务，都会导致性能急剧下降，难以覆盖现实场景的复杂情况；<strong style=\"box-sizing: border-box;\">三是软硬协同难，</strong>模型与本体的结合需要在多个时间尺度上实现协同控制，任何一环信号传输的不稳定，都很可能导致任务执行失败。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">四、萌芽中的世界模型</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195664993085618.png\" title=\"1759195664993085618.png\"/></p><p style=\"text-indent:2em;\">世界模型作为AI系统理解、推理并预测物理世界的“内部模拟器”，被视为通向通用人工智能（AGI）的核心路径之一，正在萌芽中。<strong style=\"box-sizing: border-box;\">产业界期待发展泛化能力强、物理一致性高、可解释性强的“世界模型”，</strong>满足自动驾驶、具身智能等现实需求，也架起通向通用智能的桥梁。<strong style=\"box-sizing: border-box;\">世界模型的核心能力主要包含四类：</strong>一是数据生成能力，世界模型能够根据几何和语义线索生成多样化的3D/4D场景；二是动作解释能力，世界模型能够根据历史观测数据、动作条件预测未来状态；三是环境交互能力，世界模型能够生成连续场景，模拟与环境之间的闭环交互；四是场景重建能力，世界模型能够从部分、稀疏、受损数据中还原完整场景。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195679322073637.png\" title=\"1759195679322073637.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">世界模型的技术路线还处于百花齐放的探索中，当前主要有三条技术路线，</strong>主要包括大模型增强、大模型与物理引擎融合、物理世界表征等。<strong style=\"box-sizing: border-box;\">下一步发展仍面临不少挑战。</strong>一是定义存在争议，不同领域的研究者对其范围和边界的理解不同。二是技术路线不清晰，目前世界模型的实现方法包括生成式模型、强化学习、多模态融合等，不同技术路径的侧重点和适用场景不同。三是应用范围局限，当前世界模型只在自动驾驶领域有一定规模的应用，其他领域仍未实现大规模应用。未来，随着技术层面的突破，其应用将从封闭场景向开放系统延伸，最终成为AI通向AGI的关键基石。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">五、AI正在重塑软件</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195695406097726.png\" title=\"1759195695406097726.png\"/></p><p style=\"text-indent:2em;\">软件和信息技术服务业作为我国先导性、支柱性产业。<strong style=\"box-sizing: border-box;\">大模型向软件研发全过程渗透，深刻改变软件开发工具和产品形态，正开启软件业全面重塑的新阶段。</strong>首先，AI变革软件研发全过程，国内外大模型用于编程任务的Token调用量显著提升，深度渗透软件研发全生命周期各个环节。根据中国信通院调研数据，AI在开发、测试等环节持续稳定保持高比例应用。其次，AI变革软件研发工具，2025年以来，AI IDE、智能体等工具密集发布，在工程化支撑、检查修复、记忆决策等多个维度实现能力跃升，智能研发工具正从副驾驶（Copilot）向驾驶员（Pilot）持续演进。最后，AI变革软件研发产品形态，对话交互、多模态交互、具身智能交互等方式成为主流，软件逐渐具备自我学习、自我优化和自适应能力。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195707520065947.png\" title=\"1759195707520065947.png\"/></p><p style=\"text-indent:2em;\">大模型为软件行业带来智能化新动力，推动人员、企业、产业的深刻变革。<strong style=\"box-sizing: border-box;\">对软件从业者来说，</strong>角色定位、入门门槛转变。开发人员从单一程序员角色转变为复合角色，催生“超级个体”诞生。<strong style=\"box-sizing: border-box;\">对软件企业而言，</strong>企业组织结构、业务场景、生产管理、供应链管理向智能化转型。<strong style=\"box-sizing: border-box;\">对软件行业而言，</strong>竞争规则与商业模式正在经历深刻重构。传统软件以代码为核心，而智能化软件则转向以结果和价值为导向，软件产品的计费方式也从用户定期支付固定费用的订阅模式，逐步转变为按实际资源（如Token）消耗量计费的定量模式。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">六、开放智算生态</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195720195094578.png\" title=\"1759195720195094578.png\"/></p><p style=\"text-indent:2em;\">2025年智算领域发展形势发生极大变化，<strong style=\"box-sizing: border-box;\">以开源开放为特征的新型智算生态正在加速形成，</strong>涌现出开源框架、开源通信库、开源算子库、开放计算平台、开源互联协议等多层次、多领域的标志性成果，为全球人工智能创新发展注入强劲活力。与此同时，在开放智算生态引领下，<strong style=\"box-sizing: border-box;\">我国厂商加快软硬件协同适配，</strong>取得显著成效。DeepSeek、千问、文心一言等优质模型大规模开源，为我国算力厂商提供了关键的适配验证场景，国产硬件在实际AI负载中的性能和兼容性显著提升。中国信通院AISHPerf测试结果表明，通过软硬件协同优化，部分参测硬件产品部署DeepSeek R1模型的精度、部署规模基本与英伟达系统持平，已能够满足实际产业应用需求。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195744761050275.png\" title=\"1759195744761050275.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">智算生态正在加速走向软硬协同开放阶段。</strong>从演进趋势上看，随着单点、局部开源开放逐步扩展至软硬全栈开源开放，我们认为开放智算生态影响力将进一步扩展深化，且不同技术环节——如模型、框架、算子库、通信库、底层硬件之间的开源成果有望实现更深层次、更精细的对接协同，形成自驱生长的飞轮效应，如DeepSeek结合V3训练经验对英伟达硬件体系提出改进建议、智谱GLM 4.5端侧模型基于昇腾环境自定义算子完成高效微调量化等，软硬件间形成更为高效开放、紧密耦合的新一代协同生态，助力人工智能前沿技术以更低成本、更高效率实现价值普惠和规模落地。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">七、面向行业的高质量数据集</strong></p><p style=\"text-indent: 2em; text-align: center;\"><strong style=\"box-sizing: border-box;font-size: 15px;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195763361032353.png\" title=\"1759195763361032353.png\"/></strong></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">人工智能数据集的建设重点从通用基础数据集转向行业高质量数据集，</strong>数据集质量问题成为当前制约行业垂类模型落地和场景应用的核心瓶颈。根据中国信通院可信AI人工智能数据集质量评估统计情况，当前人工智能行业数据集建设中主要面临内容密集性、领域相关性、数据多样性和形式规范性等核心质量问题，占比分别为82.50%、14.04%、1.73%和0.92%。为解决以上人工智能数据集质量问题，亟需建立面向人工智能的数据工程体系。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195778388025043.png\" title=\"1759195778388025043.png\"/></p><p style=\"text-indent:2em;\">面向通用人工智能和行业深度赋能，要加快建设适应强化学习、世界模型等前沿技术和行业智能体所亟需的新型高质量数据集，<strong style=\"box-sizing: border-box;\">构建新型人工智能数据供应链。</strong>面向训练方面，为更好支撑强化学习与智能体训练，未来需构建交互轨迹数据集、偏好对齐数据集、基准评测数据集三大类训练数据集。面向应用方面，为更好支撑AI原生应用，未来需建立基础支撑数据集、过程埋点数据集、外部交互数据集三大类原生基础数据集。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">八、开源成为标配</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195793603011935.png\" title=\"1759195793603011935.png\"/></p><p style=\"text-indent:2em;\">2025年，DeepSeek的开源某种程度上改变了大模型的发展轨迹。开源不仅孕育出一批高质量的人工智能项目，还有力促进了上下游产业链的协同与融合，深刻改变了人工智能产业的发展格局。<strong style=\"box-sizing: border-box;\">开源模型性能比肩闭源。</strong>以深度求索、通义千问等为代表的国产开源模型迅速崛起，为用户带来更具性价比的选择。模型性能方面，目前全球性能前25的大模型中，我国开源模型占据9席。模型普及方面，国产开源模型在Huggingface上的全球累计下载量已突破3亿次。应用生态方面，在Huggingface上基于我国开源模型的微调模型占比从2024年初的10%大幅上升至2025年7月的45%，显示出国产开源模型在国际范围内的接受度和影响力正快速提升。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195807329023206.png\" title=\"1759195807329023206.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">开源社区协同演进，推动技术普惠发展。</strong>我国人工智能开源生态规模稳步扩大。截至2025年9月，我国主流AI开源社区平台已托管模型达38万个、数据集5.3万个，分别相当于HuggingFace同期托管数量的15.3%和9.5%。此外，我国活跃AI开源开发者数量达2.2万人，约占全球AI开源开发者总数的18.7%。一批本土开源社区正在积极推动技术普及与生态建设。<strong style=\"box-sizing: border-box;\">商业模式孕育成型，探索合作共赢模式。</strong>模型厂商普遍采用“开源免费+高阶服务收费”的策略，即采取开源模型吸引开发者，进而通过技术支持、定制开发、云服务等增值服务实现商业转化。同时，开源模型也推动了云服务与芯片需求的增长。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">九、缓解模型幻觉</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195823427067935.png\" title=\"1759195823427067935.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">伴随大模型的落地应用，幻觉引发的风险日益凸显，越来越成为制约应用的主要障碍之一。</strong>根据OpenAI理论研究，幻觉是一种在LLM统计学习本质下必然会产生的、可预测的副产品。根据中国信通院“AI Safety Benchmark”大模型幻觉测试结果，幻觉问题难以得到根治：尽管推理模型被认为是缓解幻觉的一种方案，但所测推理模型的幻觉率依然维持在10%以上。此外，大模型幻觉也存在类似“Scaling Law”的规律：基本呈现大模型参数量越高，幻觉率越低的情况。但大参数量的模型幻觉问题仍较为明显，72b参数模型幻觉依然超过14%。在现有技术架构下，大模型幻觉是其固有属性，成因复杂，训练数据、训练方法、推理过程、评估指标等因素交织。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195846062046375.png\" title=\"1759195846062046375.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">各界探索技术路径，多措并举已现雏形。针对供给侧，</strong>在数据维度，通过数据过滤筛查来提升数据质量，采用知识检索增强扩展模型知识边界。在模型训练维度，通过双向自回归充分捕获上下文信息，采用多偏好对齐提升奖励信号的鲁棒性。在模型评估维度，采用不确定性评估机制，避免模型过度自信。 在模型推理维度，通过对比增强解码保持输出的一致性，采用反思解码及时修正累计错误。<strong style=\"box-sizing: border-box;\">针对用户侧，</strong>在测试选型层面，需判定应用场景对幻觉的容忍度，并通过测试选择适配场景的模型；在二次开发层面，可基于特定应用领域数据，对模型进行微调或编辑；在应用增强层面，可在推理过程加入约束提示或通过知识检索增强引入外部可靠数据，降低幻觉率；在输出审校层面，使用插件审核与人工校对双重核验。</p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;font-size: 15px;\">十、人工智能国际公共产品</strong></p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195862526093205.png\" title=\"1759195862526093205.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">全球人工智能发展不均衡，迫切需要国际公共产品促进跨国交流合作。</strong>当前，全球人工智能技术的研发、应用和关键资源高度集中在少数国家和大型科技公司，发展中国家尚未能真正接触、使用人工智能并从中受益。<strong style=\"box-sizing: border-box;\">随着人工智能全球化发展进入“爆发年”，国际合作扩面提质。</strong>中国信通院统计分析，在联合国、金砖、东盟、上合、G20、G7、太平洋共同体等12个全球重点多边机制中，人工智能均被作为核心议题，发布领导人宣言或联合声明等合作共识，并且中国、沙特、印尼、美国、俄罗斯等国在国际合作中比较活跃。</p><p style=\"text-indent: 2em; text-align: center;\"><img alt=\"image.png\" src=\"http://221.179.172.81:8080/mnt_manage//ueditor/jsp/upload/image/F8ECEDBE41284295911DBD83FFF98AC1/20250930/1759195877399045793.png\" title=\"1759195877399045793.png\"/></p><p style=\"text-indent:2em;\"><strong style=\"box-sizing: border-box;\">产业界通过生态基建创新、工具赋能创新、服务模式创新等策略推动全球化发展。</strong>“技术开源+生态共建”促进通用模型推广，“本地化拓展+普惠赋能”拓展全球市场。华为云、阿里云、昇腾AI等基础层企业提供算力数据芯片等底层支持；Deepseek、通义千问等技术层企业提供算法模型、开发平台；科大讯飞等应用层企业面向场景提供产品与解决方案。总体来看，人工智能国际化发展仍需解决跨境合规认证复杂、ESG评估体系模糊、数据跨境流动受限等挑战，才有望成为真正普惠共享的国际公共产品。</p></div>",
            "pub_date": "2025-10-31 08:20:37",
            "link": "http://www.cww.net.cn/article?id=604347",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "title": "大语言模型推理引擎及推理优化技术浅析（上篇）",
            "description": "<div class=\"text\" id=\"divContentDiv\">\n<p style=\"text-indent:2em;\"><strong>通信世界网消息</strong>（CWW）随着生成式人工智能技术的快速发展，大语言模型的应用规模不断扩大，其推理效率与部署成本成为制约落地的关键因素，大语言模型推理引擎应运而生，专门针对大参数量及高并发场景进行系统性优化，通过连续批处理、量化以及注意力机制等推理优化技术，显著降低了推理延迟，提高了吞吐率与资源利用率，大幅降低计算和内存成本，推动十、百亿级参数量大模型在智算硬件上高效服务，是大语言模型海量应用的核心生产力之一。本文将系统性地阐述大语言模型推理引擎的作用、主要工作流程和应用场景。</p><p style=\"text-indent:2em;\">推理引擎概述<br/></p><p style=\"text-indent:2em;\">大语言模型(LLM)主要分为训练和推理两个阶段。在训练阶段：使用大量的已知数据来训练模型，让模型学习数据中的模式和规律。在推理阶段：使用训练好的LLM模型进行“思考”和“回答”，通常会将训练好的模型部署到实际应用中，让它对未知的数据进行预测或生成内容。例如，当我们向DeepSeek提问时，它分析我们的问题并生成回答，这个过程就是推理。</p><p style=\"text-indent:2em;\">推理引擎是支撑LLM模型高效部署与服务的核心基础设施，其核心作用在于解决大模型在实际应用中面临的严峻性能与成本挑战。它首先是一个“性能加速器”，通过智能化的任务调度和资源分配，让模型能够对用户的请求做出快速的响应，保证对话、创作等应用的流畅性。同时，它也是一个“资源精算师”，能够精密地管理计算和内存资源，显著降低模型运行对硬件的要求，从而让部署和服务的成本变得可控且可接受。更重要的是，推理引擎充当了“万能适配器”的角色，它将不同结构的复杂模型与各式各样的硬件无缝连接起来，极大地简化了从开发到部署的流程。有了推理引擎的强大支撑，那些看似“庞大笨重”的LLM模型才能变得如此“灵巧敏捷”，最终化身为我们日常触手可及的智能应用。</p><p style=\"text-indent:2em;\">推理引擎的主要工作流程<br/></p><p style=\"text-indent:2em;\">大语言模型的推理引擎是驱动模型从“思考”到“回答”的核心系统，其工作流程旨在高效地将用户输入转换为连贯、合理的输出。推理流程主要分为输入处理、模型计算与输出生成三大阶段，这不仅是简单的计算，更是一个涵盖算法优化、硬件调度和资源管理的复杂系统工程。<br/></p><p style=\"text-indent:2em;\">（一）输入处理</p><p style=\"text-indent:2em;\">首先，输入处理将原始输入变为模型可理解的表示，当用户提交一段文本后，推理引擎首先对输入进行预处理，将人类可读的自然语言转化为模型能够处理的数值表示。这一阶段是后续所有计算的基础，主要包括分词和嵌入两个关键步骤。<br/></p><p style=\"text-indent:2em;\">➢分词：引擎将输入的连续文本切分成模型词汇表中存在的更小单元——词（Token）。这些Token可能是一个完整的词、一个子词（如前缀、后缀）或甚至单个字符。例如，句子“北京今天的天气怎么样？”可能会被分割成[\"北京\", \"今天\", \"的\", \"天气\", \"怎么样\", \"?\"]等多个Token。</p><p style=\"text-indent:2em;\">➢嵌入：将每个Token映射成一个高维向量，这些数值向量能够表示Token的语义信息及其在词汇表中的位置。所有Token的向量共同组成一个矩阵，作为模型计算的初始输入。同时，还会通过位置编码为这些向量注入时序信息。至此，文本输入被转换成了一个既包含语义又包含位置信息的数值矩阵，为模型的核心计算做好准备。</p><p style=\"text-indent:2em;\">（二）模型计算</p><p style=\"text-indent:2em;\">经过预处理的数据被送入模型计算单元，而模型计算是指核心的“思考”过程，依据计算特性划分为预填充和解码两个阶段。</p><p style=\"text-indent:2em;\">➢预填充：在模型接收到完整的输入序列后触发，会并行处理所有输入Token，通过自注意力机制计算整个序列的上下文表示，理解所有Token之间的关系和依赖。该过程计算强度大，但能够充分利用GPU的并行计算能力。此阶段会生成键值缓存（KV cache），即所有输入Token的Key和Value矩阵，这些矩阵被缓存在显存中，为后续的解码阶段提供支持。由于需要处理整个序列且计算复杂度与序列长度呈平方关系，该阶段是计算受限的，其性能直接影响首Token延迟（Time to First Token, TTFT），即用户从发送请求到收到第一个输出Token所需的时间。</p><p style=\"text-indent:2em;\">➢解码：模型基于预填充阶段产生的KV Cache，以自回归的方式逐个生成输出Token。即每次预测下一个Token时，模型会参考之前已生成的所有Token及其缓存信息。此过程是串行的，每次计算量相对较小，但需要频繁访问显存中的模型参数和庞大的KV Cache，因此性能主要受限于内存带宽而非计算能力。该阶段的体验通常由每输出Token时间（Time Per Output Token, TPOT）来衡量，即生成两个连续Token之间的平均间隔。TPOT直接影响生成过程的流畅度。</p><p style=\"text-indent:2em;\">（三）输出生成</p><p style=\"text-indent:2em;\">最后由输出生成阶段构造最终的结果。在解码阶段的每一步模型都会输出一个概率分布，表示词汇表中所有Token作为下一个输出的可能性。解码的任务就是依据此分布选择最终的输出，不同的策略会在生成文本的质量、多样性和确定性之间取得不同的平衡。常见的解码策略包括：</p><p style=\"text-indent:2em;\">➢贪婪搜索：总是选择概率最高的Token。方法简单且速度快，但容易生成重复、单调的文本。</p><p style=\"text-indent:2em;\">➢束搜索：在生成过程中保留多个概率较高的候选序列，最终选择整体概率最高的序列。能在一定程度上提高生成质量，但多样性仍可能受限。</p><p style=\"text-indent:2em;\">➢采样：引入随机性以增加多样性，主要有Top-k和Top-p两种采样方式。Top-k采样仅从概率最高的k个Token中随机选择。Top-p采样（核采样）从累积概率超过阈值p的最小Token集合中随机选择。</p><p style=\"text-indent:2em;\">➢温度调节：通过一个温度参数来控制概率分布的平滑程度。高温（&gt;1）会让所有Token的概率更接近，增加随机性和创造性；低温（&lt;1）会放大高概率Token的权重，使输出更确定和集中。</p><p style=\"text-indent:2em;\">最终，需要将选定的输出单元转换回最终输出格式。对于文本生成，通过解分词将Token ID序列转换回人类可读的文本。对于文生图，则通过解码器将去噪后的结果采样并转换回像素空间，生成最终的高分辨率图像。</p><p style=\"text-indent:2em;\">评估推理引擎工作流程效率的核心指标主要有TTFT、TPOT和吞吐量三个，其中TTFT指的是首Token延迟，是衡量系统响应速度的关键指标，TPOT指的是每输出Token时间，主要衡量生成过程的“流畅度”，而吞吐量指的是每秒生成Token数量，主要考核服务端的“服务容量”和“成本效益”。这些指标之间往往存在权衡。例如，为了提高吞吐量而同时处理更多请求（增大批处理大小），可能会增加每个请求的延迟（TTFT和TPOT）。因此，优化的核心目标是在给定硬件资源下，找到满足业务需求的最佳平衡点。</p><p style=\"text-indent:2em;\">整个LLM大模型推理流程是一个精妙的“文本→数字→计算→数字→文本”的循环。输入处理阶段将文本符号转化为数值向量；模型计算阶段在向量空间中进行复杂的数学变换和推理，理解上下文并预测下一个词的概率分布。输出生成阶段则根据概率分布抽样，将选中的数字ID循环反馈给模型，最终全部转换回文本符号。</p><p style=\"text-indent:2em;\"><span style=\"text-indent: 2em;\">推理引擎的主要应用场景</span><br/></p><p style=\"text-indent:2em;\">推理引擎是支撑LLM部署应用的核心基础设施，其应用场景广泛分布于专注高性能计算和低延迟的领域，这些场景能充分发挥推理引擎在平衡性能、成本与规模化服务中的关键优势。</p><p style=\"text-indent:2em;\">➢在云计算与AIaaS平台中，推理引擎通过动态批处理和显存优化等技术，实现多租户环境下高吞吐的模型服务，典型代表包括DeepSeek、GPT5等大规模并发交互系统。</p><p style=\"text-indent:2em;\">➢在边缘计算与终端设备场景中，通过推理引擎实现模型压缩，实现部分轻量化模型在移动设备或边缘服务器上的本地化推理服务。</p><p style=\"text-indent:2em;\">➢在AI编程助手、内容生成平台和实时交互机器人场景中，推理引擎保障了低延迟逐个token生成能力，显著提升用户体验。</p><p style=\"text-indent:2em;\">➢在企业私有化部署场景中，借助推理引擎提供的量化和算子融合等技术，可在有限GPU资源中高效运行十、百亿级参数量模型，满足金融、法律等行业对数据隐私与响应速度的双重要求。</p><p style=\"text-indent:2em;\">总结</p><p style=\"text-indent:2em;\">大语言模型推理引擎是一个环环相扣的复杂系统工程，它高效地融合了数据转换、数值计算、逻辑推理和资源调度等多个环节，确保在庞大的参数规模下，仍能向用户提供快速、准确且流畅的智能服务,如同LLM大模型的“高性能大脑”，负责以最低的成本、最快的速度、最可靠的方式执行推理任务，是让大模型从“拥有潜力”到“实现实用价值”的关键桥梁。</p><p style=\"text-indent:2em;\"><br/></p></div>",
            "pub_date": "2025-10-31 08:20:36",
            "link": "http://www.cww.net.cn/article?id=604829",
            "source": "cww",
            "kind": 1,
            "language": "zh-CN"
        }
    ]
}