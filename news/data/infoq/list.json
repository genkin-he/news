{
    "data": [
        {
            "id": "hsajzR0xvFoaUYpTqVpO",
            "title": "Cilium 十周年：为大规模集群带来更强的加密、更安全的策略与更清晰的可观测性",
            "image": "https://static001.infoq.cn/resource/image/1c/8b/1c65c4826e0b3c0e8044a59993b3be8b.jpg",
            "description": "<div><p>Cilium 1.19 ，标志着这款基于 eBPF 的网络与安全项目已走过十年发展历程。本次发布的版本未推出旗舰级功能，而是聚焦于安全加固、加密增强、网络策略行为优化，以及提升大规模 Kubernetes 集群的可扩展性。</p><p></p><p>将 1.19 称为一个特别的版本，以此庆祝项目首次提交代码至今的十周年；十年间，已有 1000 多名开发者参与贡献，提交次数超过 2900 次。解释了 Cilium 如何悄然成为生产级 Kubernetes 环境中占主导地位的 CNI（容器网络接口）。调查显示，超过 60% 的部署直接使用了 Cilium，如果将 Azure CNI powered by Cilium 和 GKE Datapath V2 等托管服务计算在内，超过 75% 的部署依赖基于 Cilium 的数据平面。报告指出，这一市场地位源于深思熟虑的技术选型，而非平台默认设置。用户将性能、基于 eBPF 并通过 Hubble 实现的可观测性以及高级策略语义列为选用 Cilium 的主要原因，这与 1.19 版本重点强化的更严格加密模式、更安全的跨集群默认配置和更深度的流量追踪高度契合。报告还显示，项目贡献量已稳定在每年约 10000 个拉取请求，Cilium 现已成为 CNCF 中仅次于 Kubernetes 的第二大贡献项目。</p><p></p><p></p><p><img>https://static001.geekbang.org/infoq/5d/5d8d815a429e3fc262d0589204abf3e7.png<img></p><p></p><p></p><p>报告的第二个主题是 Cilium 及其相关项目向新领域的扩展，尤其聚焦 AI 工作负载，以及跨 Kubernetes 与虚拟机的统一网络。微软、谷歌和 TikTok 等大型机构，均使用 Cilium 支撑其超大规模 AI 训练集群与纯 IPv6 数据中心部署，而来自 ESnet 和 Nutanix 等公司的案例研究则体现了跨异构环境下统一可观测性与策略管控的价值。报告还将  定位为一个新兴的运行时安全层，目前正在开发 Windows 支持、持久化执行以及基于 uprobe 和 USDT 的用户空间钩子点。这一方向与 1.19 版本中强化的加密能力、Hubble 优化后的丢包归因能力相互补充，将更多执行逻辑纳入专用安全平面。</p><p></p><p>1.19 版本为 IPsec 和 WireGuard 引入了严格模式。这一变化将加密从尽力而为的选项变为节点间的硬性要求。在严格模式下，未加密的节点间流量会被直接丢弃，满足了金融与公共部门等场景的内部合规策略要求，旨在消除对集群网络内隐式信任的依赖。项目摘要指出，这一变化主要面向“受监管或零信任环境”。认为，这让 Cilium 的数据平面行为更贴近安全团队对现代服务网格的预期。此前社区曾有长期争议，，早期 Cilium 架构在适配严格 mTLS 模型时，会迫使运维人员“破坏集群安全”，这表明项目正在直接回应早期的批评意见。</p><p></p><p>该版本还新增了  的测试版集成。Ztunnel 能够在无需边车代理的情况下实现工作负载之间 TCP 连接的透明加密和认证。在 1.19 的发布说明中，维护者介绍了如何将命名空间注册到 Ztunnel，使工作负载无需修改应用即可获得双向认证，这再次让 Cilium 更接近服务网格的理想形态。官方决定默认禁用现有的双向认证功能，并引导需要 mTLS 的用户使用 Ztunnel 方案，这也暗示了对早期设计选择的重新思考。其他类似项目如  仍依赖基于边车的部署。评论指出，这种更轻量的方案即便仍处于测试阶段，也能降低每个 Pod 的开销与配置复杂度，具备很强的吸引力。</p><p></p><p>对于多集群环境，当网络策略未指定集群时，默认行为已发生变化。在 Cilium 1.19.0 中，这类选择器默认仅允许来自本地集群的流量，这降低了因策略配置不当在 Cluster Mesh 部署中意外跨集群暴露服务的风险。该版本还新增了多级 DNS 通配符匹配，以及策略拒绝连接时 Cilium 返回 ICMPv4 “目标不可达”响应的选项。这些功能让网络策略更具表达力，也更易于调试。Kafka 协议匹配字段，以及 ToRequires 和 FromRequires 策略字段已被弃用，移除使用频率较低的复杂逻辑，帮助运维人员聚焦于实际大规模部署的常用模式。</p><p></p><p>从运维角度来看，Multi Pool IPAM（多池 IP 地址管理）升级为稳定版后得到了积极反馈，尤其是来自使用大型或分段地址空间的用户。本版本中已说明，Multi Pool IPAM 可与 IPsec 和直接路由搭配使用，已具备大规模生产使用条件。此前在 反馈 Cilium 高级功能“需要大量工作才能配置并正常运行”的用户，如今拥有了更清晰的跨多地址池分配地址的方案，这在混合集群或多租户集群中至关重要。双栈集群中支持将 IPv6 作为隧道底层选项，以及对 IP 伪装更细粒度的控制，也常在相关讨论中被提及。这些改进扩展了 Cilium 可支持的网络拓扑范围，且无需依赖脆弱的临时变通方案。</p><p></p><p>Cilium 的可观测性组件  也迎来了一系列改进，成为社区讨论中反复提及的最后一组变化。Hubble 现在支持通过 IP 选项追踪特定流的数据包，并可在命令行中按加密状态过滤流量；同时还能通过具体触发丢包的网络策略对丢包事件进行标记。这些改进解决了长期以来的痛点：基于 eBPF 的数据平面在故障期间难以理解与排查。</p><p></p><p>Cilium 1.19.1 ，更多详情请访问 。</p><p></p><p><strong>原文链接：</strong></p></div>",
            "link": "https://www.infoq.cn/article/hsajzR0xvFoaUYpTqVpO",
            "pub_date": "2026-02-28 07:00:00",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "wrX55vc9FQ6w5PlbIkiS",
            "title": "Snowflake Cortex Code：它是什么，为什么重要，以及何时使用它 ｜技术实践",
            "image": "https://static001.infoq.cn/resource/image/78/87/7840fd6e466530380a620e8cd3fe3c87.jpeg",
            "description": "<div><p><italic>2026 年，智能体将在企业级应用中取得哪些实质性突破？</italic><italic>《2026 年 AI 与数据发展预测》白皮书，获悉专家一手前瞻，抢先拥抱新的工作方式！</italic></p><p></p><p>近日，Snowflake 正式发布 Cortex Code ——一款原生集成于 Snowflake 的 AI 编程助手，旨在显著缩短从构想到生产上线的周期，尤其适用于依赖受管企业数据的开发场景。</p><p></p><p>如果您是已在 Cursor / Claude Code / Codex（或其他编程助手）中工作的开发者，本文将为您清晰解读：Cortex Code 是什么、为何推出，以及何时应选用它。</p><h2>核心要点</h2><p></p><ul><li><p><strong>Cortex Code 是 Snowflake 专为其数据技术栈打造的 AI 编程助手，旨在帮助开发者更快地将想法落地为生产应用。</strong>它不仅理解您的代码库，更深度集成您的 Snowflake 环境；</p></li></ul><ul><li><p><strong>提供两种使用方式：</strong>在 Snowsight /工作空间中使用（平台内集成），或通过 Cortex Code CLI 在本地终端调用（可无缝用于 VS Code/Cursor 等终端）；</p></li></ul><ul><li><p><strong>与通用编程助手的核心区别：</strong>Cortex Code 深度感知 Snowflake 环境（数据目录、语义信息与治理策略），遵循 RBAC 权限管控，并能自动化端到端数据工作流（涵盖 dbt、SQL、Notebook、智能体及运维/财务管理任务），从而避免在工具间频繁复制粘贴的繁琐操作；</p></li></ul><ul><li><p><strong>无需更换 IDE：</strong>如果您习惯使用 Cursor，可继续沿用。只需在终端中运行 Cortex Code，即可高效完成与 Snowflake 相关的繁重开发任务。</p></li></ul><h2>2 分钟快速上手（Cortex Code CLI）</h2><p></p><p>若想立即体验，请按以下步骤操作：</p><p></p><p>1. 安装 Cortex Code CLI：</p><p></p><p></p><p>这将安装  可执行文件（默认安装路径为）。</p><p></p><p>2. 运行  并按照设置向导连接 Snowflake。</p><p></p><p>系统将提示您从  中选择现有连接或创建新连接。若已使用 Snowflake CLI（），可直接复用同一连接配置文件。</p><p></p><p>3. 提出您的首个需求：</p><p></p><p></p><p>如需了解几个直观的后续操作示例，可尝试以下指令：</p><p></p><p></p><p></p><h2>问题所在：人工智能工具无处不在，但数据工作仍然面临瓶颈</h2><p></p><p>我认识的多数开发者已经在日常工作中广泛使用人工智能工具。它们在搭建代码框架、重构代码或解决疑难时表现出色。</p><p></p><p>然而，数据与人工智能结合的工作存在一个特定的摩擦点：</p><ul><li><p>您的代码存放于代码仓库中；</p></li></ul><ul><li><p>您的核心数据资产却位于 Snowflake 平台（包括数据目录、权限管理、查询历史、成本记录、语义模型及生产流水线）。</p></li></ul><p></p><p>通用的编程智能体通常无法自然访问（或安全操作）后者。它们的上下文边界往往止步于代码仓库，而在许多组织内部，将上下文传输至受控治理边界之外是绝对不可行的。</p><p></p><p>这正是 Cortex Code 旨在填补的空白。</p><h2>Snowflake Cortex Code 是什么？</h2><p></p><p><strong>Cortex Code 是 Snowflake 开发体验的智能体化实现。</strong>它将复杂的数据工程、分析、机器学习与智能体构建任务，转化为基于您Snowflake环境、以自然语言驱动的工作流。</p><p></p><p>其在平台中的定位同样重要：Cortex Code 是 Snowflake Cortex AI 产品套件的一部分，与 Snowflake Intelligence 并列，旨在无缝融入团队在受治理数据上端到端构建与运行AI工作流的方式。</p><p></p><p>您将通过以下两种方式使用它：</p><h2>在 Snowsight / Workspaces 平台内使用 Cortex Code（内置式体验）</h2><p></p><p>此为“我已身处Snowflake环境”的使用模式，尤其适用于：</p><ul><li><p><strong>SQL 开发；</strong></p></li></ul><ul><li><p><strong>运维与财务运营工作流</strong>（用量分析、成本动因追溯、角色/权限管理、治理问题排查）；</p></li></ul><ul><li><p><strong>数据发现</strong>（目录检索、定位准确的数据表/视图/模型）；</p></li></ul><ul><li><p><strong>Workspaces 原生工作</strong>（SQL + Python + dbt 项目，支持差异比对与评审流程）；</p></li></ul><ul><li><p>该设计同时致力于构建统一界面，能够根据需求自动导向对应功能（文档查阅、目录发现、成本/用量分析、治理问题解答、代码变更），无需用户记忆特定功能对应的操作界面。</p></li></ul><h2>Cortex Code CLI（本地终端/ IDE 集成终端）</h2><p></p><p>此为“适配工作场景”型体验，尤其适用于：</p><ul><li><p><strong>端到端项目</strong>（dbt +代码+测试+验证+部署）；</p></li></ul><ul><li><p><strong>流水线编排；</strong></p></li></ul><ul><li><p><strong>智能体与应用部署流程；</strong></p></li></ul><ul><li><p>在保持 Snowflake 环境感知的同时<strong>，操作本地文件、代码库、Git 及其他开发工具。</strong></p></li></ul><p></p><p>若您习惯使用 Cursor 或 VS Code，可在集成终端中运行 Cortex Code CLI，无需切换开发环境。</p><h2>Cortex Code 为何存在（以及它为何不仅仅是又一个 Copilot）</h2><p></p><p>对此最简洁的解释是：<strong>Cortex Code 致力于成为在 Snowflake 平台上进行开发的最实用智能体。</strong></p><p></p><p>这可以归结为四大支柱：</p><ul><li><p><strong>智能性（深度理解 Snowflake）</strong></p></li></ul><p>它是内建的 Snowflake 功能与环境专家：深刻理解您的数据库、模式、表、语义模型，以及那些通用工具常常忽略的 Snowflake 特有语义。</p><ul><li><p><strong>相关性（具备情境感知能力）</strong></p></li></ul><p>其设计旨在遵循您的工作流程（您当前所处位置、正在编辑的内容、前几个指令的上下文），而非将每个请求都当作一次全新的对话来处理。</p><ul><li><p><strong>集成性（与您的技术栈协同工作）</strong></p></li></ul><p>支持 dbt、Git、SQL、Python、Workspaces/笔记本、Streamlit，且无需改变您现有的工作方式。</p><ul><li><p><strong>治理性（安全设计为本）</strong></p></li></ul><p>Cortex Code 采用 Snowflake 的 RBAC 模型：其仅能查看并操作您当前角色权限范围内的资源，且所有操作均以您的权限执行（包括现有的行级安全策略、数据脱敏等控制机制）。对于受监管的环境而言，这正是一个酷炫演示与一个真正可投入使用的工具之间的关键区别。</p><h2>本产品的定位说明</h2><p></p><ul><li><p><strong>并非</strong>集成开发环境的替代品。（请务必继续使用Cursor/VS Code）；</p></li></ul><ul><li><p><strong>并非</strong>面向全球所有技术框架的通用型智能体；</p></li></ul><ul><li><p><strong>并非</strong>万能魔法。在使用时，仍需结合专业判断，特别是在权限控制、成本评估与结果准确性方面。</p></li></ul><h2>您能用 Cortex Code 做什么（具体示例）</h2><p></p><p>如果您是 Snowflake 原生智能体的新手，以下是展示其典型应用场景的提示示例：</p><p></p><ul><li><p><strong>数据发现与治理</strong></p></li></ul><p><italic>“查找所有包含个人身份信息（PII）的表。”</italic></p><p><italic>“我的角色在此数据库上拥有哪些权限？”</italic></p><p><italic>“为何我会遇到权限错误？</italic></p><ul><li><p><strong>成本与用量分析</strong></p></li></ul><p><italic>“哪 5 种服务类型消耗了最多的计算积分？”</italic></p><p><italic>“过去 30 天内成本最高的计算仓库是哪个？对应的前 5 条查询是什么？”</italic></p><ul><li><p><strong>SQL与数据分析</strong></p></li></ul><p><italic>“这段 SQL 脚本的功能是什么？”</italic></p><p><italic>“在不改变结果的前提下，优化此查询的性能。”</italic></p><ul><li><p><strong>dbt 与数据管道</strong></p></li></ul><p><italic>“为我的 dbt 项目创建一个新的数据集市模型并编写测试用例。”</italic></p><p><italic>“为此流水线生成依赖关系图并提出依赖项建议。”</italic></p><ul><li><p><strong>智能体与企业工作流</strong></p></li></ul><p><italic>“为此数据集创建面向 Cortex Analyst 的语义视图。”</italic></p><p><italic>“基于这些文档构建 Cortex Search 服务。”</italic></p><p><italic>“构建一个能调用 Analyst 进行指标分析、同时使用 Search 处理通话记录的 Cortex 智能体，并将其部署至 Snowflake Intelligence。”</italic></p><p></p><p>这些任务的共同点在于：它们都不是单文件代码生成任务，而是通常需要跨界面、编辑器、终端、文档乃至（坦白说）Slack 等多场景切换的多步骤工作流。</p><h2>为何重要（按角色划分）</h2><p></p><ul><li><p><strong>数据工程师/分析工程师：</strong>通过测试与验证加速dbt变更，减少“我是否破坏了生产环境？”的疑虑，降低追溯数据血缘与元数据的时间成本；</p></li></ul><ul><li><p><strong>数据科学家/AI/ML工程师：</strong>提升从笔记本到生产管道的迭代效率，减少胶水代码，实现从实验到受治理生产工作流的平滑过渡；</p></li></ul><ul><li><p><strong>平台/管理/FinOps人员：</strong>为您日常处理的角色、使用情况、成本及治理问题提供自然语言交互入口，无需反复查询系统表；</p></li></ul><ul><li><p><strong>全体人员：</strong>减少上下文切换，更专注于“基于可靠依据交付成果”。</p></li></ul><h2>真实工作流程</h2><p></p><p>Snowflake 产品数据科学团队梳理了一些内部工作流程，这些流程清晰映射了构建者日常的实际工作。以下是几个重点示例（经过转述，但保持原意）：</p><h2>通过单次提示完成数据工程变更（dbt +验证+报告）</h2><p></p><p><strong>原有方式：</strong>在 Snowsight 中编写查询，在 VS Code 中编辑 dbt 模型，运行 dbt run，运行 dbt test，编写对比查询，将结果粘贴到文档中。</p><p></p><p><strong>新方式：</strong>通过一个提示请求变更，并提供变更有效的证明。</p><p></p><p>此处的关键突破并非“打字更快”，而是将整个工作流程（包括验证产物）压缩为一次请求。</p><h2>基于语义视图生成管道图</h2><p></p><p>如果你曾接手过一份 546 行的语义视图定义，并希望“直观看到模型”，这个方法正适用于此。</p><p>提示：“这是一个 546 行的语义视图，请生成一份实体关系图。”</p><p></p><p>效果：生成的文档能保持最新，因为它源于源代码自动生成，而非手工维护。</p><h2>dbt 性能与成本优化（并将其转化为可复用技能）</h2><p></p><p>提示：“找出最慢的模型，提出优化建议，并标记出可删除的未使用下游模型。”</p><p></p><p>效果：在一个案例中，运行时间从约 10 小时降至 2 小时以内，且该工作流程被转化为一个可复用的技能文件，供他人重复使用。</p><p></p><p>最后这一点很重要：如果你的组织注重可重复性，<strong>技能能将一次性成果转化为团队的肌肉记忆。</strong></p><h2>在何时应选用 Cortex Code，而非 Cursor / Claude Code / Codex /通用型智能体？</h2><p></p><p>我们不会宣称存在唯一的优胜者——这些工具功能有重叠，最佳方案往往是组合使用。</p><p></p><p>以下为实用决策指南——</p><p></p><p>简明原则：</p><ul><li><p><strong>若答案取决于你的Snowflake账户，请使用Cortex Code；</strong></p></li></ul><ul><li><p><strong>若答案取决于你的代码库或技术框架，请选用你惯用的通用编程智能体。</strong></p></li></ul><h2>当任务依赖于 Snowflake 上下文时，请使用 Cortex Code</h2><p></p><p>在以下情况下，应考虑采用 Cortex Code：</p><p></p><ul><li><p><strong>涉及 Snowflake 目录与对象</strong>（模式/表/语义视图/搜索服务/智能体）；</p></li></ul><ul><li><p><strong>涉及 Snowflake 安全模型（</strong>RBAC、“此角色具备哪些权限？”、受管控操作）；</p></li></ul><ul><li><p><strong>需要符合 Snowflake 规范的代码</strong>（Snowflake SQL 细节、Snowpark、动态表、语义对象等）；</p></li></ul><ul><li><p><strong>需要端到端自动化</strong>（dbt 变更+测试+验证查询+可共享的报告）；</p></li></ul><ul><li><p><strong>需要在受管控数据上构建/运行智能体</strong>（Snowflake Intelligence、Cortex Analyst、Cortex Search、Cortex Agents）。</p></li></ul><p></p><p>换言之：<strong>若任务涉及基于 Snowflake 的数据工程/分析/机器学习/智能体开发，Cortex Code 应成为您的核心工具之一。</strong></p><h2>当工作主要涉及 Snowflake 外部系统时，宜采用通用编码智能体</h2><p></p><p>在以下场景中，Cursor/Claude Code/Codex类工具表现优异：</p><ul><li><p>前端/界面开发及通用应用框架构建</p></li></ul><ul><li><p>跨大型非Snowflake代码库的多语言重构</p></li></ul><ul><li><p>不涉及Snowflake元数据、角色或账户语义的通用编程任务</p></li></ul><h2>通用推荐方案（标准应用路径）</h2><p></p><p>我们预计大多数团队会采用以下模式：</p><p></p><ul><li><p>使用 Cursor（或您惯用的 IDE）进行代码编辑、审查及跨仓库操作；</p></li></ul><ul><li><p>运用 Cortex Code CLI 执行 Snowflake 感知运算、流水线任务、dbt 工作流以及智能体/应用部署。</p></li></ul><p></p><p>若您已为其他智能体或开发环境编写了指令，Cortex Code 同样支持灵活扩展：</p><p></p><ul><li><p><strong>AGENTS.md：</strong>无缝迁移您的项目上下文与规则（即使原指令为其他智能体/IDE编写）；</p></li></ul><ul><li><p><strong>MCP（模型上下文协议）：</strong>以标准化方式接入外部系统与工具；</p></li></ul><ul><li><p><strong>技能模块：</strong>将可复用的工作流程固化封装，实现团队级协同共享。</p></li></ul><h2>入门指南</h2><p></p><p>我所见过的最佳建议（也与我的工作方式一致）：</p><p></p><p><strong>选择一个你本来就要处理的实际任务，并使用 Cortex Code 来完成它。</strong></p><p></p><p>如果你希望遵循简单的进阶路径，这里有一个清晰的路线：</p><h2>初级（Level 100）：数据发现与查询</h2><p></p><ul><li><p>连接至你的 Snowflake 账户；</p></li></ul><ul><li><p>要求智能体查找可供写入的相关数据表；</p></li></ul><ul><li><p>生成或加载小型数据集（合成数据亦可）；</p></li></ul><ul><li><p>请求生成分析查询语句，并持续迭代优化。</p></li></ul><p></p><p>以下是与上述内容对应的几组复制/粘贴提示词：</p><p></p><p></p><p></p><h2>进阶（Level 200）：语义+搜索+智能体</h2><p></p><p>l 创建语义视图（供 Cortex Analyst 使用）；</p><p>l 创建 Cortex Search 服务（用于非结构化/文档检索）；</p><p>l 构建一个 Cortex 智能体，实现 Analyst 与 Search 之间的路由调度；</p><p>l 将其部署至 Snowflake Intelligence。</p><p></p><p>用于演示工作流程结构的示例提示：</p><p></p><p></p><h2>最佳实践（值得反复强调）</h2><p></p><ul><li><p>聚焦成果，而非实现细节。例如：表述为“构建用户流失看板”，而非“编写GROUP BY查询语句”；</p></li></ul><ul><li><p>复杂任务需先提供方案，以便预先审核其可行性；</p></li></ul><ul><li><p>审阅所有变更与高风险操作（DDL/DML语句），确认无误后再执行；</p></li></ul><ul><li><p>要求提供验证证据。包括数据校验查询、对比报告、测试案例等，此类要求应作为指令的固定组成部分。</p></li></ul><h2>核心观点</h2><p></p><p>Cortex Code 令我振奋之处，并非仅仅是它能更快地编写 SQL。</p><p></p><p>而是它精准应对了真正阻碍研发效率的关键痛点：</p><ul><li><p>频繁的上下文切换；</p></li></ul><ul><li><p>权限配置混乱；</p></li></ul><ul><li><p>“目标明确，但需繁琐的中间步骤”；</p></li></ul><ul><li><p>因时间不足而未经充分验证便匆忙交付。</p></li></ul><p></p><p>若 Cortex Code 能实现其设计目标，它将在不牺牲治理标准的前提下，显著提升小型数据/人工智能团队的交付能力上限。</p><p></p><p>现在，就在实际任务中尝试使用它吧。祝探索愉快！</p><p> </p><p>原文地址：</p><p></p><p><img>https://static001.geekbang.org/infoq/36/3625913187f520bdbc21798ff22d17aa.jpeg<img></p><p></p><p>点击链接立即报名注册：，<italic>更多 Snowflake 精彩活动请关注</italic><italic>。</italic></p></div>",
            "link": "https://www.infoq.cn/news/wrX55vc9FQ6w5PlbIkiS",
            "pub_date": "2026-02-25 11:13:30",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "9PhfRAXmHLAd5CrarY8q",
            "title": "亚马逊云科技终止视频编解码专利保护，开发者需“自担风险”",
            "image": "https://static001.infoq.cn/resource/image/59/27/59d985fcc4cab785f37dcfba6523f427.png",
            "description": "<div><p>亚马逊云科技已取消对其视频转码和流媒体服务用户的法律保护，此举可能使客户面临来自编解码器权利持有者的专利侵权指控。该变更涉及六项服务，包括广受欢迎的文件级视频处理服务 MediaConvert 和直播视频编码服务 MediaLive。</p><p></p><p>今后，使用媒体服务的亚马逊云科技客户必须独立评估第三方专利风险，并最终协商单独的许可协议。在此变更之前，该服务提供商未能与专利持有者达成许可协议，亚马逊云科技称这些专利持有者索要的费用极其不合理。</p><p></p><p>虽然亚马逊并未通过其传统的公开渠道宣布这一变更，但这家云提供商已联系所有使用受影响服务的客户，告知其服务条款的变动，并批评视频专利持有者的版税要求是不合理的。亚马逊云科技在邮件中写道：</p><p></p><p>受影响的服务包括：Elemental MediaLive、Elemental MediaConvert、Amazon Interactive Video Service (IVS)、Chime SDK、GameLift Streams 以及 Kinesis Video Services。The Duckbill Group 的首席云经济学家 Corey Quinn 对此道：</p><p></p><p>鉴于视频、音频文件及编解码器的输入输出格式，开发人员没有简单的方法来确定哪些格式可能会带来麻烦。该云提供商补充道：</p><p></p><p>相比之下，Azure 仍通过 Azure IP Advantage 等项目提供针对第三方知识产权指控（包括专利和版权）的赔偿保护。该计划为客户提供防御性专利许可权，并允许客户访问微软的专利库，从而使其能够阻吓或反击专利流氓的索赔。在亚马逊云科技官方社区平台 re:Post 上，一位开发者质疑道：</p><p></p><p>条款变更已于 2 月 2 日生效，且仅适用于编解码器和媒体服务；对于使用其他托管服务的客户，该云提供商继续提供知识产权侵权保护。亚马逊云科技 表示，对于此次变更前发生的编解码纠纷，它仍将履行所有既定义务。</p><p></p><p><strong>原文链接</strong>：</p><p>https://www.infoq.com/news/2026/02/aws-drops-patent-protection/</p></div>",
            "link": "https://www.infoq.cn/article/9PhfRAXmHLAd5CrarY8q",
            "pub_date": "2026-02-25 08:20:06",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "GLV2qyBOst18dXj3ubDz",
            "title": "告别云原生内存黑盒：SysOM MCP助力ACK AI助手智能运维实践",
            "image": "https://static001.infoq.cn/resource/image/27/ee/278c8d0506fd58dfb69b3fab24debbee.jpg",
            "description": "<div><h2>云原生场景下节点/容器内存问题频发，内存一扩再扩</h2><p></p><p>在云原生时代，Kubernetes（K8s）虽已成为容器编排的标准，但其复杂资源管理场景却让运维团队饱受挑战。其中，节点和容器的OOM（Out of Memory）及内存异常占用问题尤为常见，如：</p><ul><li><p><strong>内存持续高位占用</strong>：节点长期接近  阈值，导致 Kubelet 频繁触发驱逐机制，Pod 被迫迁移，业务稳定性受损。更糟糕的是，高内存压力还会影响节点调度评分，导致新 Pod 无法正常调度。</p></li></ul><ul><li><p><strong>容器 OOM 频发</strong>：Pod 因超出 memory limits 而被 cgroup 终止，表现为 状态，导致业务频繁重启，难以定位真正原因。</p></li></ul><ul><li><p><strong>应用内存泄漏隐性增长</strong>：应用存在内存泄漏时，短期压测可能完全正常，但运行数天甚至数周后，内存占用逐步攀升直至触发 OOM。这类问题隐蔽性极强，往往在生产环境才暴露。</p></li></ul><ul><li><p><strong>资源配额设置失衡</strong>：  配置不合理是常见问题——配置过低导致频繁 OOM 驱逐，配置过高则造成资源浪费和调度效率下降。而\"合理值\"的判断高度依赖业务特征和历史数据。</p></li></ul><h2>问题排查困难</h2><p></p><p>但是云原生内存问题排查起来又遇到重重阻碍，通常需要多方专业人员协助投入，耗时多天才能定位定位根因找到合适解决方案。</p><p></p><h2>应运而生：ACK AI助手与 ACK&SysOM MCP</h2><p></p><p>面对上述痛点，业界一直在探索更智能的解决方案。阿里云容器服务团队推出的计算 AI 助手（ 也称 ACK AI 助手）、ACK MCP 工具与阿里云基础软件团队推出  工具集正是为此而生；通过将 SysOM 专业系统诊断能力以 MCP形式深度集成至 ACK AI 助手，从而一句话闭环云原生内存问题。</p><p></p><p><strong>ACK AI 助手 + ACK MCP：懂云原生业务场景的「智能 SRE」</strong></p><p></p><p>ACK AI 助手是构建在阿里云容器服务 ACK 之上的智能运维助手。</p><p></p><p>容器服务 AI 助手深度融合操作系统能力，<strong>打造覆盖容器全生命周期（Day0~Day2）的智能运维体验</strong>。基于“卓越架构”理念，助手在稳定性、成本、安全与性能等维度提供最佳实践指导。</p><p></p><p>其核心能力包括：</p><ul><li><p>智能诊断——通过环境全感知、多轮反问补充上下文，并协同多个专家 Agent 会诊，结合观测数据与领域经验，实现从异常发现、根因定位到一键修复的闭环；</p></li></ul><ul><li><p>集群优化——自动完成成本、安全、架构及弹性配置等多维度分析，生成可执行优化方案并预测效果；</p></li></ul><ul><li><p>智能健康检查——对集群、节点、Workload、网络、存储等全方位进行动态异常检测，融合大模型与算法，超越传统阈值告警；</p></li></ul><ul><li><p>同时支持复杂场景下的全自动AIOps流程，未来还将实现应用创建与资源管理的自动化，真正让容器服务更智能、高效、自愈。</p></li></ul><p></p><p><img>https://static001.geekbang.org/infoq/cc/cca408a21297e475463fc799b7ecbd4e.webp<img></p><p></p><p>ACK AI助手也同样提供开源项目 ack-mcp-server tool集合 ，以提供用户在自己的AI Agent上构建阿里云容器服务 ACK、Kubernetes 领域的 SRE Agent。</p><p></p><p>以下一些核心 AIOps 场景 demo：</p><p></p><p></p><p><strong>SysOM MCP：深度操作系统诊断的「专业医生」</strong></p><p></p><p>SysOM MCP 项目内置超过 20 个操作系统控制台生产级节点/容器诊断工具：</p><ul><li><p><strong>内存分析</strong>：内存全景诊断、应用内存诊断、OOM 内存诊断；</p></li></ul><ul><li><p><strong>IO 诊断</strong>：IO 一键诊断、IO 流量分析诊断；</p></li></ul><ul><li><p><strong>网络排查</strong>：网络丢包诊断、网络抖动诊断；</p></li></ul><ul><li><p><strong>调度诊断</strong>：系统负载诊断、调度抖动诊断；</p></li></ul><ul><li><p><strong>磁盘诊断</strong>：磁盘分析诊断；</p></li></ul><ul><li><p><strong>宕机诊断</strong>：宕机诊断（dmesg 分析）、宕机诊断（vmcore 深入分析）。</p></li></ul><p></p><p>对于内存问题，SysOM 内存工具覆盖从内核内存到应用内存的全方位内存分析，涵盖 10+ 内存异常场景：</p><p><img>https://static001.geekbang.org/infoq/3b/3b3e1a216c697429909b244d0833a597.webp<img></p><h2>强强联合：云原生内存问题诊断闭环</h2><p></p><p><strong>为什么需要结合？</strong></p><p></p><p>看起来我们已经有了两个强大的工具 -- <strong>一个懂业务，一个懂内核</strong>。但在针对本文聚焦的云原生内存问题上，它们各自都存在一些局限性。如日常定位云原生内存相关问题时，通常也需要结合云原生和操作系统的相关专业知识来排查，这也正是我们需要将它们结合起来的原因。</p><p></p><p></p><p><strong>数据维度全面打通</strong></p><p></p><p>通过 ACK MCP 和 SysOM MCP 工具链，ACK AI 助手实现：</p><ul><li><p><strong>元数据自动关联</strong>：一次提问，AI 自动关联 Namespace → Deployment/Daemonset → Pod → Node → 实例规格，将 SysOM 的进程数据与 K8s 对象一一对应。SysOM 告诉你“是什么”（内核层面的内存异常根因结论），ACK MCP 告诉你“为什么”（K8s 配置上下文），两者结合才能形成完整的根因定位。</p></li></ul><ul><li><p><strong>日志事件指标融合</strong>：OOM 发生时自动拉取容器日志、K8s Events、Prometheus 指标、审计日志等多维度数据。SysOM 提供“当前状态”（内存分布快照），Prometheus 提供“历史趋势”（何时开始异常），审计日志提供“变更事件”（是否与发布相关），三者交叉比对才能区分“流量突发”还是“版本缺陷”。</p></li></ul><p></p><p><strong>具体问题 CASE</strong></p><p></p><p><strong>CASE 1:  kubectl top node 内存占用和节点监控不一致</strong></p><p></p><p>客户在日常巡检中发现一个让人困惑的现象：kubectl top node 显示节点内存使用率仅 60%，但云监控控制台显示该节点内存占用已达 85%，两者差异超过 20%。这种数据不一致导致团队无法准确判断节点的真实负载状态，也无法确定是否需要扩容。</p><p></p><p>传统解决方案：找到相关同学，获取具体指标的计算方式，检查计算差异，获取差异部分具体内存占用，得出数据不一致根因。</p><p></p><p>通过 ACK AI 助手：</p><p></p><p><img>https://static001.geekbang.org/infoq/32/326a40204b04d1947a2ee1d64e04a70d.png<img></p><p></p><p><img>https://static001.geekbang.org/infoq/3c/3cabdfd830cf3dfc837e60c4d3a58890.webp<img></p><p><strong>CASE 2:  Java 应用 pod 频繁 OOMKilled</strong></p><p></p><p>问题场景：一个 netty 服务在生产环境运行一段时间后，开始频繁出现 OOMKilled 重启。容器配置了 4Gi 内存 limit，JVM 堆内存设置为 `-Xmx3g`，理论上应该足够。但 Pod 仍然每隔几小时就被 OOM 终止一次，业务方抱怨服务不稳定。</p><p></p><p>传统解决方案：找到相关应用同学，通过各种各样 Java 问题排查工具，定位是哪部分内存使用不当导致；多方讨论如何改变设置或参数缓解问题。</p><p></p><p>通过 ACK AI 助手：</p><p></p><p><img>https://static001.geekbang.org/infoq/43/43f81ed73ecc081e381ca5bc3ba15cca.webp<img></p><p></p><p><img>https://static001.geekbang.org/infoq/e2/e2b1569bf9d43fa85a2398df3208d937.webp<img></p><p></p><p><strong>CASE 3:  Emptydir 使用不当导致 Pod OOMKilled</strong></p><p></p><p><strong>问题场景：</strong>一个数据处理服务的 Pod 在运行过程中突然被 OOMKilled，但应用日志中没有任何内存异常的迹象，应用本身的内存占用也远低于 limits。用户百思不得其解：明明应用没用多少内存，为什么容器还是被 OOM 了？</p><p></p><p><strong>传统解决方案：</strong>通过容器监控无法定位是哪部分内存占用导致 OOM，深入排查需要 SSH 登录节点、定位 cgroup 路径、手动解析 ，再与 Pod 配置交叉比对才能定位根因。整个过程涉及多系统切换、依赖内核经验，耗时长且门槛高。</p><p></p><p><strong>通过 ACK AI 助手：</strong></p><p></p><p><img>https://static001.geekbang.org/infoq/b1/b11a0b2350829bc75e84f77063df169a.webp<img></p><p></p><p><img>https://static001.geekbang.org/infoq/e5/e5cab5ac4141f170e20f5e30553a567d.webp<img></p><h2>总结</h2><p></p><p>通过 ACK AI 助手 + SysOM & ACK MCP 的组合，云原生内存问题从\"凭经验\"变为\"有系统、有规则、有工具\"的标准化闭环能力。</p><p></p><p>这不仅仅是两个工具的简单叠加，而是 \"云原生视角\"与\"操作系统视角\"的深度融合——让运维人员只需要一句话，就能获得从业务层到内核层的完整诊断报告和可执行建议。</p><p></p><p><strong>链接：</strong></p><p>ACK AI 助手功能说明文档：</p><p>ACK MCP 官方开源 tool 工具集：</p><p>🌟 GitHub 地址：</p><p>SysOM MCP</p><p>🌟 GitHub 地址：</p><p>操作系统控制台：</p><p></p><p><strong>联系我们 </strong></p><p>若想使用更全面的 SysOM 功能，请登录阿里云操作系统控制台体验，地址：</p><p>您在使用操作系统控制台的过程中，有任何疑问和建议，可以扫描下方二维码或搜索群号：94405014449 加入钉钉群反馈，欢迎大家扫码加入交流。</p><p><img>https://static001.geekbang.org/infoq/b2/b25287aa24b6e95b58056b5056ca0927.webp<img></p><p><size>操作系统控制台</size><size>钉钉交流群</size></p></div>",
            "link": "https://www.infoq.cn/article/GLV2qyBOst18dXj3ubDz",
            "pub_date": "2026-02-25 07:17:13",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "yWGFSIQs1Uh3LEmLIpgi",
            "title": "Cloudflare推出基于路径的边缘路由垂直微前端模板",
            "image": "https://static001.infoq.cn/resource/image/db/4e/db0ff1342ba2f5a4aa87bbeaebaf824e.jpg",
            "description": "<div><p><color>Cloudflare刚刚推出了一个面向垂直微前端（VMFE）的</color><color>。该架构可以将独立的</color><color>映射到同一域名的特定URL路径上。通过整合Service Bindings和Speculation Rules API，该模板使分散的团队能够管理自己的技术栈和CI/CD管道，同时仍然给用户带来流畅的单页应用（SPA）体验。</color></p><p><color> </color></p><p><color>这里的变化是从横向组件混合转为纵向的基于路径的所有权。本质上，如果一个团队拥有/docs路径，他们便能掌控整个纵向栈——从选择</color><color>或</color><color>等框架到管理完整的CI/CD管道——而且完全不会与管理/marketing或/dashboard的团队产生冲突。</color></p><p><color> </color></p><p><color>该技术粘合层可以归结为三个部分。服务绑定允许Router Worker直接在边缘与子应用Worker通信，通过避免使用公网来保持低延迟。然后是Router Worker本身，它充当前门，根据路径前缀引导请求。最后，HTMLRewriter会自动调整HTML响应以修复路径问题（通常出现在对服务做反向代理时），例如在图像源中添加/docs。</color></p><p><color> </color></p><p><color>为了保持连贯的用户体验，模板内置了两个现代浏览器API。首先，CSS View Transitions有助于在页面更改期间保持DOM元素（如导航栏）可见，这消除了多页应用中经常出现的“白屏”现象。此外，它使用Speculation Rules API将相关联的微前端预加载到内存中。实话实说，这目前只在基于Chromium的浏览器中有效，不过，这使得物理上相互分离的Worker之间几乎可以瞬间完成切换。</color></p><p><color> </color></p><p><color>实际上，Cloudflare自己的内部仪表板便是使用这种模型将核心功能与Zero Trust等产品分开。正如Cloudflare全栈工程师Brayden Wilmoth</color><color>：</color></p><p><color> </color></p><p><color> </color></p><p><color>向垂直微前端的转变反映了我们软件思考方式的大幅转变。在最近发表的一篇</color><color>中，亚马逊云科技首席解决方案架构师Luca Mezzalira指出，微前端应该真正关注团队自治和“流程（flow）”，而不仅仅是重用代码。他认为，端到端的垂直切片是完美的“试验场”，让团队可以处理像认证和可观察性这样的复杂问题，而不必经历“大爆炸”式迁移的噩梦。</color></p><p><color> </color></p><p><color>虽然这种架构带来了组织方面的好处，但也引入了特有的运营方面的权衡。在</color><color>中，有人发出了一个涉及基于边缘的路由计费模型的警告：</color></p><p><color> </color></p><p><color> </color></p><p><color>最后，在</color><color>，Vercel通过采用垂直方法也获得了类似的收益，将预览构建时间减少了40%，但他们也遇到了一些问题。在本地测试这些配置仍然比较麻烦，经常有些功能需要采取手动的临时措施。行业对这一理念也还存在分歧。虽然垂直切片对大型企业来说堪称救星，但许多小型团队意识到，如果开发人员少于15人，额外的架构“成本”可能得不偿失。</color></p><p></p><p><color>原文链接：</color></p></div>",
            "link": "https://www.infoq.cn/article/yWGFSIQs1Uh3LEmLIpgi",
            "pub_date": "2026-02-25 06:41:36",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "Ek2SwBQSUmCAbg9V7WWD",
            "title": "LocalStack for AWS放弃社区版引发开发者担忧",
            "image": "https://static001.infoq.cn/resource/image/db/b8/db693e2288ce1e4e42996b68aaa59ab8.jpg",
            "description": "<div><p><color>LocalStack最近宣布</color><color>，放弃了广受欢迎的开源社区版，并创建了一个需要注册的单一镜像。目前使用最新社区镜像的项目将需要更新他们的工作流程。</color></p><p><color> </color></p><p><color>在过去的几年里，LocalStack为AWS维护了两个独立的LocalStack版本：一个是根据Apache 2.0许可证开源且对社区免费提供的社区版，以及一个只能通过付费许可证访问的专业版。根据公告，LocalStack现在将这些组件合并为一个单一镜像。它将为个人和开源用户提供一个免费的基于账户的选项，并引入一个新的命令行界面（CLI v2）以支持本地云开发。LocalStack的联合创始人兼联合首席执行官</color><color>和</color><color>写道：</color></p><p><color> </color></p><p><color> </color></p><p><color>是一个流行的云服务模拟器，它在本地运行并复制了许多AWS服务，允许应用程序在不连接到实时AWS云的情况下在本地机器上开发和测试。在</color><color>的一个热门话题中，社区对此举和项目的未来表示了担忧。虽然一些开发者希望AWS有朝一日能收购LocalStack，但用户alvsanand写道：</color></p><p><color> </color></p><p><color> </color></p><p><color>用户rad15h建议：</color></p><p><color> </color></p><p><color> </color></p><p><color>在讨论替代方案和变通方法时，不同的从业者提到了</color><color>，这是一个允许模拟AWS服务的库，以及最近的</color><color>，一个本地EC2模拟器。展望未来，LocalStack将不会发布任何对社区版的进一步更新，产品增强和安全补丁只应用于新版本。Hummer和Sheganaku警告：</color></p><p><color> </color></p><p><color> </color></p><p><color>对于“娱乐性”使用AWS的开发者，有一个有限的免费计划可用，工具对学生和开源项目仍然免费。分配给工作区的CI积分数量取决于定价层级，免费计划不包括它们。在Reddit上，许多开发者质疑CI构建的积分系统，认为它是“不合理的”，LocalStack的开发者关系负责人</color><color>承认了这一挑战，并表示公司可能很快就会对其进行</color><color>。</color></p><p><color> </color></p><p><color>切换计划在3月进行，新的LocalStack for AWS将通过Docker Hub上的</color><color>单一镜像分发提供。社区版本以前版本的源代码仍然可以在</color><color>上获得，但存储库将处于非活动状态。LocalStack在AWS上的</color><color>起价为每个许可证每月39美元，按年计费。</color></p><p><color> </color></p><p><color>原文链接：</color></p></div>",
            "link": "https://www.infoq.cn/article/Ek2SwBQSUmCAbg9V7WWD",
            "pub_date": "2026-02-22 00:00:00",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "PRrDv1gQQ2JhuOp1xI9b",
            "title": "Cloudflare推出Moltworker，将自托管AI智能体带到边缘环境中",
            "image": "https://static001.infoq.cn/resource/image/29/8b/29f7559b723a99b3ea2b86f2b5a8818b.jpg",
            "description": "<div><p><color>Cloudflare推出了开源的</color><color>，支持在Cloudflare开发者平台上运行Moltbot（一款可自托管的个人AI智能体），从而不再需要专用的本地硬件。Moltbot最初名为Clawdbot，设计定位是通过聊天应用提供个人助手服务，可集成AI模型、浏览器与第三方工具，且全程由用户自主掌控。</color></p><p><color> </color></p><p><color>Moltworker将Moltbot适配到了Cloudflare Workers中，在架构上组合了入口Worker与隔离的沙箱（Sandbox）容器。Worker充当API路由与管理层，而Moltbot运行时及其各类集成则在沙箱内执行。包括对话记忆与会话数据在内的持久化状态会存储在Cloudflare R2中，解决了容器本身无状态、生命周期短的问题。</color></p><p><color> </color></p><p><color>该实现充分利用了Cloudflare Workers近期在Node.js兼容性上的增强。Cloudflare表示，对Node API更完善的原生支持减少了对变通方案的需求，让更多npm包可以不经修改直接运行。尽管Moltbot当前主要在容器中运行，但Cloudflare认为，这种更强的兼容性未来将让更多智能体逻辑可以更贴近边缘节点执行。</color></p><p><color> </color></p><p><color>Moltworker集成了多项Cloudflare服务，复刻并扩展了本地版Moltbot的体验。AI请求会经由Cloudflare AI Gateway进行路由，支持多模型厂商、集中式可观测性与多种配置选项；浏览器自动化任务通过Cloudflare Browser Rendering来处理，使Moltbot可以控制无头Chromium实例完成页面导航、表单填写与内容抓取，而无需在容器内直接运行浏览器；API与管理后台的身份认证则通过Cloudflare Zero Trust Access实现。</color></p><p></p><p><img>https://static001.geekbang.org/infoq/c6/c6bc892e6ac5b2779fd47fa818eadd7b.png<img></p><p></p><p><color>该项目在早期用户中引发了褒贬不一的反响。有人认为，基于Cloudflare托管的方案显著降低了使用门槛。Peter Choi在</color><color> 中指出，在Cloudflare上运行Moltbot有望大幅提升普及度，但同时质疑这种迁移是否会改变项目最初强调完全本地控制的核心吸引力。</color></p><p><color> </color></p><p><color>另一些用户则强调其运维优势，有的用户这样</color><color>：</color></p><p><color> </color></p><p><color>Cloudflare已经在GitHub上开源了Moltworker，并将其定位为概念验证（proof of concept），而非正式支持的产品。官方表示，该项目旨在展示其开发者平台（结合了Workers、Sandboxes、AI Gateway、Browser Rendering与存储服务）如何在边缘环境安全地、规模化地运行AI智能体。</color></p><p><color> </color></p><p><color>原文链接：</color></p></div>",
            "link": "https://www.infoq.cn/article/PRrDv1gQQ2JhuOp1xI9b",
            "pub_date": "2026-02-13 10:00:00",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "h5huIV6bVgqR2BeSNuPC",
            "title": "RFC 规范中的 CNAME 顺序问题是如何导致 Cloudflare 1.1.1.1 宕机的",
            "image": "https://static001.infoq.cn/resource/image/ec/b9/ecf572ce2475d85d246ce1yy29b9e7b9.jpg",
            "description": "<div><p><color>在一篇题为</color><color>的最新文章中，Cloudflare 解释了一个 RFC 规范表述不清的问题，是如何导致其广受欢迎的 1.1.1.1 公共 DNS 服务发生故障的。在定位问题并发现旧版 DNS 标准中关于记录顺序的模糊之处后，Cloudflare 提出了一份澄清后的规范建议。</color></p><p><color> </color></p><p><color>1 月 8 日，一次看似例行的 DNS 服务更新改变了响应中 CNAME 记录出现的顺序，导致部分 DNS 客户端在解析域名时失败，因为它们假定别名记录必须先出现。尽管大多数现代软件认为 DNS 响应中记录的顺序并不重要，但 Cloudflare 团队发现，一些实现实际上依赖 CNAME 记录必须出现在其他记录类型之前。</color></p><p><color> </color></p><p><color>当这一顺序发生变化后，DNS 解析开始失败，最终引发了 1.1.1.1 这一流行公共 DNS 服务的一次严重中断。Cloudflare 的系统工程师 </color><color> 解释了该变更引入的原因和时间点：</color></p><p><color> </color></p><p><color>当 DNS 解析器查询一个包含 CNAME 的域名时，它可能会看到一系列别名记录，将原始名称一路链接到最终的地址，并且解析器会以不同的过期时间缓存链路中的每一步。Cloudflare 指出，如果这条链中的某一部分在缓存中已过期，解析器只会重新获取过期的那一段，并与仍然有效的部分组合，形成完整的响应。Neuteboom 补充道：</color></p><p><color> </color></p><p><color>示例如下：</color></p><p><color> </color></p><p><color>虽然许多 DNS 客户端实现并不依赖记录顺序，例如 </color><color>，但也有一些实现（包括 </color><color> 中的 </color><color> 函数）在解析过程中会跟踪“期望的记录名称”，并按顺序遍历响应内容，假定在任何最终答案之前都能先遇到 CNAME 记录。Reddit 上有用户</color><color>道：</color></p><p><color> </color></p><p><color>在 </color><color>中，许多用户围绕 RFC 是否真的存在歧义展开了争论，尤其是在 RRset 与 RR 在消息分区中的细微区别上，还是说 Cloudflare 的工程师误解了规范。Patrick May 则评论道：</color></p><p><color> </color></p><p><color>在一份即将在 IETF 讨论的 </color><color> 中，Cloudflare 提议制定一份 RFC，明确规定 DNS 响应中应如何正确处理 CNAME 记录。</color></p><p><color> </color></p><p><color>根据公开的时间线，Cloudflare 于 1 月 7 日开始全球部署，并在 1 月 8 日 17:40（UTC）覆盖了 90% 的服务器。公司随后宣布发生事故，并于 1 月 8 日 18:27 开始回滚变更，最终在 19:55 完成回滚。</color></p><p></p><p><strong>原文链接：</strong></p><p>https://www.infoq.com/news/2026/02/cname-rfc-cloudflare-outage/</p></div>",
            "link": "https://www.infoq.cn/article/h5huIV6bVgqR2BeSNuPC",
            "pub_date": "2026-02-12 10:00:00",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "5dsQgAfhRJSyvZNtZWCh",
            "title": ".NET 10现已在AWS Lambda上作为托管运行时和基础镜像提供",
            "image": "https://static001.infoq.cn/resource/image/6b/0e/6bf74826f58c31d0af5115fa287e030e.jpg",
            "description": "<div><p><color>亚马逊云科技宣布，AWS Lambda现在已经</color><color>使用.NET 10创建无服务器应用程序。通过这次更新，在构建和运行Lambda函数时，开发者可以将.NET 10作为托管运行时和基于容器的镜像来使用。</color></p><p><color> </color></p><p><color>按照亚马逊云科技的说法，当有新版本发布时，托管运行时和基础镜像会自动更新，不需要开发团队手动维护。</color></p><p><color> </color></p><p><color>是.NET平台最新的长期支持版本，在2028年11月之前会一直提供安全更新和Bug修复。通过在AWS Lambda上提供.NET 10，亚马逊云科技旨在使开发者能够在无服务器环境中使用平台的最新特性。这包括支持基于文件的应用程序，旨在简化应用程序结构和开发工作流。</color></p><p><color> </color></p><p><color>此次发布还增加了对</color><color>的支持。这项能力使Lambda函数能够在Amazon EC2实例上运行，同时保留通常与无服务器计算相关的操作模型。亚马逊云科技表示，这个选项旨在提供更多的灵活性，包括潜在的成本效益和对专用计算资源的访问权限，同时减少通常与服务器管理相关的运营开销。</color></p><p><color> </color></p><p><color>此外，Powertools for AWS Lambda (.NET)是一个旨在帮助开发者遵循无服务器最佳实践并提高开发速度的工具包，现在也已提供.NET 10支持。开发者可以继续使用亚马逊云科技提供的各种工具来部署和管理他们的应用程序，包括Lambda控制台、AWS Command Line Interface、AWS Serverless Application Model、AWS Cloud Development Kit和AWS CloudFormation。</color></p><p><color> </color></p><p><color>正如官方公告所言，.NET 10运行时可以在所有AWS区域中使用，包括AWS GovCloud（美国）区域和中国区域。</color></p><p><color> </color></p><p><color>社区对这一公告表现出了很大的热情，并进行了技术探讨。</color><color>们既充满期待又带着务实的好奇，众多评论聚焦于.NET 10带来的全新的基于文件的应用开发体验。有社区成员表示，一旦基于文件的应用编辑能和常规JavaScript工作流一样流畅，他们会“欣喜若狂”。</color></p><p><color> </color></p><p><color>还有一些人讨论了构建工具、使用当前的CLI方法所需的部署步骤，以及可能对冷启动性能产生的影响。从这些讨论中可以看出，总体而言，.NET开发者对这个扩展的无服务器选项是认可的，并且对未来改进Lambda工具和编辑器支持也很感兴趣。</color></p><p><color> </color></p><p><color>亚马逊云科技还发布了</color><color>，演示如何在AWS Lambda中使用新的.NET 10运行时。该文通过一个示例展示了如何创建、配置和部署基于.NET 10的Lambda函数，并解释了可用的运行时和部署选项。</color></p><p></p><p><img>https://static001.geekbang.org/infoq/f6/f690f77c19f2e2b5793a499a5fe9a5a3.png<img></p><p></p><p><color>Lambda控制台的创建函数页面，图片来源：</color></p><p><color> </color></p><p><color>根据亚马逊云科技的说法，该示例旨在帮助开发者利用他们提供的标准工具在现有的无服务器工作流中采用.NET 10。</color></p><p><color> </color></p><p><color>亚马逊云科技的官方文档和公告材料中提供了</color><color>和其他一些细节，感兴趣的读者可以进一步阅读。</color></p><p><color> </color></p><p><color>原文链接：</color></p></div>",
            "link": "https://www.infoq.cn/article/5dsQgAfhRJSyvZNtZWCh",
            "pub_date": "2026-02-10 00:51:55",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        },
        {
            "id": "fdGoAsQ91o7rDIGiOsrd",
            "title": "AI时代的分野与合流：什么才是算力选型的“版本答案”？",
            "image": "https://static001.infoq.cn/resource/image/84/6f/84ca4d0b0363854a5970bc9a0bb55b6f.jpg",
            "description": "<div><p>当 AI 大模型从实验室冲向产业一线，企业的算力需求正经历一场前所未有的“撕裂式分化”：一边是 3A 游戏、AI 渲染等场景对极致性能的“军备竞赛”，一边是 Web 服务、视频转码等高频场景对性价比与能效比的“精打细算”，电力成本的飙升与数据安全的红线，更让这场算力抉择变成“既要又要还要”的多重考验。</p><p></p><p>过去“一套拳法打天下”的时代早已落幕，当行业还在为“性能优先”还是“成本优先”争论不休时，英特尔与腾讯云的联合实践给出了不一样的答案。在最新一期《C 位面对面》栏目中，InfoQ 极客传媒创始人 &CEO 霍太稳和英特尔数据中心与人工智能集团副总裁兼中国区总经理陈葆立、腾讯云 CVM 产品副总经理李德铠的深度对话，揭开了算力“分野与合流”的核心逻辑——以芯片双架构为底层支撑，以分层云实例为落地载体，让高性能与普惠性不再对立，让软硬件协同成为破解行业痛点的关键钥匙。</p><p></p><h2>算力分化时代的三重困局</h2><p></p><p>数字化与智能化的加速，让企业算力需求的分化从隐性走向显性，而 AI 技术的爆发则让这种分化演变成不可调和的多重矛盾，倒逼行业从“大一统”走向“精细化”。</p><p></p><h2>性能与能效的对立统一</h2><p></p><p>“AI 算力的尽头其实是电力”，李德铠的这句话点破了行业核心困境。随着大模型参数指数级增长，电力成本在算力总支出中的占比已攀升至极高水平，单纯追求极致性能的算力配置，往往会陷入“高能耗、高成本”的恶性循环。但另一方面，GenAI、游戏等场景，又对算力的主频、内存带宽和并行计算能力提出了苛刻要求，性能短板直接影响用户体验。</p><p></p><p>这种矛盾催生了算力需求的分层：一部分场景需要“火力全开”，另一部分场景则需要“精打细算”。陈葆立补充道：“这种分化不是短期现象，而是 AI 时代的长期趋势。”</p><p></p><h2>安全与生态的刚性需求</h2><p></p><p>除了性能与成本，数据安全与生态适配也成为企业算力选型的“必选项”。随着数据资产价值的提升，企业对数据存储、传输、计算全流程的安全要求越来越高，而算力解决方案能否与现有生态无缝对接，直接影响部署效率与迁移成本。陈葆立强调：“企业需要的不仅是算力本身，更要构建完整的安全防护体系和生态支持。”</p><p></p><h2>通用与专用的场景分化</h2><p></p><p>过往企业依赖一套通用架构解决所有问题的模式，在 AI 时代也彻底失效。不同业务场景的算力诉求呈现出显著差异：3A 游戏需要单核高主频保障操作无延迟，视频转码需要高并发处理能力降低成本，AI 推理需要矩阵运算加速提升效率，Web 服务需要稳定性能避免抖动。</p><p></p><p>场景的细分要求算力供给必须“精准匹配”，而非“大水漫灌”。腾讯云与英特尔的合作，正是抓住了这一核心趋势，推出针对性的产品组合，让不同场景都能找到“量身定制”的算力解决方案。</p><p></p><h2>双轨破局：从芯片到云实例的协同革命</h2><p></p><p>面对算力撕裂的三重困局，英特尔与腾讯云的联合创新并非简单的产品叠加，而是从芯片架构到云实例、从硬件优化到软件协同的全链路重构，构建起“性能 + 普惠”的双轨算力体系。</p><p></p><p>实际上，英特尔在最新的至强®6 处理器中推出双架构设计，便是应对算力需求分化的破题关键。“一个是性能核 P-core，另一个是能效核 E-core，我们希望通过两种不同的处理器架构，提供不同的算力服务于客户。”陈葆立介绍道。</p><p></p><p>其中，性能核 P-core 主打极致性能，具备高主频、大缓存、高内存带宽等特性，完美适配 AI 训练、高性能计算等核心场景；能效核 E-core 则聚焦高内核密度与更优每瓦性能，通过精简设计，在保证性能的同时降低功耗，特别适合云原生、高并发等普惠型场景。</p><p></p><p>基于英特尔至强®6 的双架构，腾讯云打造了 S9E、S9Pro、S9 三款分层实例：其中 S9E 与 S9Pro 主打极致性能，搭载至强®6 P-core，专为 AI、游戏、图像渲染等高性能场景而生；S9 实例则是全球首发搭载至强®6 E-core 的 SRF-AP 云实例，主打高性价比与高并发适配。</p><p></p><h2>高性能场景：CPU 与 GPU 如何“1+1＞2”？</h2><p></p><p>在 RAG（检索增强生成）等高性能场景中，行业曾普遍认为 GPU 能包揽所有核心任务，CPU 并无用武之地，但基于英特尔至强®6 P-core 的 S9E/S9Pro 用实践打破了这一认知。</p><p></p><p>“进入大模型时代，GPU 和 CPU 有各自的优势——GPU 算力强，CPU 内存大。如果以篮球队为例，CPU 就像控球后卫，既可以传球给 GPU 前锋，也能自己得分。”陈葆立表示。</p><p></p><p><strong>一方面，作为“控球后卫”，CPU 能帮助 GPU 更好的释放性能。</strong> 陈葆立表示：“大模型就像记忆力不好的天才，无法在 GPU 中存储大量用户上下文。但是如果通过 CPU 与系统内存的协同，就能最大化发挥 GPU 的能力。”</p><p></p><p>例如，在 RAG 场景中，借助 CacheClip 技术，能够有效提升 KVCache 的利用率，从而支持更长的上下文窗口并提高执行效率；另外，通过英特尔推出的异构计算框架 HeteroFlow，能够将 MoE 模型中的“冷专家”模块直接卸载至 CPU 处理（卸载、调度、加速三管齐下），让 GPU 的工作更聚焦，从而突破显存瓶颈，为用户带来更高的整体性能。</p><p></p><p>“许多客户在 TTS、ASR、OCR 等预处理任务上的日常支出，甚至达到后续大模型推理费用的数十倍。这些 AI 工作的前置准备阶段，以前常常要 GPU 分心兼顾。AI 工作负载里的非结构化数据解析、格式转换、特征清洗，看着是‘细活’，实则要高并行逻辑和高 I/O 吞吐，正好是机头 CPU 的强项。更重要的是：数据预处理通常具有流程复杂、数据量巨大、需弹性扩展、实时性要求低但吞吐量极高等特点。而这些需求，恰恰与至强®6 的架构优势高度契合。CPU 把预处理扛了，GPU 就不用在训练推理这样的核心任务和预处理这种边缘任务之间来回切换，算力与时间一点儿都不浪费。”陈葆立解释道。</p><p></p><p>“这种 1+1>2 的组合拳，不仅帮客户解决了 GPU 资源紧张的燃眉之急，更通过更优的部署成本和更低的系统延迟，实现了全链路的性能提升。”李德铠补充道。</p><p></p><p><strong>另一方面，CPU 本身也能在 AI 场景“上大分”。</strong> 英特尔至强®6 P-core 集成了 AMX 加速引擎，专为大规模 AI 训练和推理工作负载提供支持，能够助力客户提高效率，降低推理、训练和部署成本以及降低总拥有成本 (TCO)。值得一提的是，由于 AMX 是直接集成在 CPU 内核上且靠近系统内存的内置加速器，相比于独立加速器，它能提供更便捷、更快速的加速支持。</p><p></p><p>“利用 AMX 矩阵加速能力，S9e/S9pro 可以非常高效地处理 Embedding（向量嵌入）、数据清洗和中小型模型的推理任务。”李德铠举例称。腾讯云实测数据显示，在千问 4B 小模型的 Embedding 场景中，搭载英特尔至强®6 P-core 的 S9E/S9Pro 相比 T4 GPU 卡，性能提升了 25%，综合性价比直接提升了 66%。</p><p></p><p>当然，在游戏对战服、AI 渲染和图像处理等传统高性能场景中，S9E/S9Pro 凭借着高主频和高内存带宽等特性，也成为了“客户的优选”。“玩家 PK 时的实时响应至关重要，S9E/S9Pro 能保障数据传输的高带宽和低延迟，让操作指令即时生效不卡顿。”李德铠介绍道，“此外，在 AI 渲染和图像处理场景中，S9E/S9Pro 的多线程核与高内存带宽，也能帮助客户企业快速处理海量数据，大幅提升渲染效率，缩短项目周期。”</p><p></p><h2>普惠场景：如何实现“性能无抖动、满载不降频”？</h2><p></p><p>“普惠不代表性能不行，搭载至强®6 E-core 的 S9 相比上一代实例性能提升了 15%-20%，能稳定支撑 Web 服务、小程序等轻负载场景的高并发需求。”李德铠强调。</p><p></p><p>“性能无抖动、满载不降频”的背后是英特尔与腾讯云在设计细节上的不妥协。</p><p></p><p>“我们首先肯定不希望普惠版的云实例在性能上缩水。”陈葆立表示。硬件层面，英特尔在 E-core 中关闭了超线程功能，让每个虚拟机拥有独立的物理核、显存和内存，避免用户间的性能干扰，保障性能稳定无抖动。“另外，能效核（E-core）顾名思义它的能效比是非常好的，也就是在性能更优的同时功耗更低，这也符合国家倡导的节能减碳以及绿色数据中心等理念。”</p><p></p><p>软件与优化层面，腾讯云也做了非常多用户“看不见”的工作。其中最关键的就是“绑核设计”——将 CPU 核心与虚拟机绑定，确保单个虚拟机高负载运行时，不影响整片 CPU 的性能表现；同时优化了 CPU 与总线、内存的搭配关系，进而缩短了数据传输路径，提升了计算效率。“‘绑核设计’对于计算密集型任务的提升非常明显。”李德铠补充道。</p><p></p><p>这种软硬件协同的优化，让 S9 在教育行业大受欢迎。教育机构的录播视频课程通常需要转码为不同码率，以适配不同网络环境，S9 实例搭配英特尔软件库后，转码性能获得了 90% 以上的提升，在降低成本的同时，保障了课程传输的流畅性。</p><p></p><p>“S9 的高并发适配能力，也使其在 Web 服务和小程序场景中备受青睐。很多客户反馈，S9 能稳定支撑高峰期的并发请求，且成本比传统实例更低。”李德铠补充道。</p><p></p><p>此外，基于英特尔至强®6 E-core 的 S9 云实例，在腾讯内部的超大规模业务中，也得到了普遍验证。</p><p></p><p>以微信存储为例，不仅通过高 I/O 实例配置的使能以及软件优化，高效解决了 Gen5 SSD 高吞吐性能所带来的存储压力，还通过英特尔 QAT（数据保护与压缩）加速器，使得存储压缩效率提升了 70%，真正实现了“用更少空间存更多数据”。</p><p></p><p>在搜索业务领域，腾讯新一代海量搜索引擎借助 SRFAP 平台能力，使得元宝的搜索性能提升了 15%。另外，在大数据业务中，S9 实例的多核并行能力与扩展性，也帮助腾讯实现了显著的降本增效。</p><p></p><p>产品成功的背后，是双方更深层次的战略共识。</p><p></p><p>“我们双方的合作已经超越了简单的买卖关系，上升到了联合定义产品的高度。腾讯的宗旨是一切以用户价值为依归，英特尔则以客户场景为核心，双方的价值观高度契合。我们不会盲目追求单纯的技术参数，而是先去听市场和用户的声音，再回过头来定义产品。”李德铠表示。</p><p></p><p>这种契合体现在合作的全流程：从芯片设计阶段，英特尔就与腾讯云紧密沟通，了解最终用户的实际需求，定制化设计芯片；在产品定义阶段，双方共同规划了三款实例的定位，确保硬件架构与场景需求精准对接；在技术优化阶段，双方专家联合研发，充分发挥 AMX、QAT 等指令集的优势，将好钢用在刀刃上，真正让技术红利转化为客户价值。</p><p></p><h2>AI Agent 引爆的算力“新战场”</h2><p></p><p>谈及未来，李德铠表示：“AI 的技术热潮已经从模型向 Agent（智能体）演进，这将带来算力需求的新变化。”</p><p></p><p>在 AI 发展的早期，算力资源几乎全部向“模型训练”倾斜，但随着 AI Agent 时代的到来，这种天平正在发生逆转——从“重训练”转向“重推理”。“据专家预测，未来推理算力的需求将达到现在训练算力的 10 倍。”陈葆立指出。如果说训练主要是 GPU 的“大力出奇迹”，那么 Agent 架构中的各种推理需求则让 CPU 的角色将变得空前重要。</p><p></p><p>“Agent 的本质是‘大脑 + 工具’。GPU 负责思考，而 CPU 负责执行（比如运行 Python 代码、查询数据库、读写文件、网络通信等），每一步推理后，CPU 都要介入处理非线性逻辑，这会导致 CPU 的负载大幅增加。腾讯云第九代云实例及至强®6 平台的设计，正是致力于通过更高性能、更优能效的通用算力，帮助客户应对推理与 Agent 负载带来的计算密度挑战。”李德铠表示。</p><p></p><p>同时，“算力即财富”的 AI 时代也对系统的稳定性、可靠性提出了更高的要求。随着 AI 集群正加速向万卡规模突破，系统越复杂，计算密度越高，就越可能出现更多的静默数据错误。</p><p></p><p>陈葆立指出，至强®6 具备 99.999% 的 RAS（可靠性、可用性、可维护性），能够全面保障整体系统的稳定运行；同时其内置的 TDX 技术，能够为云服务提供硬件级可信执行环节，有效支持通用机密计算和异构机密计算，助力构建端到端的可信 AI 服务能力。</p><p></p><p>“TDX 技术，帮助我们在云上打造了一个‘数据保险箱’，企业可以无缝地把它的 AI 模型、Agent 应用部署到 S9 系列实例上，来确保模型与数据的安全。”李德铠补充道。</p><p></p><p>此外，AI 应用的大爆发也将进一步催生数据海量吞吐的需求，对内存、SSD 等部件厂商提出了更高的要求，也对生态适配提出了新挑战。“英特尔作为平台方，一直以来保持着‘生态联盟’的方式，跟伙伴厂商保持密切互动、相互验证，以确保整个平台生态的高质量、高安全、高可用。”陈葆立表示。</p><p></p><p>据介绍，英特尔最新的 18A 制程工艺已进入量产阶段，性能提升可达 15%，密度提升 30%。基于 18A 制程的至强®6 Plus 处理器（Clearwater Forest）将于 2026 年内发布，目前英特尔已经与部件厂商、腾讯云等合作伙伴展开了早期的适配与验证工作。</p><p></p><p>“下一步，随着英特尔 18A 等革命性制程工艺的推进，我们也会在第一时间推出结合下一代芯片性能的云实例。同时，我们正在紧锣密鼓地研发适配 vRDMA 网络的新一代 CVM 机型，这将进一步释放底层硬件的传输潜力。此外，在加密计算、可信计算等对安全性要求极高的垂类场景，我们也会持续演进，利用最新的指令集优势，为企业数字化转型和 AI 应用的全面落地提供一个更高效、更安全、更具性价比的底座。”李德铠表示。</p><p></p><h2>结语</h2><p></p><p>算力的分野与合流，本质上是 AI 产业从“技术狂欢”走向“价值落地”的必然。当狂热褪去，企业终将回归理性：算力的核心竞争力，从来不是参数的堆砌，而是对场景需求的精准响应与资源的最优配置。</p><p></p><p>英特尔与腾讯云的双轨实践，撕开了行业“非黑即白”的选型困局：性能核与能效核的二元架构，消除了“杀鸡用牛刀”的尴尬；CPU 与 GPU 的异构协同，打破了“谁主谁次”的偏见；分层实例的场景适配，终结了“一套方案包打天下”的粗放。这不是简单的产品组合，而是对算力分配逻辑的底层重构，让每一份算力投入都能匹配对应的业务价值，让技术创新真正服务于成本与效率的平衡。</p><p></p><p>AI Agent 时代的到来，将会让这种精准匹配的需求愈发迫切。推理算力的爆发式增长、多模态场景的复杂诉求，会进一步放大“按需分配”的重要性。而英特尔与腾讯云的合作，早已提前卡位这一趋势：从芯片到实例，从硬件到软件，构建起了一套“场景定义技术”的完整闭环。</p><p></p><p>AI 时代的算力革命，终将是一场“以场景为锚、以协同为纲”的效率革命，谁能更深刻地洞察不同业务的算力痛点，谁能更高效地整合软硬件资源形成精准解决方案，谁就能掌握 AI 落地的核心话语权。那些真正能够破解“既要又要还要”困局的玩家，才能成为最终的规则制定者。</p><p></p><p></p><p>点击链接  观看完整视频。</p><p></p></div>",
            "link": "https://www.infoq.cn/article/fdGoAsQ91o7rDIGiOsrd",
            "pub_date": "2026-02-06 09:00:00",
            "source": "infoq",
            "kind": 1,
            "language": "zh-CN"
        }
    ]
}