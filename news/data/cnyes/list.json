{
    "data": [
        {
            "id": 6355139,
            "title": "白宮：已邀集亞馬遜、微軟等科技巨頭 簽署AI用電自理協議",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p>美國總統川普周二 (24 日) 的國情咨文演講中，針對人工智慧引發的電力危機提出重大政策，要求開發 AI 的科技巨頭必須「自行解決電力需求」。白宮隨後證實，包括亞馬遜 (<a data-ga-click-item=\"USS:AMZN:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://invest.cnyes.com/usstock/detail/AMZN\" rel=\"noopener noreferrer\" target=\"_self\">AMZN-US</a>)、Google(<a data-ga-click-item=\"USS:GOOGL:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://invest.cnyes.com/usstock/detail/GOOGL\" rel=\"noopener noreferrer\" target=\"_self\">GOOGL-US</a>)、Meta(<a data-ga-click-item=\"USS:META:STOCK:ETF\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://invest.cnyes.com/usstock/detail/META\" rel=\"noopener noreferrer\" target=\"_self\">META-US</a>)、微軟 (<a data-ga-click-item=\"USS:MSFT:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://invest.cnyes.com/usstock/detail/MSFT\" rel=\"noopener noreferrer\" target=\"_self\">MSFT-US</a>)、Oracle(<a data-ga-click-item=\"USS:ORCL:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://invest.cnyes.com/usstock/detail/ORCL\" rel=\"noopener noreferrer\" target=\"_self\">ORCL-US</a>)、OpenAI 及 xAI 在內的企業領導人，將於 3 月 4 日前往白宮正式簽署「費率支付者保護承諾」。</p></section><p></p><div class=\"c1hvmcli\"><figure><div class=\"iirgi4a\"><img alt=\"cover image of news article\" src=\"https://cimg.cnyes.cool/prod/news/6355139/l/0d5f8a41f9e3af77dceb9dcf453f4bb5.jpg\"/></div><figcaption class=\"c1gcnfq1\">白宮：已邀集亞馬遜、微軟等科技巨頭 簽署AI用電自理協議(圖:shutterstock)</figcaption></figure></div><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>這項政策的核心在於，建設超大規模 AI 資料中心的科技公司，未來必須自行建造、引進或購買專屬電力供應，而非直接從現有的公共電網抽取電力。川普直言，美國目前的電網設備老舊，根本無法負荷 AI 發展所需的龐大電量。</p></section><section>\n</section><section style=\"margin-top:30px\"><p>根據估計，美國資料中心的電力需求在 2018 至 2024 年間已翻倍，預計到 2028 年將再增長 3 倍，這已導致部分地區電價飆升。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>川普強調，此舉是為了確保美國家庭的電費不會因 AI 競爭而增加，甚至在某些情況下能降低社區電價。事實上，微軟與 OpenAI 等公司此前已提出類似的自發性承諾，Anthropic 則表示願意支付 100% 的電網升級費用，以換取連接資料中心的權利。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>這項轉向「自給自足」的電力政策，被市場視為電力設備行業「超級牛市」的開端。隨著資料中心從單純的電力消費者轉型為「能源基礎設施投資者」，市場對燃氣輪機、變壓器、不斷電系統 (UPS) 及微型電網的需求預計將迎來噴發。西門子 (Siemens) 與 GE Vernova 等電力基礎設施巨頭，已因資料中心電力需求強勁而上調了獲利預期。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>然而，法律專家對此持保留態度。哈佛電力法律倡議組織指出，總統難以單方面改變由聯邦與各州監管機構管轄的電力合約，且目前該承諾缺乏具體的強制執行細節。</p></section><section style=\"margin-top:30px\">\n</section></main>",
            "link": "https://news.cnyes.com/news/id/6355139",
            "pub_date": "2026-02-26 18:50:03",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355308,
            "title": "台股創新高散戶活躍，科技與黃金市場動態持續引發關注",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><div class=\"summary-content\"><h3>台股創新高散戶活躍，科技與<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>市場動態引發關注</h3>\n<div class=\"highlight\">\n台股因散戶投資熱潮而創下歷史新高，證券劃撥存款餘額激增，顯示市場信心強勁，M1B與M2年增率重現<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>交叉，散戶成交占比達56.2%<a href=\"https://news.cnyes.com/news/id/6354907\">[1]</a>。經濟部長龔明鑫對於可能影響半導體產業的晶片國安法持保留態度，擔心過度限制將導致研發中心外移，削弱台灣技術優勢，並強調現行投審機制已足夠<a href=\"https://news.cnyes.com/news/id/6355130\">[2]</a>。在全球科技競爭加劇的背景下，台灣需平衡市場活力與產業發展，以維持其在半導體領域的競爭力。\n</div>\n<div class=\"highlight\">\n根據TrendForce的分析，受原物料與人工成本上漲影響，2026年第一季UV LED市場規模將突破2億美元，年增長至少10%，顯示出光固化、美黑及醫療需求的穩定增長<a href=\"https://news.cnyes.com/news/id/6355128\">[3]</a>。此外，財商進化的思維模式也在改變個體的資產管理方式，透過資源整合與策略佈局，實現資產的非線性增長，強調資金應如員工般為自己工作，並主動創造現金流<a href=\"https://news.cnyes.com/news/id/6355148\">[4]</a>。這些趨勢不僅反映出市場需求的多樣化，也顯示出個體在財務管理上的進步，未來將持續影響相關產業的發展動能。\n</div>\n<div class=\"highlight\">\n在2月26日，台股創下1.13兆元的成交量，顯示市場活躍度提升，但三大法人合計賣超139億元，外資更是賣出台積電 (<a data-ga-click-item=\"TWS:2330:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/2330\" rel=\"noopener noreferrer\" target=\"_self\">2330-TW</a>) 6.1萬張，反映出市場對於短期波動的謹慎態度<a href=\"https://news.cnyes.com/news/id/6355038\" target=\"_blank\">[5]</a>。同時，方舟投資的伍德大舉加碼AI概念股，顯示其對人工智慧的長期看好，特別是在Figma和DoorDash等新興科技公司的投資，表明市場對於科技創新的信心仍然強勁<a href=\"https://news.cnyes.com/news/id/6354485\" target=\"_blank\">[6]</a>。這種資金流向的變化，可能暗示著投資者在尋求穩健成長的同時，也在積極布局未來的科技趨勢。\n</div>\n<div class=\"highlight\">\n致伸 (<a data-ga-click-item=\"TWS:4915:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/4915\" rel=\"noopener noreferrer\" target=\"_self\">4915-TW</a>) 於法說會中強調車用市場及新感測技術的長期成長潛力，預計將透過與全球汽車品牌的直接合作成為未來的核心成長引擎，並在2024年第4季開始貢獻人工智慧感測技術的營收<a href=\"https://news.cnyes.com/news/id/6355040\">[7]</a>。同時，廣達 (<a data-ga-click-item=\"TWS:2382:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/2382\" rel=\"noopener noreferrer\" target=\"_self\">2382-TW</a>) 公布2025年財報，受益於AI伺服器的需求，全年稅後純益達19.45元，並決議配發每股15.6元現金股利，顯示出強勁的資本回報能力<a href=\"https://news.cnyes.com/news/id/6354906\">[8]</a>。隨著AI伺服器市場的快速增長，廣達的營收結構將持續優化，整體伺服器營收比重將提升至80%，顯示出科技產業在未來的投資潛力。\n</div>\n<div class=\"highlight\">\n<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>市場重拾漲勢，價格回升至每盎司5200美元，分析師指出若延續過往牛市表現，金價有望在10月衝向6750美元，這一趨勢受到全球債務及央行持續買盤的支撐<a href=\"https://news.cnyes.com/news/id/6354415\">[9]</a>。同時，華新 (<a data-ga-click-item=\"TWS:1605:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/1605\" rel=\"noopener noreferrer\" target=\"_self\">1605-TW</a>) 雖然本業虧損，但業外收益使稅後純益達10.14億元，顯示出在不銹鋼市場復甦及金屬原物料價格上升的背景下，企業仍具備一定的抗壓能力<a href=\"https://news.cnyes.com/news/id/6355141\">[10]</a>。這些現象反映出在不確定的地緣政治及美元走強的環境中，資本市場對於<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>及金屬類資產的需求仍然強勁，未來可能持續吸引投資者的關注。\n</div>\n<div class=\"highlight\">\n圓裕 (<a data-ga-click-item=\"TWG:6835:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/6835\" rel=\"noopener noreferrer\" target=\"_self\">6835-TW</a>) 公布2025年財報，儘管全年營收達23.8億元，但稅後純益大幅減少76.3%至6376萬元，每股純益僅0.97元，並擬配發現金股利1元，顯示其面臨營運挑戰<a href=\"https://news.cnyes.com/news/id/6355138\">[11]</a>。相對於圓裕的表現，同泰 (<a data-ga-click-item=\"TWS:3321:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/3321\" rel=\"noopener noreferrer\" target=\"_self\">3321-TW</a>) 和嘉聯益 (<a data-ga-click-item=\"TWS:6153:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/6153\" rel=\"noopener noreferrer\" target=\"_self\">6153-TW</a>) 去年均出現虧損，未配發股利，顯示行業整體困境。另一方面，中鋼 (<a data-ga-click-item=\"TWS:2002:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/2002\" rel=\"noopener noreferrer\" target=\"_self\">2002-TW</a>) 也因鋼鐵生產成本高企，1月自結稅前淨損8579萬元，營業淨損達7318.4萬元，儘管營收小幅增長，但終端需求尚未全面回溫，顯示鋼市復甦仍需時日<a href=\"https://news.cnyes.com/news/id/6355041\">[12]</a>。整體而言，電子及鋼鐵產業面臨的挑戰反映出市場需求的不確定性，未來需密切關注成本控制及需求回暖的進展。\n</div></div></section><p></p><section style=\"margin-top:30px\"><p class=\"signature\">Powered by <a href=\"https://www.yushan.ai/\" target=\"_blank\">Yushan.AI</a></p></section></main>",
            "link": "https://news.cnyes.com/news/id/6355308",
            "pub_date": "2026-02-26 18:45:02",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355309,
            "title": "美股AI熱潮與南韓科技股強勁反彈，新興市場信心上升",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><div class=\"summary-content\"><h3>美股AI投資熱潮與新興市場信心提升，南韓科技股強勁反彈</h3>\n<div class=\"others\">\n「木頭姐」伍德對人工智慧的信心再度升溫，透過方舟投資大舉加碼Figma、DoorDash及AMD等AI概念股，顯示其對未來科技創新的堅定看法<a href=\"https://news.cnyes.com/news/id/6354485\" target=\"_blank\">[1]</a>。同時，美國最高法院推翻川普政府的關稅政策，促使企業積極評估可申請的退稅金額，並引發套利潮，部分公司選擇提告追求全額退款，或出售關稅退稅請求權以提前變現。這一動態吸引了華爾街投行的關注，儘管市場規模尚小，但需求顯著上升<a href=\"https://news.cnyes.com/news/id/6354490\" target=\"_blank\">[2]</a>。這些趨勢不僅反映出市場對科技創新及政策變動的敏感度，也顯示出投資者在不確定環境中尋求機會的靈活性。\n</div>\n<div class=\"others\">\n小米 (<a href=\"https://www.cnyes.com/hkstock/quote/01810\">01810-HK</a>) 創辦人雷軍宣布未來五年將投入2000億元<a href=\"https://invest.cnyes.com/forex/detail/cnyusd\">人民幣</a>於晶片、AI及作業系統等核心技術，這一策略不僅是對千億研發計畫的延續，更是小米打破供應鏈依賴、提升高端市場競爭力的關鍵舉措，顯示出中國科技企業在全球競爭中的轉型挑戰<a href=\"https://news.cnyes.com/news/id/6354044\" target=\"_blank\">[3]</a>。此外，花旗集團指出新興市場因經濟增長及美元走軟而成為2023年投資亮點，MSCI新興市場股票指數創歷史新高，顯示投資者對這些市場的信心增強，尤其是在亞洲及拉丁美洲的股票多頭部位增加。儘管市場因AI憂慮出現波動，但新興市場資產依然表現穩健，<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>作為穩定性資產的需求也持續上升<a href=\"https://news.cnyes.com/news/id/6354417\" target=\"_blank\">[4]</a>。\n</div>\n<div class=\"others\">\n南韓股市今日表現強勁，綜合股指KOSPI收於6307.27點，漲幅達3.69%，主要受益於科技股的強勁表現，特別是三星電子和SK海力士的顯著上漲，顯示出AI需求對晶片產業的正面影響<a href=\"https://news.cnyes.com/news/id/6354416\" target=\"_blank\">[5]</a>。南韓央行維持基準利率於2.5%不變，並首次發布「點陣圖」，預示利率將在8月前保持穩定，這一決策反映出對經濟成長的樂觀看法，尤其是半導體出口的強勁動能<a href=\"https://news.cnyes.com/news/id/6354433\" target=\"_blank\">[6]</a>。然而，南韓公正交易委員會對電商巨頭Coupang的重罰，揭示了其在供應鏈管理上的不當行為，可能對市場信心造成影響<a href=\"https://news.cnyes.com/news/id/6354477\" target=\"_blank\">[7]</a>。在全球貿易環境不確定性加劇的背景下，美國新關稅政策對歐盟商品的影響也引發關注，這可能進一步影響南韓的出口市場<a href=\"https://news.cnyes.com/news/id/6353672\" target=\"_blank\">[8]</a>。整體而言，南韓市場在科技股的推動下展現出強勁的增長潛力，但需警惕外部貿易環境的變化及內部市場的挑戰。\n</div></div></section><p></p><section style=\"margin-top:30px\"><p class=\"signature\">Powered by <a href=\"https://www.yushan.ai/\" target=\"_blank\">Yushan.AI</a></p></section></main>",
            "link": "https://news.cnyes.com/news/id/6355309",
            "pub_date": "2026-02-26 18:45:03",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355149,
            "title": "國旅最新住房價日均「2984元」 觀光署：近8成房價低於平均值",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p>國旅過去因住宿價位，遭國人放大檢視，據交通部觀光署今 (26) 日統計，去 (2025) 年國內旅宿業整體住客人次達 8,209 萬人次，較前 (2024) 年的 7,879 萬人次增加約 329 萬人次，亦高於 2019 年 (疫情前) 水準，旅館業 (含觀光及一般旅館) 平均每晚房價為 2,984 元，從市場分布來看，約 79% 旅館房價低於平均水準。</p></section><p><template id=\"P:1\"></template></p><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>觀光署指出，從 2025 年住宿人口次觀察，去年 8,209 人次不僅高於去年，也高於 2019 年的 7,981.2 萬人次，顯示住宿市場規模已恢復並超越疫情前水準。</p></section><section>\n</section><section style=\"margin-top:30px\"><p>從客源結構觀察，觀光署表示，去年本國籍住客人次為 6,132.9 萬人次，較 2024 年 5,986.8 萬增加約 146 萬人次，較 2018 年的 5,153 萬增加約 980 萬人次；外國籍住客為 2,076.1 萬人次，較 2024 年增加約 183 萬人次，顯示國內外住宿需求均持續回升，整體市場已由疫情後復甦階段，逐步邁入穩定發展階段。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>在價格部分，觀光署統計 2025 年平均房價為<a href=\"https://invest.cnyes.com/forex/detail/usdtwd\">台幣</a> 2,984 元，較 2024 年增率 0.81%；民宿平均房價為 2,438 元，年增 1.37%，整體漲幅相較前期已趨於平穩，約 79% 旅館房價低於平均水準，顯示住宿價格帶分布多元，消費者可依預算與需求進行選擇。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>在供給面方面，合法民宿房間由 2023 年的 49,007 間增加至 2025 年的 53,628 間，3 年累計成長 9.43%，顯示旅宿供給穩定擴張。在供給持續增加的背景下，統計近 3 年 (2023-2025) 旅宿業平均住房率分別為 46.8%、46.09% 及 45.73%，整體維持於約 45%-47% 區間，於房間數增加情況下，住房率仍能維持穩定水準，反映住宿需求具一定支撐力，市場發展趨勢趨於平衡。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>觀光署強調，國民旅遊除旅館與合法民宿外，亦包含露營、登山及戶外體驗等多元型態。因此旅館與民宿住房率並非全面反映整體旅遊熱度，依國際訂房平台資料，約 25% 的旅客希望遠離都市環境，70% 的旅客對自然與生態型住宿展現高度興趣，住宿需求呈現分眾與多元發展態勢。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>整體而言，觀光署表示，國旅市場並非需求減弱，而是在供給擴張與旅遊型態多元化背景下，逐步由供給相對稀缺階段轉向選擇多元、分眾發展與品質競爭並行的成熟階段。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>為維護產業公平競爭及旅客安全，觀光署建議民眾優先選擇合法登記旅館與民宿，並留意相關認證標章，民眾可透過「台灣旅宿網」查詢登記資訊，並參考「好客民宿」及「星級旅館」等標章，作為選擇住宿之依據。</p></section><section style=\"margin-top:30px\">\n</section></main>",
            "link": "https://news.cnyes.com/news/id/6355149",
            "pub_date": "2026-02-26 18:45:25",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355295,
            "title": "三洋實業與麗明營造合作拿下高雄白埔產業園區133億元開發標案",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p>三洋實業 (<a data-ga-click-item=\"TWS:1472:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/1472\" rel=\"noopener noreferrer\" target=\"_self\">1472-TW</a>) 今 (26) 日公布與麗明營造共同參與取得高雄市政府委託公民營事業辦理「白埔產業園區」標案，此一開發案主辦單位為高雄市經發局，開發總金額為 133 億元，三洋實業占比 50％，開發時程預計 2026-2030 年。</p></section><p><template id=\"P:1\"></template></p><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>同時，三洋實業將依此一開發案進度陸續認列營收，將為公司增添營運成長新引擎，使未來 3-5 年營運能見度相對明確。</p></section><section>\n</section><section style=\"margin-top:30px\"><p>此一開發案，主要為滿足半導體先進製程企業之需求，高雄市經發局依「產業創新條例」選定高雄市岡山區及橋頭區之白埔農場作為「白埔產業園區」之基地範圍，面積約 88.73 公頃，目前已通過環境影響評估及都市計畫變更，預計 2026 年公共工程與廠商廠房同步施工。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>未來將提供優良產業用地，吸引半導體廠商擴廠投資，強化南部半導體材料 S 形廊帶之發展，並引領高雄市產業朝高值化方向發展與深化產業發展根基，其規劃 53 公頃產專區，產值預估達 3000 億元，進而促進地方整體經濟繁榮與提供充足之就業機會。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>三洋實業 2021 年成功轉型營造業，旗下控有甲級營造廠上鋌營造公司，集團陸續完成高雄、台南、屏東等政府新建公共工程標案，加上在建太陽能工程、社會住宅、水利工程等多元營建業務，繳出 2025 年全年合併營收 36.43 億元，創下年度歷史新高，年增率高達 56％，前三季淨利 2.68 億元，推升前三季每股純益高達 5.1 元，已賺贏歷年全年。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>三洋實業截至 2025 年底在手合約案量超過 10 案，包含高雄市水利局、高雄與花蓮港務分公司基礎建設、能源基礎建設、運動場館興建工程、國家運動訓練中心、小港機場擴建、社會住宅新建統包工程，在手案量將持續貢獻未來營運成長動能。</p></section><section style=\"margin-top:30px\">\n</section></main>",
            "link": "https://news.cnyes.com/news/id/6355295",
            "pub_date": "2026-02-26 18:47:21",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355296,
            "title": "〈台幣〉股匯雙漲爆巨量收31.251元攀逾2月新高 月線終結連4黑",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p>台北股匯本周金馬年開市後展開強勢補漲，大盤一舉衝破 3 萬 4、3 萬 5 兩道關卡，外資近日也擴大匯入力道，今 (26) 日再往 31.2 元關卡靠攏，但在央行介入調節下，終場升幅收斂收在 31.251 元，升 8.9 分，由於股匯 2/27 休市一天，熱錢提前匯入，帶動台北與元太外匯單日成交值爆出 30.61 億美元。</p></section><p><template id=\"P:1\"></template></p><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p><a href=\"https://invest.cnyes.com/forex/detail/usdtwd\">新台幣</a>兌美元同步收周線及月線，本周開紅盤後，匯價一路走升，單周累計升值 2.67 角或 0.85%，周線寫下連 2 升；2 月則呈現先貶後升，單月累計升值 2.17 角或 0.69%，月線終結連 4 黑。</p></section><section>\n</section><section style=\"margin-top:30px\"><p>台股近期日日有新高，今天盤中一度衝上 35579.34 點再締新猷，並誕生首檔萬金股王信驊，不過，適逢 MSCI 季調即將生效，尾盤爆量甩尾，終場<a href=\"https://invest.cnyes.com/index/TWS/TSE01\">加權指數</a>小漲 1.42 點，收在 35414.49 點，仍創新高，集中市場爆出 1.2 兆元成交量，改寫歷史新天量紀錄。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p><a href=\"https://invest.cnyes.com/forex/detail/usdtwd\">新台幣</a>今天盤中一度升值逾 1.4 角，最高觸及 31.203 元，熱錢瘋狂湧入，不過，央行適時進場穩定匯率，終場<a href=\"https://invest.cnyes.com/forex/detail/usdtwd\">新台幣</a>收在 31.251 元，升值幅度縮至 8.9 分，創 2 個多月以來的收盤新高。</p></section><section style=\"margin-top:30px\">\n</section><section style=\"margin-top:30px\"><p>觀察主要貨幣今天對美元表現，根據央行統計，<a href=\"https://invest.cnyes.com/index/GI/DXY\">美元指數</a>小跌 0.04%，<a href=\"https://invest.cnyes.com/forex/detail/cnyusd\">人民幣</a>強勢大漲 0.42%，<a href=\"https://invest.cnyes.com/forex/detail/usdtwd\">新台幣</a>約升 0.28%，與<a href=\"https://invest.cnyes.com/forex/detail/krwusd\">韓元</a>升值幅度相當，新加坡幣升 0.14%，<a href=\"https://invest.cnyes.com/forex/detail/jpyusd\">日元</a>則貶值 0.08%。</p></section><section style=\"margin-top:30px\">\n</section></main>",
            "link": "https://news.cnyes.com/news/id/6355296",
            "pub_date": "2026-02-26 18:48:42",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355307,
            "title": "台股成交量創新高，華新業績回穩但市場情緒受壓力",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><div class=\"summary-content\"><h3>華新業績逆勢回穩，台股成交量創新高，市場情緒仍受壓力</h3>\n<div class=\"highlight\">\n華新 (<a data-ga-click-item=\"TWS:1605:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/1605\" rel=\"noopener noreferrer\" target=\"_self\">1605-TW</a>) 在2025年第四季雖然本業虧損7.88億元，但因業外收益的挹注，稅後純益達10.14億元，每股純益0.23元，並計劃發放每股0.5元的現金股利，顯示出其在逆境中仍具備一定的資本運作能力<a href=\"https://news.cnyes.com/news/id/6355141\" target=\"_blank\">[1]</a>。同時，台股在2026年1月的證券劃撥餘額創下歷史新高，散戶參與度上升至56.2%，顯示資金正快速流入股市，並且M1B與M2的<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>交叉現象再度出現，反映出市場資金動能的強勁<a href=\"https://news.cnyes.com/news/id/6354907\" target=\"_blank\">[2]</a>。這些趨勢不僅顯示出散戶對市場的信心，也可能為華新未來的業務復甦提供支持，尤其是在不銹鋼及電線電纜需求回暖的背景下，市場前景值得關注。\n</div>\n<div class=\"highlight\">\n經濟部長龔明鑫對於在野黨推動的晶片國安法表達保留，擔心過度限制將導致研發中心外移，影響台灣的技術優勢<a href=\"https://news.cnyes.com/news/id/6355130\" target=\"_blank\">[3]</a>。此外，TrendForce報告指出，因原物料及人工成本上升，2026年第一季UV LED價格將季增5%，市場規模有望突破2億美元，顯示出該領域的穩定成長潛力<a href=\"https://news.cnyes.com/news/id/6355128\" target=\"_blank\">[4]</a>。龔明鑫強調現行投審機制的完善性，並期待台美關稅談判的良好進展能為台灣產業帶來競爭優勢，尤其在能源轉型及半導體產業的節水表現上，政府已展現出積極的應對措施，這些因素共同影響著台灣未來的產業發展與市場競爭力。\n</div>\n<div class=\"highlight\">\n今日台股成交量達1.13兆元，指數微幅上漲至35414.49點，雖然盤中曾創下新高，但三大法人合計賣超139億元，外資賣超台積電 (<a data-ga-click-item=\"TWS:2330:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/2330\" rel=\"noopener noreferrer\" target=\"_self\">2330-TW</a>) 6.1萬張，顯示市場情緒仍受壓力。另一方面，圓裕 (<a data-ga-click-item=\"TWG:6835:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/6835\" rel=\"noopener noreferrer\" target=\"_self\">6835-TW</a>) 雖然公布去年每股純益0.97元並擬配發現金股利1元，但其全年營收下滑及毛利率下降，顯示其面臨營運挑戰，尤其在與同泰 (<a data-ga-click-item=\"TWS:3321:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/3321\" rel=\"noopener noreferrer\" target=\"_self\">3321-TW</a>) 和嘉聯益 (<a data-ga-click-item=\"TWS:6153:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/6153\" rel=\"noopener noreferrer\" target=\"_self\">6153-TW</a>) 的虧損情況相比，圓裕的未來成長潛力仍需觀察。整體而言，台股在外資賣壓及個別企業表現不佳的背景下，市場需謹慎評估後市走向<a href=\"https://news.cnyes.com/news/id/6355038\" target=\"_blank\">[5]</a>、<a href=\"https://news.cnyes.com/news/id/6355138\" target=\"_blank\">[6]</a>。\n</div>\n<div class=\"highlight\">\n中鋼 (<a data-ga-click-item=\"TWS:2002:STOCK:COMMON\" data-ga-event-name=\"Click_Quote\" data-ga-section=\"News_Article_文中行情\" data-ga-target=\"news\" href=\"https://www.cnyes.com/twstock/2002\" rel=\"noopener noreferrer\" target=\"_self\">2002-TW</a>) 公布1月份自結稅前淨損8579萬元，顯示鋼鐵生產成本高企對營運造成壓力。儘管營收小幅增長至260.18億元，月增2%、年增1%，但營業淨損達7318.4萬元，反映單位毛利減少的影響。全球製造業需求回穩雖有助於補庫存，但歐美鋼價上漲主要受貿易壁壘影響，亞洲鋼廠如中國與越南亦調漲板材售價，顯示市場仍面臨高成本與需求未回溫的挑戰。未來中鋼需尋求有效的成本控制策略以應對不利環境<a href=\"https://news.cnyes.com/news/id/6355041\" target=\"_blank\">[7]</a>。\n</div></div></section><p></p><section style=\"margin-top:30px\"><p class=\"signature\">Powered by <a href=\"https://www.yushan.ai/\" target=\"_blank\">Yushan.AI</a></p></section></main>",
            "link": "https://news.cnyes.com/news/id/6355307",
            "pub_date": "2026-02-26 18:40:06",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355300,
            "title": "預告：美國上週初請失業金數據今晚公佈，預期21.5萬人",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p>BlockBeats 消息，2 月 26 日，美国至 2 月 21 日當周初請失業金人數將於今晚 21:30 公佈，前值 20.6 萬人，預期 21.5 萬人。</p></section><p></p><section style=\"margin-top:30px\"><p><a href=\"https://m.theblockbeats.info/tw/flash/333614\" rel=\"nofollow\" style=\"color:#A9A9A9\">原文連結</a></p></section><section style=\"margin-top:30px\"><p>發佈者對本文章的內容承擔全部責任<br/>在投資<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">加密貨幣</a>前，請務必深入研究，理解相關風險，並謹慎評估自己的風險承受能力。不要因為短期高回報的誘惑而忽視潛在的重大損失。</p></section></main>",
            "link": "https://news.cnyes.com/news/id/6355300",
            "pub_date": "2026-02-26 18:30:10",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355301,
            "title": "萬字拆解英偉達20年崛起全史：從兩塊遊戲顯卡到5兆帝國",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p style=\"text-align: left;\">作者：戈多Godot 來源：X，@GodotSancho</p></section><p></p><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我們的故事，要從一個比賽說起。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">李飛飛曾任 Google 副總裁及 Google Cloud AI/ML 首席科學家，同時也是斯坦福大學教授。但她還有另一重身份——ImageNet 大賽創辦人。</p></section><section><p style=\"text-align: left;\">ImageNet 大賽，正式名稱 ILSVRC（ImageNet Large Scale Visual Recognition Challenge），是計算機視覺領域最具影響力的學術競賽。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2012年 ImageNet 大賽，圖靈獎得主傑弗里·欣頓（Geoffrey Hinton）的學生 Alex Krizhevsky，憑藉 AlexNet 神經網路將圖像識別錯誤率從 26% 降至 15.3%，以領先第二名 10.8個百分點的驚人優勢震驚世界。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">關鍵在於，AlexNet 並未使用超級計算機，而是僅靠兩塊普通的英偉達 GTX 580 遊戲顯卡完成訓練。這是 AI 首次大規模使用 GPU 加速。在此之前，訓練主要依賴 CPU。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這一結果等於向全世界宣告：AI 深度學習 + GPU = 算力革命。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">當研究者們紛紛將目光轉向 GPU 時，他們發現，只有英偉達的 CUDA 能讓他們用類 C 語言編寫複雜算法。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">黃仁勛的「十年豪賭」</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">時間撥回 2006年。彼時 GPU 的職責只有一件事：渲染遊戲畫面。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但黃仁勛想讓 GPU 變成通用計算工具。他堅信摩爾定律在 CPU 上已近失效，串行計算的未來必然是並行計算。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">於是在 2006年，首席科學家 Ian Buck 領銜開發 CUDA（Compute Unified Device Architecture）。然而當時根本沒人知道這東西有什麼用。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">為了支撐 CUDA，英偉達在每一顆 GPU 晶片中都額外嵌入一塊專用計算電路。這意味著晶片面積增大、功耗升高、良品率下降、成本飆升。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">除了極少數科研人員，沒人買賬。在深度學習爆發前，英偉達甚至主動向全球頂尖實驗室免費寄送顯卡，並派駐工程師協助優化。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">CUDA 每年要燒掉英偉達約 5億美元的研發費用，而當時英偉達一年的利潤也不過幾億美元。2008年金融危機來襲，英偉達股價暴跌。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">黃仁勛頂着股價暴跌的壓力，堅持了整整十年。他始終堅信，GPU 不僅僅是用來渲染遊戲畫面的，而是一台通用並行處理器。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 2012年那個轉折點上，Intel 還在忙着維護 CPU 的霸權。Intel 長期迷信 CPU 的通用性，認為神經網路不過是一陣風。即便要算，也可以通過擴展 CPU 指令集（如 AVX）來解決。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">AMD 當時正深陷收購後的陣痛，在軟體投入上極其吝嗇，導致其 AI 軟體棧 ROCm 直到今天在易用性和穩定性上仍落後 CUDA 幾個身位。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">於是，2012年那個夏天，Alex Krizhevsky 面對 ImageNet 比賽中數百萬張圖片，正愁 CPU 算不動。他發現 CUDA 極其好用，便用類 C 語言寫了幾千行代碼，跑在兩塊 GTX 580 上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">結果一出，全球學術界震動。原本要跑幾周的實驗，在 GPU 上幾天便出了結果，且準確率斷層領先。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">放棄行動網路，全面轉向 GPU 計算</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2013年，黃仁勛在 GTC 大會上做出了一個在當時看來近乎瘋狂的決定，將公司重心全面轉向 GPU 計算。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">那是行動網路的<a href=\"https://invest.cnyes.com/index/GI/XAUUSDOZ\">黃金</a>時代，智慧型手機浪潮正盛。英偉達雖在手機市場受挫，卻沒有在手機晶片領域死磕，而是果斷將資源全部抽調回來，押注當時還極為小眾的數據中心加速計算。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">同年，CUDA 進入 5.0/5.5 時代，引入動態並行（Dynamic Parallelism），GPU 可在不回傳 CPU 的情況下自行啟動新任務，大幅削減通信延遲。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">與此同時，英偉達內部開始秘密研發 cuDNN，專為深度神經網路打造 CUDA 深度學習庫，將神經網路中最難編寫的卷積算法直接封裝在底層庫中。開發者只需調用一行命令即可完成操作。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而換到 AMD 的顯卡上，同樣的功能得自己寫幾百行複雜的底層代碼。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2014年，深度學習框架混戰拉開帷幕。Google 開源了 TensorFlow，英偉達隨即派出大量工程師駐紮在開源社區，持續優化 CUDA 適配。當 TensorFlow 1.0 發布時，在英偉達顯卡上的運行效率比 AMD 顯卡高出數倍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">\"顯卡買英偉達\"，開始成為行業共識。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">時至今日，CUDA 已從一個開發工具演變為一種行業標準語言。GitHub 上數以億計的 AI 代碼庫依賴 CUDA 原語，大學課程幾乎全部基於 CUDA 教學。這意味著新一代工程師在畢業前就已成為英偉達生態的\"原住民\"。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GitHub 上數以億計的 AI 代碼庫依賴 CUDA 原語。大學課程幾乎全基於 CUDA 教學。這意味著新一代的工程師在畢業前就已經成為了 NVIDIA 生態的「原住民」。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 CUDA 之上，還有一套龐大的中間件與庫體系。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">A. cuDNN 與 cuBLAS</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">深度神經網路與線性代數庫，歷經十餘年手工匯編級優化。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">B. TensorRT</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">推理優化引擎，能自動融合算子、篩選最佳 kernel、執行量化校準。進入 Blackwell 時代後，TensorRT-LLM 更成為部署大語言模型的標配，直接支持 FP4/FP8 極致優化，競爭對手難以望其項背。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">C. Triton Inference Server</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">已成為雲原生 AI 推理的事實標準。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">黃仁勛、馬斯克 、OpenAI、《Attention is All You Need》…2017，AI 之神顯靈</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2017年，英偉達 Volta 架構誕生，旗艦產品 Tesla V100 隨之發布。這顆晶片上第一次出現了 Tensor Core。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">AI 計算從這一刻起，由矢量運算邁入矩陣運算時代。AI 算力爆發，迎來元年。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而早在 2016年底，黃仁勛便親手將全球第一台搭載早期加速卡的 DGX-1 超級計算機，送到了當時還名不見經傳的 OpenAI 辦公室。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">於是便有了那張著名的照片。照片中那個雙手交叉的人，正是 OpenAI 出資人馬斯克。這台機器後來成為訓練 GPT 系列模型的\"始祖機\"。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2017年還發生了一件看似無關、實則決定了今天格局的大事：Google 發表論文《Attention is All You Need》，提出了 Transformer 架構。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這篇論文奠定了當今大語言模型的基石，徹底改變了 AI 處理資訊的方式，並直接促成了後來 ChatGPT、Claude、Gemini 等大模型的誕生。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Transformer 架構的計算幾乎全部由矩陣乘法構成，對算力的需求極為貪婪。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">矩陣乘法，是不是有些眼熟？沒錯，英偉達的 Tensor Core，恰恰就是為矩陣乘法而生的。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">至此，AI 的\"寒武紀大爆發\"正式拉開序幕。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">宏觀角度看，英偉達的霸主地位建立在三大支柱之上：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）Tensor Core 架構</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">實現了矢量計算到矩陣計算的跨越、從通用計算到深度學習專用計算的跨越。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）CUDA 軟體生態</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達最深護城河，不僅是一門編程語言，更是一個涵蓋 cuDNN、cuBLAS 等在內的龐大庫與工具集合，使得遷移成本極高。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3）NVLink 互連技術</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GPU 之間協作的橋樑。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">通俗理解三者的關係：Tensor Core 是硬體創新，CUDA 是軟體生態，NVLink 是互聯通道，分別對應性能、生態與可組合性。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">其中 Tensor Core 是英偉達真正甩開對手、確立 AI 霸主地位的關鍵。不理解 Tensor Core，就無法理解現代 AI 晶片。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Tensor Core 標誌着 GPU 從圖形渲染設備徹底轉型為 AI 專用計算平台，以犧牲通用性為代價，換取矩陣乘法（Matrix Multiply）這一 AI 核心運算上的極致性能。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">什麼是 Tensor Core ？</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Tensor Core 可進一步拆解為三個核心概念：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）矩陣乘法（Matrix Multiplication） 2）混合精度（Mixed Precision） 3）架構演進</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">1）矩陣乘法（Matrix Multiplication）</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從矢量計算邁向矩陣計算，是 Tensor Core 實現性能飛躍的核心邏輯。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">傳統 CUDA Core 執行的是標量或向量運算，例如 A + B。即便並發執行，每個周期也只能處理有限的數據點。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Tensor Core 則是嵌入 GPU 內部的 DSA（Domain Specific Architecture，領域專用架構）模塊，相當於在通用 GPU 架構內部植入了 ASIC 級別的專用加速單元。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Tensor Core 並不是為了執行所有類型的指令，而是專攻一種特定運算——矩陣乘累加，即 D = A × B + C。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">通俗地說，矢量計算像是一行一行地下達計算指令；矩陣計算則是直接輸出一整塊表格（4×4 矩陣）。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">2）混合精度（Mixed Precision）——模糊的藝術</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">AI 的本質是機率，而非定論。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">判斷一張圖里是貓還是狗，98.0001% 的機率與 98.0000000001% 的機率並無區別。但精度不同，對算力效率的影響卻天差地別。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">所謂混合精度，就是在不影響結果正確性的前提下，儘可能用低精度換取極致效率。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">A. 如何衡量精度？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這裡要引入一個概念：FP（Floating Point），即浮點數。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在計算機內部，任何數字都由 0 和 1（位/Bit）組成。一個浮點數通常包含三部分：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）符號位（Sign），表示數字是正還是負。 2）指數位（Exponent），決定數字的大小範圍。 3）尾數位（Mantissa/Fraction），決定數字精度，即小數點後有多少位。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">常見的如 FP32，用 32位記錄一個數，極其精確但占用空間大。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP16 空間減半、速度翻倍，但精度和範圍都隨之縮小；FP4 則是極低精度，類似像素畫，只能記錄非常模糊的數值。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在計算機科學中，這本質上是在有效資訊量（資訊熵）、計算吞吐量與數值穩定性之間尋找最優解。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">B. 混合精度如何運作？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">a. 精度降級</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">計算時，Tensor Core 將原本 32位的輸入強制轉換為 16位。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP32：1位符號 + 8位指數 + 23位尾數。 FP16：1位符號 + 5位指數 + 10位尾數。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">尾數位從 23 降到 10，在矩陣乘法階段，計算壓力減少 4倍以上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">b. 累加保護</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這是 Tensor Core 設計最精妙之處。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">輸入是 FP16，但累加使用 FP32——注意，加法用的是 FP32。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">原因在於，小誤差在相乘時尚且安全，但若在數萬次相加中持續丟棄微小值，誤差會迅速放大。通過在高精度下累加，英偉達保障了最終結果的精確性。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">c. 損失縮放——對抗\"下溢出\"</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">AI 訓練中，若全程使用 FP16，模型會崩潰。因為有些關鍵數據極其微小，FP16 根本無法表達，這個問題叫下溢出。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">對策是，程序在計算前將損失值乘以一個巨大的係數（如 1024），強行將這些微小梯度推回 FP16 能表達的有效範圍內。計算完成後，再除以 1024 還原。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">C. 混合精度的極限——Microscaling Format（MX）微縮放</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達 V100 支持 FP16，到了 H100 變成 FP8，B200 進一步降至 FP4。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP4 雖然比 FP16 快得更極致，但 FP4 只能表達 2⁴ = 16 個數值。要知道一張圖片中的色號都遠不止 16個，AI 將無法分辨梵高的《向日葵》和《星空》。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">於是在 Blackwell 架構中，英偉達引入了 Microscaling Format，其核心思想是塊浮點（Block Floating Point）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">通俗地說，AI 網路同一個向量塊中，數值的數量級往往相近。與其對每個數值逐一縮放，不如按批處理：在一批數值中找到絕對值最大的那個，以此確定公共縮放因子。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">最棘手的情況是，一組數據里混入了一個極大值，而其餘都是極小值。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">就像一張照片里既有太陽，旁邊又有一隻微弱的螢火蟲。在 AI Transformer 的某些層中，這種\"異常值\"時常冒出。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這也正是英偉達在 Blackwell 架構中並未完全拋棄 FP8 和 FP16，並且在軟體層面投入大量精力做平滑處理的原因。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">3）架構演進</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這裡有個很方便的記憶方式：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Volta 是誕生——Ampere 走向主流——Hopper 大爆發——Blackwell 現在最火。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">年份越往後，架構名越靠後，支持的精度（FP 後的數字）越小，矩陣運算的量級越大，AI 越像人。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2017年 Volta（V100）：一場極其冒險的豪賭</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2017年 Volta 問世，是英偉達發展歷程中的關鍵分水嶺。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在此之前 Pascal 架構，比如 GTX 1080 Ti，主要目標還是讓遊戲畫面更好看。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而從 Volta 開始，黃仁勛做了一個當時看來極其冒險、事後證明是神來之筆的決定——模糊精度，即降低精度換取極致 AI 計算效率，讓 GPU 從通用計算設備變成 AI 專用平台。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2017年之前，科學計算領域如天氣模擬、核爆仿真，要求絕對精準，大家都在比拼 FP32 單精度甚至 FP64 雙精度算力。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但突然之間，AI 爆發了。而 AI 網路恰恰很\"抗噪\"。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">訓練 AI 就像教小孩認貓，不需要告訴孩子這隻貓耳朵長 3.1415926 厘米，只需要說大概 3 厘米就夠了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達在 V100 上大力推行混合精度：計算用 FP16 半精度，累加時用 FP32 高精度防止誤差積累。就像從寫楷書變成寫草書，速度瞬間翻倍，而 AI 準確率幾乎沒有下降。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這在當時極其冒險。在一顆極其昂貴的晶片上劃出一大塊面積，為一個當時僅有少數人在用的矩陣運算做專用電路，這是非常、非常、非常冒險的決定。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但黃仁勛和英偉達賭對了 AI 大爆發。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">於是，這成為了其他競爭對手，如英特爾，至今落後的原因。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">2018年 Turing（T4）——遊戲畫質的超級革新：光追與 DLSS</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">其實到此時，晶片的主要使用場景仍然是遊戲畫面渲染。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2018年，英偉達發布 Turing 架構（RTX 2080 Ti）。這是顯卡歷史上第一次將三種完全不同性質的處理器封裝在同一塊硅片上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">先解釋一下背景。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在此之前，遊戲畫面渲染用的是光柵化（Rasterization），本質上就是 2D 貼圖。老遊戲玩家應該深有體會。比如水面倒影，其實是預先畫好再貼上去的，玩家視角變了，影子紋絲不動。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">光線追蹤（Ray Tracing）則是模擬真實物理世界的光影效果。遊戲中的光線和倒影會隨玩家視角與光源實時變動。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">光追在此之前並非做不了，只是計算量太大，遊戲會直接卡成 PPT。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Turing 架構中，三種完全不同性質的處理器分別是 RT Core、CUDA Core 和 Tensor Core。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）RT Core（Ray Tracing Core，光線追蹤核心）</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這是 Turing 的獨創，專門負責計算光線與三角形的求交運算（BVH Traversal）。功能極其單一，只用於光追計算。將這類枯燥的幾何運算從通用核心中抽離出來，效率提升了數十倍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）CUDA Core（通用計算核心）</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">繼續承擔傳統的光柵化渲染任務。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3）Tensor Core（混合精度計算核心）</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">新增 INT8、INT4、INT1 支持，引入低精度推理能力，並首次將 Tensor Core 帶入消費級顯卡（RTX 20 系列）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這裡隱藏着一個偉大的發明——DLSS（深度學習超級採樣）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">其邏輯是，光追計算太吃力，先渲染 1080P 畫面，再用 Tensor Core 跑一個神經網路，將 1080P 的畫面\"腦補\"成 4K。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這是 AI 生成內容在圖形領域的首次大規模落地，證明了 AI 可以成為傳統圖形流水線的一部分。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2018年前後，傳統性能增長已觸及瓶頸。英偉達強推光追，本質上是重新定義了衡量顯卡優劣的標準。AMD 或 Intel 即使想跟進，也缺乏像 Tensor Core 這樣高效的硬體來支撐。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">也就是說，英偉達形成了\"算法 + 硬體 + 訓練數據\"的全方位封鎖。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">光追與 Tensor Core 的結合，還意外打開了通往元宇宙和數字孿生的大門。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">既然 Tensor Core 能通過 AI 補全遊戲畫面，那能不能根據幾張照片，直接\"腦補\"出一個真實的 3D 空間？這便是近幾年大熱的 NeRF 神經輻射場技術，實現了僅需幾秒鐘便能從影音生成 3D 模型。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">2020年 Ampere（A100）——史上最成功的 AI 晶片</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">用\"易用性革命\"概括 A100，再合適不過。A100 之前，計算領域存在三個問題： 1）精度分裂。FP32 太慢，FP16 太難駕馭； 2）算力分裂。訓練卡和推理卡互不通用； 3）資源分裂。大模型吃不飽，小模型吃撐了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達在 A100 上做出了堪稱革命性的改進： 1）TF32（TensorFloat-32） 2）結構化稀疏（Structural Sparsity） 3）MIG（Multi-Instance GPU）</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">三者合力，實現了單張晶片的大一統。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">TensorFloat-32 (TF32)</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這是一個天才設計。還記得上文提到，此前 AI 計算沿用高精度方案，進行氣象模擬、粒子仿真、核爆軌跡推演等場景嗎？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TF32 能讓那些習慣編寫高精度 FP32 代碼的開發者，不改代碼，直接享受 Tensor Core 的模糊精度加速。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TF32 並非一種全新的儲存格式，而是一種運算中間格式。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">通過對 FP32 進行\"截斷\"實現加速，本質是為了平衡計算精度與數值範圍，設計的一種全新數學格式。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">上篇提到，計算機內部任何數字都由 0 和 1（位/Bit）組成。一個浮點數通常由三部分構成： 1）符號位（Sign），數字是正還是負。 2）指數位（Exponent），決定數字的大小範圍。 3）尾數位（Mantissa/Fraction），決定數字精度，即小數點後有多少位。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">常見的如 FP32，用 32位記錄一個數，極其精確但占用空間大；FP16 空間減半、速度翻倍，但精度和範圍都隨之縮小；FP4 則是極低精度，類似像素畫，只能記錄非常模糊的數值。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TF32 精妙之處在於，把 FP32 的範圍和 FP16 的精度拼接在一起，形成一個 19位的格式：符號位 1 bit，指數位 8 bit（與 FP32 一致），尾數位 10 bit（與 FP16 一致）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">換句話說，TF32 是 FP32 與 FP16 之間的橋樑。是不是非常天才！！！！！！！</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">其工作流程如下：TF32 從顯存中讀取標準 FP32 數據，Tensor Core 在硬體電路中自動將尾數位從 23-bit 截斷為 10-bit，轉換為 TF32 格式，在此格式下執行高效乘法；所有中間乘積最終在 FP32 精度下完成累加；寫回顯存的數據依然是標準 FP32。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">更關鍵的是，截斷過程完全自動，意味著可以自動兜住數值的下溢出問題。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">結構化稀疏（Structural Sparsity）</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">稀疏的本質，是把不重要的權重變成 0。就像識別一張貓的圖片，大部分像素不起決定作用。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達規定：在每 4 個連續權重中，必須有 2 個被設為 0。原本需要 64 bit 的數據，現在只需約 34 bit，模型在顯存中幾乎瘦身一半。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">打個比方，如果顯卡有 80GB 顯存，原本只能裝下 400億參數（40B）的模型。開啟結構化稀疏後，可能就能塞進一個接近 700億（70B）甚至 800億（80B）參數的模型。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而且性能還翻了倍。密集計算 156 TFLOPS（每秒 156 兆次運算），稀疏計算 312 TFLOPS。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">如果再疊加上文提到的 TF32 相較傳統 FP32 帶來的近 10倍提升，會發現 A100 在處理特定 AI 任務時，比幾年前的舊顯卡快了整整一個時代。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">至於是否會擔心連續 4 個權重都很重要、丟失關鍵資訊？首先，模型尚未\"定型\"時，權重是可以流動調整的。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">其次，神經網路具有極強的容錯能力——雖然在某個小局部損失了資訊，但其他層可以通過學習來彌補這一損失。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">此外，稀疏並非隨機刪除，而是按權重大小裁剪。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">MIG（Multi-Instance GPU）</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">MIG 用於晶片的空間管理，將單顆 GPU 在物理電路層面進行\"硬分割\"。沒看錯，是物理層面的切分。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 A100 上，MIG 最多可將 GPU 切成 7 個獨立實例（Instance），每一份都擁有自己專屬的 Tensor Core 和顯存路徑。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">切分方式靈活多樣，比如切成 7 個小實例，或者 1 個大實例加 3 個小實例。硬體在出廠時就具備了這種\"切割\"能力，但具體怎麼切、切成幾份，完全可以在購入後通過軟體命令實時控制。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 A100 的硬體結構中，MIG 主要切割三類核心資源： 1）SM（流式多處理器）。計算核心，包含 CUDA Core 和 Tensor Core。 2）內存系統（Memory System），包括 HBM2 顯存與 L2 緩存。 3）帶寬（Pathways），晶片內部的數據傳輸通道（On-chip crossbar）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">每個實例擁有獨立、固定的內存地址空間和計算路徑。這意味著 A 實例在瘋狂讀寫數據時，其產生的電磁信號和總線占用完全不會干擾到 B 實例。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這帶來的好處顯而易見：</p></section><section style=\"margin-top:20px\"><ul class=\"list-paddingleft-2\"><li><p style=\"text-align: left;\">其一，大幅提高利用率、節省成本。一張 A100 售價數萬美元，如果只給一個博士生跑實驗，未免太過奢侈。有了 MIG，一家公司可以讓 7 位工程師在同一張卡上同時進行不同實驗，效率提升 7倍。</p></li><li><p style=\"text-align: left;\">其二，深受雲租賃市場歡迎。雲服務商可以按需靈活出租算力。</p></li></ul></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從更宏觀的視角回望：</p></section><section style=\"margin-top:20px\"><ul class=\"list-paddingleft-2\"><li><p style=\"text-align: left;\">Volta（2017）：證明通用計算的 CUDA Core 不再是唯一主角，矩陣計算的 Tensor Core 才是 AI 時代的皇冠。</p></li><li><p style=\"text-align: left;\">Turing（2018）：證明精度並非越高越好，低精度 INT8/INT4 才是推理時代的王道；同時證明 AI 可以反哺圖形學。</p></li><li><p style=\"text-align: left;\">Ampere（2020）：證明分裂是低效的，統一才是最終答案。訓練與推理被整合進同一塊硅片（A100）；同時證明稀疏化與 TF32 比\"蠻力的精準\"更具生產力。</p></li></ul></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在進入 2022年的 H100 之前，不得不先介紹英偉達壟斷地位的另一項關鍵創新——NVLink。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">如果說 Tensor Core 是晶片的心臟，那 NVLink 就是連接數萬顆心臟的大動脈。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">NVLink：GPU 之間的點對點高速互連協議</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink 是 GPU 之間的點對點高速互連協議，在 GPU 之間搭建高速公路，讓 GPU 直接對話，繞過 CPU。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink 存在的唯一目的——幹掉 PCIe 瓶頸。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">什麼是 PCIe 瓶頸？</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">PCIe（Peripheral Component Interconnect Express）是計算機主板上的通用總線，設計初衷是讓 CPU 連接各類外設，如顯卡、聲卡、網卡、硬盤。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">AI 場景下，瓶頸主要體現在：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）帶寬太低。目前最先進的 PCIe 5.0 x16 理論帶寬約為 63 GB/s，聽起來很快，但 H100 的顯存帶寬高達 3,350 GB/s。這意味著 GPU 內部算得極快，但數據進出的速度比內部運算慢了 50倍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）延遲太高。通過 PCIe 傳輸需要 CPU 介入。數據先從顯卡 A 傳給 CPU，再由 CPU 轉發給顯卡 B，由此產生巨大的延遲。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">為何這個瓶頸？最主要原因是，PCIe 的設計初衷是通用。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">說句題外話，通用與 AI 專用之間的權衡，貫穿英偉達崛起的始終，也是英偉達能彎道超車 Intel 的最核心原因。Intel 的長處在於 CPU——功能強大、通用性強，但也恰恰構成了 AI 計算的瓶頸。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而英偉達的崛起，正是因為敢於押注 AI 計算的專用性，並且賭對了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從物理極限、協議損耗、拓撲矛盾三個更專業的維度，可以更好地理解通用性與專用性之間的權衡。 1）拓撲矛盾。在 PC 端或服務器架構中，所有 PCIe 通道最終都匯聚於 CPU。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">CPU 像交通環島，所有車輛必須繞島一圈。即便 GPU 算力再強，只要 CPU 調度不過來，或者 CPU 連接的帶寬被占滿，數據交換就會卡頓。這就是所謂的 CPU 綁定瓶頸。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）協議損耗。PCIe 傳輸數據包時，需要附加報文頭、校驗碼等額外資訊；傳輸完成後，還要向 CPU 發送\"中斷請求\"，讓 CPU 處理後續邏輯。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3）物理層面的干擾。趨膚效應（Skin Effect）——頻率越高，電信號越傾向於在導線表面流動，導致電阻增大、信號衰減。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">NVLink 如何幹掉 PCIe 瓶頸？</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">回到那句話：NVLink 存在的唯一目的——幹掉 PCIe 瓶頸。如何做到？逐一來看。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）拓撲結構重構</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink 讓 GPU 之間直接點對點通信，徹底繞開 CPU 和系統內存。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）協議極致簡化</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink 採用類內存傳輸協議，協議開銷極低，有效載荷比遠高於 PCIe。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3）物理層面升級：多通道並行與高帶寬</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 H100 晶片背面，英偉達密密麻麻地布滿了 18 條 NVLink 鏈路，雙向總帶寬達到 900 GB/s。而 PCIe 5.0 x16 的帶寬僅為 63 GB/s。NVLink 的速度是 PCIe 的 14倍以上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">4）多卡合一：內存池化與 NVSwitch</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達不僅做了線，還專門做了交換機晶片——NVSwitch。在服務器內部，所有 GPU 都連接在 NVSwitch 上。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">NVLink 網路化：從點對點到全互聯</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">更進一步，NVLink 能將多張 GPU 連接為統一整體，以裝載更大的模型。要理解這一點，需要補充三個硬核維度。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）NVSwitch——從高速路到立交橋</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVSwitch 並非集成在 GPU 晶片內部，而是獨立的交換機晶片，安裝在 GPU 基板上。如果說 NVLink 是高速公路，NVSwitch 就是立交橋。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">A100 之前，GPU 之間主要是點對點連接。H100 之後，有了 NVSwitch，GPU 從點對點通信邁入了網路化時代，可以將多張卡連成更大的整體，裝載更大的模型。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">想象一下點對點通信的侷限：如果有 8張卡，卡 A 與卡 B 有 NVLink 物理連線，但卡 A 想與卡 D 通信，就需要經過 B 和 C 中轉，占用它們的帶寬。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">以 H100 為例，GPU 底部有 18 條第四代 NVLink 鏈路，這些鏈路插在主板的 NVLink 背板上。在 8張卡之間，分布着 4 到 6顆專用的 NVSwitch 晶片。每張 GPU 的所有 NVLink 路徑都直連到這些交換機上，而非直接連到另一張卡。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這種拓撲結構確保了任意兩張卡之間的通信，無需經過 CPU 或主板上的 PCIe 總線。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">更專業地說，NVSwitch 的核心技術指標是無阻塞全雙工帶寬（Non-blocking Switch），保證任何一張 GPU 都能同時以最高速率與另一張 GPU 通信。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）網路計算（SHARP）——讓交換機一邊搬數據一邊算數</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">網路計算是英偉達又一項黑科技，改變了計算機通信的基本邏輯：網路交換機不再只是搬運數據，而是在傳輸過程中直接把數學題算了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 AI 大模型訓練中，有一個動作會重複千萬次：梯度聚合（All-Reduce）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">簡單來說，梯度聚合就是讓參與訓練的所有 GPU 交換彼此的計算結果，最終讓每張卡都擁有完全相同的、經過匯總後的最新數據。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">梯度聚合有點類似區塊鏈的分布式計算，顧名思義，主要包含\"梯度\"和\"聚合\"兩個步驟。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">訓練大模型時會涉及並行計算。每張顯卡拿到一部分數據，算出自己那份數據的誤差方向，即梯度。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">由於每張卡看到的數據不同，算出的梯度也不同。如果各自直接更新，幾張卡上的模型就會南轅北轍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">因此在更新權重之前，所有卡必須把各自的梯度加起來求平均值。所有卡拿到這個全局平均梯度後同步更新，保證 8張卡里的模型永遠一模一樣。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">關於梯度聚合的具體計算方式。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">A100 採用環形聚合（Ring All-Reduce），是當時最節省帶寬的算法，將數據切成 N 片，像接力賽一樣傳球。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">SHARP 則採用樹形聚合（Tree All-Reduce），是英偉達目前力推的方案，數據像樹根一樣層層匯聚。GPU 將數據發給第一層 NVSwitch，SHARP 技術在交換機晶片接收多個 GPU 數據流時直接完成加法運算，再把結果發回各 GPU 晶片。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">為什麼梯度聚合（All-Reduce）是 AI 的生命線？</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">評價一個 GPU 集群優劣的標準，不是看單卡多快，而是看當卡數增加到 1000張時，梯度聚合耗時是否還能控制在毫秒級。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">如果顯卡算力很強（如 H100），但網路很弱，就會發現 GPU 有 70% 的時間在跑梯度聚合。也就是在等數據，只有 30% 的時間在真正計算 AI。這就是所謂的通信受限。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink、NVSwitch、SHARP 這一系列技術的存在，本質上都是為梯度聚合提供最快的通道。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">接下來，2022年，英偉達核彈級產品 H100 將登上舞台。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">2022年 Hopper（H100）——Transformer 引擎，現代大模型的基石</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2022年，H100 問世，堪稱核彈。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">H100 直接將特定的軟體算法 Transformer 刻進晶片，專為處理兆級參數的大語言模型 LLM 而生。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2022年 H100，堪稱核彈。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Transformer 架構源於 Google 在 2017年發表的論文《Attention Is All You Need》，是現代大語言模型的基礎。而 Transformer 引擎是 H100 內部的一個物理模塊。不是軟體，是硬連線的電路。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">與此同時，H100 利用 FP8 精度實現了比 A100 快 9倍的訓練性能，配合 NVLink Switch，能讓 256張顯卡化身為一個巨型超級大腦。沒有 H100，就沒有 ChatGPT 及兆參數大模型時代的爆發。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">研究 H100，可以從四個方面入手：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）Tensor Core 引入 Transformer 引擎與 FP8；</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）第四代 NVLink 與 NVSwitch 實現 900 GB/s 帶寬；</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3）引入新 CUDA 特性——DPX 指令集加速動態規劃；</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">4）全球首款支持隱私計算的 GPU。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Tensor Core 引入 Transformer 引擎與 FP8</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在 H100 中，FP8 像衝鋒陷陣的執行者。推理和訓練的大部分矩陣乘法都可以跑在 FP8 上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP16 像老謀持重的文官，保留副本，不至於因精度太低而丟掉更新量，起到承上啟下的作用，兼顧速度與穩定。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP32 垂簾聽政，專用於儲存與權重更新，因為低精度累加時細微梯度會被\"四捨五入\"抹除，導致誤差積累而停止學習。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP8 使得在有限顯存下訓練兆參數模型成為可能，吞吐量隨之翻倍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">DPX 指令集：順手比大小</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">DPX 本質是英偉達在晶片里焊死了一個\"算完加法順手比大小\"的快捷鍵。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">想象在一個棋盤格上，從左上角走到右下角，每走一步都有代價，你想找代價最小的路線。於是你看看從上面來要花多少、從左邊來要花多少、從斜上方來要花多少，挑最便宜的那個。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">注意這個動作的結構：先加，再比誰小。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">整個棋盤有幾百萬甚至幾十億個格子，每個格子都要執行一遍這個動作。這就是動態規劃的日常。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">H100 的 DPX 把這兩步焊成了一步。之所以用\"焊\"這個字，是因為這確實是晶片上的硬體結構。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">DPX 不需要像 Tensor Core 那樣增加大型專用單元，只是在現有整數計算通路上添加了一個\"順手比大小\"的功能——晶片面積開銷很小，但收益巨大。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">比如基因測序，一次要比對幾十億個鹼基對，每個鹼基對都要執行這個操作。省一條指令乘以幾十億次，節省的時間極為可觀。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">此外，H100 是全球第一款支持硬體級 TEE 的 GPU，由此開啟了隱私計算的新篇章。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TMA（Tensor Memory Accelerator）：異步數據搬運引擎</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TMA 是 H100 在 SM 微架構層面最重大的變化之一，直接決定了 Tensor Core 和 Transformer Engine 能否跑滿。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">簡單來說，TMA 就是英偉達在晶片里安了一個專職搬運工，讓幹活的線程不用再自己跑去倉庫搬數據。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GPU 的內存結構分為兩層：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）全局內存（Global Memory/HBM）容量大（80GB），但離計算單元遠、訪問慢，像一個巨大的遠郊倉庫；</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）共享內存（Shared Memory/SMEM）容量小（每個 SM 最多 228KB），但離計算單元近、訪問快，像工位旁的小櫃子。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">所有計算都必須先把數據從遠郊倉庫搬到工位小櫃子裡，算完再搬回去。搬數據本身不產生任何有用的計算結果，但搬不完就沒法算。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TMA 就是一個專職搬運模塊，讓分工更加精細。它理解張量的形狀，而且關鍵在於，可異步執行。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">TMA 還有一招殺手鐧：Multicast。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">H100 引入了 Thread Block Cluster（多個 SM 組成一個集群），TMA 不僅能把數據搬到發起請求的那個 SM 的共享內存，還能將同一份數據同時抄送給集群中的多個 SM。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">總結一下，</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GPU 的核心矛盾是\"算得快但搬得慢\"。A100 時代，幹活的人還得自己去搬貨，大家一起停下來搬完再開工。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">H100 的 TMA 則是一個專職快遞員。寫個地址貼上去，快遞員自行搞定，其他人繼續干自己的活。而且這個快遞員還懂張量的形狀，不管數據是幾維的，給個坐標它自己就能找到。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">如果說 DPX 是\"讓計算更快\"，一條指令干兩條的活，那 TMA 就是\"讓搬運不再拖後腿\"，搬運和計算並行，互不耽誤。兩者協同，才讓 H100 真正跑滿了算力。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從顯卡供應商到 AI 基礎設施的絕對統治者</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2023年，英偉達徹底蛻變。從顯卡供應商躍升為全球人工智慧基礎設施的絕對統治者，市值首次突破 1兆美元。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">財報連續三個季度大幅超出華爾街預期。數據中心業務收入取代遊戲業務，成為公司的絕對核心支柱。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從微軟、Meta、Google 等矽谷巨頭，到沙烏地阿拉伯、阿聯酋等主權國家，全球都在瘋狂囤積 H100 晶片。由於台積電 CoWoS 封裝產能受限，H100 變得一卡難求，單卡價格在二手市場一度炒到 4萬美元以上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">幾乎所有主流大模型，如 GPT-4、Llama 等，都在 CUDA 架構上開發。即便 AMD 的硬體參數更優，開發者也很難遷移，因為所有底層優化和算子庫都握在英偉達手裡。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">與此同時，英偉達開始通過軟體授權變現。硬體是一次性買賣，但軟體訂閱帶來的是源源不斷的現金流。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GTC 2023 上，黃仁勛喊出了那句著名的口號：\"AI 的 iPhone 時刻已經到來。\"</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">2024 Blackwell（B200）——微張量縮放</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3月 GTC 大會，英偉達發布 Blackwell（B200/GB200），通過 NVLink-C2C 將兩塊晶片連為一體，即\"雙芯一體\"結構，晶體管數量暴增至 2080億顆。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而在軟體端，B200 依然呈現為一個統一整體。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我們可以從 Tensor Core、CUDA、NVLink 三個維度分析 B200。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">第五代 Tensor Core：支持 FP4</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">B200 的 Tensor Core 核心突破在於支持 FP4。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從 2017年第一代 Tensor Core 支持 FP16，到 2022年 H100 支持 FP8，再到如今 B200 的第五代 Tensor Core 支持 FP4。精度一路下探，算力一路飆升。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">B200 的 FP4 並非簡單的精度截斷，而是引入了微張量縮放（Micro-tensor Scaling）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">一句話，微張量縮放是一種數據壓縮與量化技術，讓每個數字變小，但不丟棄數字。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">本質是動態範圍管理算法與硬體級縮放的協同，允許數十個元素組成的群組擁有獨立的縮放因子。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">硬體層面，微張量縮放依靠 Blackwell 的第二代 Transformer Engine 與第五代 Tensor Core 的物理電路協同完成。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">第二代 Transformer Engine 充當硬體調度中樞，負責動態範圍管理算法，實時追蹤不同網路層和不同張量 Tensor 數值分布範圍，計算出最優公共放大/縮小比例。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">第五代 Tensor Core 則在物理層面直接增加了對 FP4 的原生硬體支持，即硬體級縮放，負責執行。算術邏輯單元（ALU）能在接收 FP4 數據和縮放因子的同時，直接在硬體層級執行矩陣乘法運算。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">FP4 數據在計算時能瞬間對齊，恢復出高精度的動態範圍，從而在不丟失關鍵特徵的前提下實現算力翻倍，專為超大規模模型設計。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">此外，硬體解壓縮引擎（Decompression Engine）的引入，變相提升了 PCIe 和 NVLink 的有效帶寬利用率。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">CUDA 13.0</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">重點在於如何讓開發者無感地操控 B200 這種複雜的\"雙芯一體\"結構。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">儘管 B200 物理上由兩顆晶片組成，但 CUDA 通過 NV-HBI（High-Bandwidth Interface）讓開發者看到的依然是一個擁有 192GB 顯存的統一實體，無需手動處理跨晶片的數據同步。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink 5.0 與 NVL72</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">第五代 NVLink 協議將單個 GPU 的雙向帶寬提升至 1.8 TB/s，是 H100 的兩倍。兩顆晶片之間的帶寬更是高達 10 TB/s，讓軟體層完全感知不到這是兩塊晶片。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在此基礎上，英偉達還推出了 GB200 NVL72 機櫃，集成 36顆 Grace CPU 和 72顆 Blackwell GPU，形成了一個擁有 1.4 EB/s 聚合帶寬的巨型資源池。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GB200 NVL72 不得不採用液冷設計，因為風扇已經不管用了。機櫃背面使用了 5000 根銅線而非光纖，大幅降低功耗的同時，消除了光電轉換帶來的納秒級延遲。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">至此，英偉達開始以\"機櫃\"為最小銷售單元。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">SHARP 也進化至 v4 版本，網路計算能力再次翻倍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NIM (NVIDIA Inference Microservices) ：軟體閉環</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">過去，企業想把一個開源大模型部署到自己的服務器上，是一件極其痛苦的手工活。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">工程師需要配置底層環境、安裝 CUDA、編譯 PyTorch、手寫加速腳本，最後還要自行封裝接口，整個過程往往耗費數周。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NIM 是一個預裝好的軟體容器，內部已調優好模型。企業只要買了英偉達的卡，直接一鍵即可運行，不再需要昂貴的算法團隊去逐項調優。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">企業可以將 NIM 部署在自己的內網中。藉助 AWS 等雲服務上的 NIM，企業能在享受最新模型的同時，保持對專有數據和應用程序的絕對安全控制——數據永遠不會泄露給第三方模型提供商。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2024年 6月，英偉達市值一度超越微軟和蘋果，成為全球市值最高的公司。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但同年，市場開始出現分歧。一方面，英偉達財報依然炸裂，利潤率高得驚人。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">另一方面，矽谷開始擔憂 AI 的投資回報率。微軟、Google 砸了數千億美元買 GPU，但增值服務收入未能覆蓋成本，導致英偉達股價在 8至 9月經歷劇烈波動，儘管業績依然保持着百分之幾百的增長。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2025年，英偉達市值一度衝破 5兆美元大關，坐穩全球市值第一。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">儘管年初受到 DeepSeek R1 號稱減少了對頂級晶片依賴的短期衝擊，市值單日大幅蒸發，但市場隨後意識到 AI 訓練對高性能算力的需求並未改變，英偉達股價反而更具剛性。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2025財年營收達 1305億美元，年增率增長 114%，數據中心業務占比接近 80%。英偉達財報發布會已取代傳統經濟指標，成為美股風向標。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達還參與了微軟與 OpenAI 耗資 5000億美元的 Stargate 星際之門超算項目。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2025年，英偉達實際上有多個重要的戰略方向轉變：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">1）業務層面：面向主權國家出口晶片，構建主權 AI；</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2）技術路線：從生成式 AI 轉向 Agentic AI Swarm；</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">3）應用前沿：深耕機器人與數字孿生。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2025年，英偉達還發布了兩個少有人關注但極具分量的重磅計劃：GR00T 與 Cosmos。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GR00T 是首個開源人形機器人通用基礎模型，Cosmos 是物理模擬平台，與 Google、迪士尼等合作。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">兩者結合，可讓機器人在數字孿生世界中完成訓練，在計算機虛擬環境裡模擬重力、摩擦力、流體力學，甚至材質的彈性與光影。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">藉助 GPU 強大的算力，虛擬世界可以倍速運行。現實中的一天，在虛擬世界裡可以跑完相當於幾十年甚至上百年的物理模擬過程。機器人的 AI 大腦在極短的現實時間裡，經歷了億萬次的摔倒與爬起。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">相當於\"人間一天，數字世界十年\"。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">人形機器人原型 Isaac GR00T N1 的量產，標誌着英偉達正式成為全球機器人的\"腦幹供應商\"。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Jetson Thor 則是專為機器人設計的車載級計算平台，已開始大規模量產，目標是成為所有會動的\"智能體\"的腦幹。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">年底，英偉達正式預告下一代 Rubin 架構。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">2026 Rubin（R100）—— Agentic AI Swarms 超大規模推理</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">年初，英偉達交付 Rubin R100，重新設計了 CPU、GPU、NVSwitch、NIC、DPU、SuperNIC 六款關鍵晶片。英偉達將這一理念稱為極限協同設計（Extreme Co-design）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">第四代高帶寬內存 HBM4 與 12-Hi 堆疊</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這裡涉及三個概念：內存牆、堆疊、HBM。而這三個詞彙恰好構成了\"發現問題——提出思路——解決問題\"的完整鏈路：內存牆是問題，堆疊是思路，HBM 是解法。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">什麼是內存牆？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">一句話，RAM/顯存的數據傳輸速度跟不上 GPU/CPU 的計算速度。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">比如 GPU 一秒鐘能做 100萬次乘法，但內存一秒鐘只能送來 10萬個數字，GPU 剩下 90% 的時間都在閒置。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">像 ChatGPT 這樣的模型，參數動輒幾千億，每次回答問題都要把這幾千億個數字從內存里搬出來算一遍。存在內存牆問題，GPU 算力再強也是一堆廢鐵。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">堆疊：從物理層面打破內存牆</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">打破內存牆，最簡單粗暴的方式是，把內存和 GPU 挨得越近越好，並且多放幾塊內存。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但 GPU 周圍的主板面積有限。於是工程師利用 TSV（硅通孔）在內存晶片上打出數以萬計的微小孔洞，填入銅導線，然後將 4層、8層、12層甚至未來的 16層內存晶片像疊漢堡一樣垂直堆疊在一起。這就是堆疊。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">HBM（高帶寬內存）：堆疊里的高速公路</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">HBM 是利用堆疊技術造出來的數據高速路，主要依靠 TSV（Through Silicon Via，硅通孔）和硅仲介層（解決外部水平連接）實現。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">HBM4（High Bandwidth Memory 4）是目前全球最先進的第四代高帶寬內存技術。而 12-Hi 堆疊指的是利用先進封裝技術，將 12層內存晶片像蓋樓一樣垂直疊放為一顆晶片。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">單顆 Rubin 晶片原生集成 288GB 的 HBM4 顯存，聚合帶寬達到了恐怖的 22 TB/s。在處理主流 10兆參數超大模型時，Rubin 能在不增加 GPU 數量的前提下，將訓練效率提升 3.5倍，推理成本降低 10倍。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Vera CPU——原生支持 FP8</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">先回顧一下 CPU 與 GPU 的本質差異。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">CPU 將大量晶體管用於複雜的控制單元（Control Unit）和緩存（Cache），而非計算單元（ALU）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這種設計對邏輯複雜的操作系統非常有效，但面對 AI 這種\"呆板\"的大規模數學運算，複雜的控制單元就是純粹的浪費，能效比極低。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">GPU 採用 SIMD（單指令多數據流）或更進一步的 SIMT（單指令多線程）架構。一個控制單元指揮一大群計算單元。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">就像廣播體操，教官（CU）喊一句\"抬手\"，幾千個學生（ALU）同時做動作，極大節省用於\"指揮\"的晶體管面積，將其全部轉化為\"幹活\"的算力。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這就是 GPU 在 AI 任務上能效比遠超 CPU 的根本原因。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但 GPU 沒有能力運行操作系統，無法直接讀取硬盤文件，也不能處理外部網路請求，必須受僱於 CPU，由 CPU 派活、準備數據。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Vera CPU 並非處理 Windows 數據的通用處理器，而是英偉達專為 Agentic AI 定製的數據管家，以極低延遲和極高帶寬，穩定地給旁邊的 Rubin GPU 餵數據。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">其本質是一個為最大化 GPU 算力吞吐而生的特化型處理器。捨棄傳統通用計算中的冗餘功能，用極致的內存帶寬、極低的單線程功耗和原生的低精度數據支持，換取在單一 AI 計算場景下的絕對數據調度效率。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2022年之前，英偉達只造 GPU。所有 AI 服務器都是買 Intel 或 AMD 的 x86 CPU 作為主板核心，再把英偉達的 GPU 像插 U 盤一樣插上去。於是就有了前文提到的 PCIe 瓶頸。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">到了 Hopper（H100）時代，英偉達自研 ARM 架構的 Grace CPU，並推出 GH200（Grace Hopper Superchip），第一次將自家 CPU 和 H100 GPU 封裝在同一塊超級主板上。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而到了 Vera，CPU 與 GPU 之間的數據壁壘被徹底打通。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">此前，GPU 內部已經在用極低精度（如 FP8）計算，但 CPU 傳統上只擅長處理高精度 FP32/FP16 數據。數據在兩者之間傳遞時需要頻繁進行格式轉換，白白浪費大量帶寬和時間。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Vera 是業界首款在硬體底層原生支持 FP8 的 CPU，可在數據餵給 Rubin GPU 之前，直接在 CPU 層面完成 FP8 的預處理和對齊，徹底消除數據格式轉換的延遲開銷。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NVLink 6 與硅光子 (CPO)</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在物理層面上，英偉達已經觸及多個工程與材料學的極限。接下來要說的從銅線到硅光子 CPO 的設計，正是這一極限的縮影。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">硅光子與 CPO 技術，是用極其高昂的製造成本與災難級的維護難度，換取打破物理極限的海量帶寬與極低功耗。銅線則以低廉的成本和極高的物理可靠性，在單機櫃內做最後的堅守。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但 R100 已經觸及了銅線的極限。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">上一代 Blackwell 架構的機櫃中，為實現 72顆算力晶片的全銅線互連，機櫃背板已塞滿五千多根極其沉重的粗壯銅纜。而 2026年發布的 NVLink 6 將單卡互連帶寬再次翻倍至 3.6 TB/s。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">如果繼續沿用純銅方案，機櫃內的銅纜數量將直接破萬。不僅在物理空間上根本塞不下，極其密集的線纜還會徹底堵死整個機櫃的散熱風道。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">更致命的是，在極高頻信號傳輸下，銅線的電阻會導致嚴重的信號衰減。為了把電信號\"硬推\"過去，系統必須消耗巨大的電力。在單機櫃功耗已極度誇張的 Rubin 時代，這種因信號衰減帶來的無謂能耗完全不可接受。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">因此，英偉達從銅線轉向硅光子 CPO，與其說是主動選擇，不如說是一種不得不做的權衡與取捨。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NIM 2.0 與推理儲存</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">R100 的核心關鍵詞是\"Agentic AI\"。前文介紹的是硬體層面對 Agentic AI 的支撐，而 NIM 則是硬體與軟體的協同。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">NIM 2.0 是專為多智能體（Multi-Agent）協同計算設計的標準化軟體容器與調度總線，作用是實現不同 AI 模型間的極速數據交互與算力分配。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">在軟體層面將不同的 AI 模型封裝好，以極低延遲互相調用，並全自動地將複雜任務拆解、分發。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">推理儲存（Inference Storage） 則是針對大模型超長上下文（KV Cache）專門構建的物理多級內存架構，作用是徹底打破單卡顯存容量的物理上限。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">模型推理時的上下文數據不再頻繁往返於主存，而是在網路交換階段就被動態緩存。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">二者軟硬結合，解決了 Agentic AI 在處理百萬字級別複雜任務時的延遲與內存溢出瓶頸。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">傳統推理服務框架主要針對單一模型（如讓單個 LLM 不斷生成文本）進行串行優化，而在 Agentic AI 工作流中，往往需要多個模型高頻並發協作。NIM 2.0 正是為此重構的軟體基礎設施。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">另外，代表未來方向的 GR00T 與 Cosmos 進化至 2.0 版本。英偉達與寶馬、特斯拉等工廠深度綁定，2026年已有數十萬台由 GR00T 2.0 驅動的協作機器人通過英偉達 Isaac 平台實現雲端聯動。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">至此，英偉達的發展脈絡已全部梳理完畢。</p></section><section style=\"margin-top:30px\"><h3 style=\"text-align: left;\">後記</h3></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">研究英偉達的過程中，我深深為其兩個方面折服：</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">1）黃仁勛的判斷力</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2012年 ImageNet 大賽，Alex Krizhevsky 憑藉兩塊普通的英偉達 GTX 580 遊戲顯卡，將圖像識別錯誤率從 26% 降至 15.3%，以領先第二名 10.8% 的驚人優勢震驚世界。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2013年，黃仁勛將重心全面轉向 CPU。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">要知道，這距離 Google 發表論文 《Attention is All You Need》，提出了 Transformer 架構，奠定現代 LLM 大模型基礎還有 4年時間。彼時晶片領域競爭還在更通用的 CPU 領域。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">此後，黃仁勛幾乎判斷對了每一個關鍵節點的選擇。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2006年，沒人知道 CUDA 有什麼用，他每年燒掉 5億美元堅持投入。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2017年，科學計算界還在追求 FP64 的絕對精確，他敢在最貴的晶片上劃出大片面積給當時只有少數人在用的矩陣運算做專用電路。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2018年，行動網路浪潮正盛，他果斷放棄手機晶片，把全部資源押注數據中心。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">2022年，他親手把第一台 DGX-1 送進了還名不見經傳的 OpenAI 辦公室。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">每一次決策，在當時看來都近乎瘋狂。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這種判斷力並非來自先知式的預言，而是來自對技術底層邏輯的深刻理解。黃仁勛始終在問一個問題：計算的未來是什麼？他的答案也始終如一：並行計算終將取代串行計算，專用效率終將戰勝通用性能。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這個信念貫穿了英偉達從 CUDA 到 Tensor Core，從 NVLink 到 Rubin 的整條發展脈絡。</p></section><section style=\"margin-top:30px\"><h4 style=\"text-align: left;\">2）英偉達的工程能力</h4></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">英偉達的晶片迭代多次觸及物理極限，為此做出的創新、權衡與取捨，不僅涉及通信、材料、光學領域，更延伸至量子物理學的邊界。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">混合精度是一種權衡，用模糊換速度。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">結構化稀疏是一種權衡，用裁剪換容量。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從銅線到硅光子是一種權衡，用製造難度換傳輸極限。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">每一代架構的進步，都不是簡單地把數字做大，而是在精度與效率、通用與專用、成本與性能之間反覆尋找最優解。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這背後是一支極其龐大且深入底層的工程團隊。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">cuDNN 里的卷積算法經過了十餘年手工匯編級優化；TensorRT 的算子融合精確到每一條 kernel 的調度策略；TMA 的異步搬運機制讓計算與數據傳輸真正實現了並行。這些看不見的底層功夫，才是 CUDA 生態護城河最深處的基石。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">更難得的是，英偉達在硬體和軟體之間搭建了一座極其堅固的橋樑。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從 CUDA 到 cuDNN，從 TensorRT 到 NIM，從晶片到機櫃再到整個數據中心，每一層都嚴絲合縫地咬合在一起。競爭對手即便在某一層追上來，也很難在整個棧上同時追平。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這不是一家只會造晶片的公司，而是一家從晶體管到軟體容器、從單卡到萬卡集群、從算法到物理定律都在同時推進邊界的系統級公司。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">回望英偉達的崛起之路，最讓我感慨的是一個樸素的道理：真正的護城河，從來不是某一項單點技術，而是無數個正確決策在時間軸上的複利。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">CUDA 用了十年才等來深度學習的爆發。Tensor Core 用了五年才等來 Transformer 的統治。NVLink 用了三代才從點對點連接進化為全互聯網路。每一項技術在誕生之初都顯得超前甚至多餘，但當歷史的浪潮真正湧來時，它們恰好就在那裡。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這大概就是黃仁勛常說的那句話最好的註腳——</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">\"我們公司距離倒閉永遠只有 30 天。\"</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">正是這種危機感，驅動英偉達在每一個別人覺得\"還早\"的時刻，提前十年布局。而當風口真正到來時，所有人才發現：跑道上只剩英偉達一個人。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">最後，說幾句感想。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">除了英偉達，研究過程中更讓我心生敬畏、甚至心潮澎湃的是人類所展現出的智慧。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">單顆 B200 晶片上集成了 2080億個晶體管。2080億是什麼概念？銀河系中肉眼可見的恆星大約 6000億顆，一顆指甲蓋大小的晶片上，晶體管數量已經是同一個數量級。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">而這 2080億個晶體管，不是一顆一顆焊上去的，是光刻出來的，用波長僅 13.5 納米的極紫外光，穿過極其精密的掩模版，將電路圖案投射到硅片上，一層一層地\"印刷\"而成。每一層的對準精度要求在亞納米級別，相當於從地球上用激光瞄準月球表面的一枚硬幣。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">當晶體管的柵極長度縮小到 3 納米甚至更小時，電子的行為不再完全遵循經典物理學，量子隧穿效應開始顯現，電子會像幽靈一樣穿過本應是絕緣體的薄壁。換句話說，晶片工程已經觸及了量子力學中測不準原理的邊界。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這也正是 B200 不得不採用\"雙芯一體\"拼接方式的根本原因：單塊硅片已經逼近了當前光刻技術與物理定律的極限，繼續做大隻會讓良品率崩塌。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">於是工程師換了一種思路。既然一塊做不到，就把兩塊完美拼在一起，再用 NVLink-C2C 以 10 TB/s 的帶寬縫合為一個整體，讓軟體層完全感知不到接縫的存在。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">從量子物理到材料科學，從光學工程到封裝技術，一顆晶片的誕生匯聚了人類幾乎所有前沿學科的智慧結晶。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">想起茨威格一本著作《人類群星閃耀時》。我們用沙子造出了思考的機器，又用這台機器去探索宇宙、模擬物理、甚至試圖理解意識本身。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這或許是比任何一家公司的崛起都更值得書寫的故事。</p></section><section style=\"margin-top:30px\"><p>來源：金色財經</p></section><section style=\"margin-top:30px\"><p>發佈者對本文章的內容承擔全部責任<br/>在投資<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">加密貨幣</a>前，請務必深入研究，理解相關風險，並謹慎評估自己的風險承受能力。不要因為短期高回報的誘惑而忽視潛在的重大損失。</p></section></main>",
            "link": "https://news.cnyes.com/news/id/6355301",
            "pub_date": "2026-02-26 18:30:23",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        },
        {
            "id": 6355302,
            "title": "以太坊怎麼了？",
            "description": "<main class=\"c1tt5pk2\" id=\"article-container\" style=\"--c1tt5pk2-0:20px\"><section style=\"margin-top:30px\"><p style=\"text-align: left;\">作者：Pavel Paramonov 編譯：白話區塊鏈</p></section><p></p><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這篇文章的靈感主要來自 Vitalik 最近關於市場現狀和變化的推文。雖然整個市場都在下跌，很難具體歸咎於某個人，我也不打算這樣做。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section><p style=\"text-align: left;\">我曾與許多<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>團隊合作，代表風險基金投資過多個構建在<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>上的協議，總的來說，我曾是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>及 EVM 相關事物的狂熱粉絲。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">遺憾的是，我再也無法說出同樣的話了，因為我覺得<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>不知道自己要往哪裡走（很多人也有同感）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我不想討論 ETH 的價格走勢，但我不能忽視一個事實：全球排名第二的<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">加密貨幣</a>表現得極其不穩定。無論全球市場走向如何，ETH 的表現更像是一個正在脫錨的穩定幣。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這篇隨筆旨在探討過去幾年<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>發生了什麼，以及為什麼許多人正在失去希望或已經失去希望。<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>並不是輸給了 Solana 或其他競爭對手，<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>是輸給了它自己。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">匯總中心化路線圖 (Rollup-centric Roadmap)</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">當<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>引入以 Rollup 為中心的路線圖時，幾乎所有人都感到興奮。當時的承諾是，Rollup（和 Validiums）將承擔擴容任務，終端用戶的交易將發生在 Rollup 上，而<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>將作為驗證層，即專注於成為 Rollup 的 L1，而不是直接面向用戶的 L1。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">開發 Rollup 比開發 L1 要快得多、容易得多，因此「成千上萬個 Rollup」的願景看起來非常可能且樂觀。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">哪裡出了問題？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">事實證明，一切都出了問題。無休止的爭論、意識形態凌駕於需求之上、社區內的持續內鬥、身份危機，以及放棄「匯總中心化」願景的時機太晚。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">凡是可能出錯的地方都出錯了。大部分社區曾認為 Max Resnick 是一個完全無能的惡人，結果卻發現他在幾乎所有事情上都是正確的。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Max 在 Consensys 工作期間，提出了大量關於<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>如何前進的建議，但只遭到了批評，幾乎沒有得到支持。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">最愚蠢的巔峰是，整個行業開始討論某個 L2 到底是不是「<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>」，例如：</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">觀點 A：「Base 是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的延伸，我們為<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>生態做出了巨大貢獻。」</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">觀點 B：「Base 不是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的延伸，它是一個獨立的個體。」</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我們到底在討論什麼鬼東西？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這種對話如何能引導<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>及其生態系統走向更好的未來？為什麼人們會嚴肅地爭論什麼是核心<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>，什麼不是？難道我們沒有更重要的問題要解決嗎？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這種意識形態的討論根本不是討論，而是兩個小圈子（circlejerks）之間的對抗，試圖證明誰才是正確的。我們不需要內耗（PvP），我們需要對外擴張（PvE）。 我們需要理解，這不是我們之間的對抗，而是我們共同面對問題和未來。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">不幸的是，很多人寧願追求精神快感，也不願考慮自己的觀點可能是錯誤的。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">技術意識形態優先於用戶需求</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Based Rollups, Booster Rollups, Native Rollups, Gigagas Rollups, Keystore Rollups... 哪一個更好，未來會怎樣，它們如何連接？ 「這種類型才是未來」，「不，那種類型才是未來」。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">所有的這些討論……結果只是 Arbitrum 和 Base 繼續大獲全勝。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">技術優越性能帶來優勢，但當你比較「蘋果與梨」或者「橙子與柑橘」時，這種優勢就消失了。它們太相似了，相似到用戶根本不在乎。 泡沫之外的人沒人在意。多一個預編譯，少一個預編譯——你不會因此獲勝。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">「噢，我們其實是『<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>對齊』（<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">Ethereum</a>-aligned）的，我們有優勢，我們與<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>非常親近，體現了它的核心價值觀，用戶會選擇我們。」</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我想問，哪些價值觀？又是哪些用戶會選擇你？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">@0xFacet 成為了第一個達到階段 2（Stage 2）的 Rollup，他們是對齊<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的典範。 但他們在哪裡？ 他們的用戶、開發者、技術 KOL 以及那些支持<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>生態和對齊的擁護者都在哪裡？你們中有多少人聽說過 Facet？Facet 上有多少應用可用？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我對 Facet 個人沒有意見，我尊重它的創始人。但那些口口聲聲說我們需要更多「階段 2」Rollup 的人去哪了？ 我不知道，你也不知道。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">財務激勵遠比技術激勵強大。 我曾是 Taiko 的粉絲，尤其是他們對 Based Rollups 的研究。這種模式有很多好處：更強的抗審查性、中立性、無測序器宕機風險、L1 驗證者賺更多錢。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">陷阱在哪？</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">陷阱在於模型背後的財務。你不能強迫人們為了所謂的「對齊」而放棄收入。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Arbitrum 承諾過去中心化測序器，Scroll、Linea、zkSync 和 Optimism 也都承諾過。它們在哪？那些測序器在哪？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">每個 Rollup 團隊在文檔里都寫着：「我們目前使用中心化測序器，但未來有強烈的去中心化意願。」幾乎沒有人兌現。 Metis 兌現了，但幸運或不幸的是，人們並不在乎 Metis。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我認為他們是為了討好有影響力的 ETH 原教旨主義者（Maxis）而過度承諾嗎？是的。 我認為他們真的想去中心化測序器嗎？也是肯定的，但這在商業上說不通。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Coinbase (Base) 在法律上有義務儘可能多地賺錢，為公司創造價值。其他團隊也一樣，你為什麼要親手殺掉自己的收入來源？這根本不符合邏輯。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Base 的收入中大約只有 5% 回流到了<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>。Rollup 從來就不是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的延伸。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Taiko 曾經有過這樣的日子：它付給<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的排序費比它從用戶交易中收取的費用還要多。顯然，像 Taiko 這樣的公司除了付給<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>費用外，還有很多其他開支。Based Rollups 或任何「<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>對齊」的願景，只有在團隊願意放棄收入的情況下才可能實現。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我沒有低估去中心化、安全性和無許可的重要性。但當你唯一的目標只是為了「意識形態正確」而非「以用戶為中心」時，這一切都失去了意義。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">不出所料，這種弱點和對「<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>對齊」的承諾引來了大批投機者（grifters）。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">匯總中心化路線圖的後果</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Eclipse, Movement, Blast, Gasp (Mangata), Mantra：這些協議從未打算為了長遠未來而構建。 躲在「<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>對齊」、讓<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>變得更好、把 SVM 引入<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>等假面具後面非常容易。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">他們都在某種程度上「軟割肉」（rugged）了。 所有的 Rollup 都意識到他們的 Token 幾乎沒用，因為他們用 ETH 支付費用，而自己的 Token 幾乎沒有實用價值。投機者意識到，你可以圍繞 Rollup 中心敘事製造大量炒作，然後通過向散戶拋售毫無價值的 Token 來變現。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\"><a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>從未承認 Polygon 是真正的 L2，儘管他們在保障 ETH 價值方面發揮了重要作用。如果你相信 Rollup 是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的「文化」延伸，為什麼不承認一個與<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>安全和使用緊密相連的項目？</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Polygon 在 2021 年牛市中對<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>至關重要，為 ETH 作為資產的增長貢獻良多。但沒錯，它不是 L2，不配得到<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>社區的讚賞。如果 Polygon 是一個 L1，它的估值會高得多。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">甚至連 Paradigm 這種可以說對<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>生態貢獻最大、甚至開發了自己 L2 (Ithaca) 的頂級 VC，也轉向了與 Stripe 合作開發 L1 (Tempo)。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我認為，當你的頭號信徒開始去構建你的競爭對手時，說明你一定做錯了什麼。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\"><a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>基金會（EF）缺乏方向</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">儘管<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>在技術上是去中心化的，但在文化上是圍繞 Vitalik 高度中心化的。 <a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的內部圈子是真實存在的。正如人們所說，你想要成功，所要做的就是獲得 Vitalik 身邊的人以及那幾個有影響力的 VC 的關注。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我並不是說你必須同意 Vitalik 的每一句話，但他的觀點基本上定義了對<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>而言什麼是好，什麼是壞，你無法與之競爭。</p></section><section style=\"margin-top:30px\"><p style=\"text-align:center\"></p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">首先是超強貨幣（ultrasound money），由於 EIP-1559 和合併，ETH 的經濟模型變得具有通縮性，認為它會比<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">比特幣</a>是更好的價值儲存。但在 2024 年，ETH 的年通膨率轉正了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">所以超強貨幣的願景只持續了 3 年？這樣是不可能成為價值儲存的。這個敘事已經死了，而且它從未真實過，因為 ETH 本就不是為了成為價值儲存而設計的，那是<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">比特幣</a>的使命，你無法競爭。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">接着，<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>無法決定它的 Token 究竟是商品（由於動態供應變化和質押機制而不適用），還是更像科技股（由於收入不足以支撐像科技公司那樣的估值而不適用）。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">還有人爭論 ETH 根本不是錢。這到底在搞什麼？我們需要選定一個方向。 <a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>不能同時是多種東西——你要麼有一個全球統一的定義方向，要麼就會落後。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">財務激勵……再次缺失</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">我至今無法想象，像 Péter Szilágyi 這樣的首席工程師，為<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>做出的貢獻每年只拿到大約 10 萬美元。這個從一開始就在這裡、幫助<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>從零達到 4500 億美元市值的功臣，薪酬僅占市值的 0.0001%。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">加密史上最有影響力、最成功的協議（僅次於<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">比特幣</a>）竟然沒有提供任何激勵或股權。 躲在去中心化、開源和無許可的信條後面很容易辯解：「我們不是為了賺錢，是為了進步。」</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但你必須激勵即使是最忠誠的戰士，否則他們會離開，或者在私下裡接單。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Péter 離開了，Danny Ryan 離開了，Dankrad Feist 直接去了 Tempo。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">Justin Drake 和 Dankrad 在 2024 年接受了 EigenLayer 的顧問職位並獲得了 Token 分配，結果社區就開始仇恨他們。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">這些在 EF 拿「花生米」薪水的人（相比 FAANG 公司和 AI 實驗室），僅僅因為賺了錢並幫助一個想要讓<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>變得更好的協議（即使它不是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>本身），就遭到了攻擊。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">你們是傻子嗎？ 有時我覺得，如果你在<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>是一個誠實勤奮的人，你就被剝奪了賺錢的權利，被期望為了得到<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>方面的「認可」而像奴隸一樣工作。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">EF 一直在拋售 ETH 來資助各種營運和研究。但也許應該先給你們的研究員發夠工資？</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">對適應性的零容忍</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">「第一天。<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>終將獲勝。擁有最高運行時間的去中心化區塊鏈。」 我們每天都聽着這些話，就像每天都聽着<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的藉口一樣。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">是的，<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>又貴又慢。 但我們有 Rollup，用 Rollup 吧，Rollup 就是<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>！</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">是的，ETH 價格滯後。 但<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>擁有最大的開發者生態，我們有堅實的基礎，需求會隨之而來的。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\"><a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>是最去中心化的！ Solana 垃圾，他們沒有客戶端多樣性。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\"><a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a> 100% 運行時間！ Solana 垃圾，宕機了好幾次。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\"><a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>的網路活躍度低於 Solana。 那是因為 Solana 的活動都是垃圾郵件和土狗賭徒。我們是道德的鏈！</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">你知道嗎，看到人們意識到自己的錯誤，我是開心的，這需要勇氣。但我認為這可能已經太晚了。 <a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>再次找到了它長期需要走的路徑，但進展依然緩慢。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">EF 最近確實發生了一些變化：新的領導層、國庫透明化、研發重組等等。EF 開始僱傭像 Abbas Khan、Binji、Lou3e 這樣年輕且有才華的 DevRel 和市場人才。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但變革必須快。<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>必須全力衝刺來證明所有人都錯了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">讓我們看看，在這些改革和 EF 的變動之後，我們能否看到<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>再次成為令人興奮的對象，而不是盲目、妄想式的信仰和失望的對象。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">同樣的藉口，同樣的回答，同樣的反應，年復一年。 除了<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>和 Rollup，其他一切都是垃圾。如果<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>在任何指標上表現不佳，我們就說「這才是第一天」，我們知道自己在做什麼，沒有比<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>更好的地方了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">每個人都聽膩了社區一遍又一遍找的藉口。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\"><a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>給人的感覺就像一個走路都費勁、拒絕任何創新的有錢老奶奶，但卻把錢分給那些寄生在她身上的子孫後代。</p></section><section style=\"margin-top:30px\"><h2 style=\"text-align: left;\">變革</h2></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">就在我快寫完這篇隨筆前幾個小時，Vitalik 發推表示匯總中心化路線圖是一個失敗，他們需要尋找另一條路徑並對 L1 進行擴容。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">你知道嗎，看到人們意識到自己的錯誤，我是開心的，這需要勇氣。但我認為這可能已經太晚了。 <a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>再次找到了它長期需要走的路徑，但進展依然緩慢。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">EF 最近確實發生了一些變化：新的領導層、國庫透明化、研發重組等等。EF 開始僱傭像 Abbas Khan、Binji、Lou3e 這樣年輕且有才華的 DevRel 和市場人才。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">但變革必須快。<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>必須全力衝刺來證明所有人都錯了。</p></section><section style=\"margin-top:30px\"><p style=\"text-align: left;\">讓我們看看，在這些改革和 EF 的變動之後，我們能否看到<a href=\"https://crypto.cnyes.com/ETH/24h\" target=\"_blank\">以太坊</a>再次成為令人興奮的對象，而不是盲目、妄想式的信仰和失望的對象。</p></section><section style=\"margin-top:30px\"><p>來源：金色財經</p></section><section style=\"margin-top:30px\"><p>發佈者對本文章的內容承擔全部責任<br/>在投資<a href=\"https://crypto.cnyes.com/BTC/24h\" target=\"_blank\">加密貨幣</a>前，請務必深入研究，理解相關風險，並謹慎評估自己的風險承受能力。不要因為短期高回報的誘惑而忽視潛在的重大損失。</p></section></main>",
            "link": "https://news.cnyes.com/news/id/6355302",
            "pub_date": "2026-02-26 18:30:24",
            "source": "cnyes",
            "kind": 1,
            "language": "zh-HK"
        }
    ]
}