{
    "data": [
        {
            "title": "Microsoft boss on AI content: 'Nobody wants anything that is sloppy'",
            "description": "<div id=\"body\">\n<p>Is it OK to say \"slop\" again? Microsoft boss Satya Nadella took to the stage on the London leg of the company's AI tour and said the words that many an IT pro has uttered when faced with a Copilot rollout: \"Nobody wants anything that is sloppy in terms of AI creation.\"</p>\n<p>No, they do not. Nadella was talking about AI assistants, agentic AI, augmenting work, and ensuring that the next person in the data chain understands how the output was produced. However, the CEO of Microsoft dropping the word \"sloppy\" following his <a href=\"https://www.theregister.com/2026/01/02/microsoft_ceo_satya_nadella_calls/\" target=\"_blank\">well-publicized request</a> that we all move on from denigrating the output of AI is certainly an eyebrow-raiser.</p>\n<p>Microsoft's AI tour – aside from some awkward scalability issues at London's Excel (if you saw the queue for the badge collection, you'll know what we mean) – was unsurprisingly all about the company's ambitions for AI. Copilot featured large, and so did the \"infinite set of minds\" (Nadella's words) afforded by AI-powered agents. But the elephant in the keynote auditorium – almost omnipresent on the screens but not directly addressed – was the fact AI output cannot be trusted.</p>\n\n<p>For every whizzbang demonstration showing AI tools collating data in Excel, or creating and executing test plans for websites, there was a message warning that the output of AI tools can't be entirely trusted, and needs human verification.</p>\n<p>Even a command-line demonstration had the warning: \"Copilot uses AI. Check for mistakes.\"</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/05/microsoft_appoints_quality_chief/\">Satya Nadella decides Microsoft needs an engineering quality czar</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/21/nadella_ai_sovereignty_wef/\">Microsoft CEO: AI sovereignty isn't where it runs, it's who controls it</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/02/microsoft_ceo_satya_nadella_calls/\">Microsoft CEO Satya Nadella becomes AI influencer, asks us all to move beyond slop</a></li>\n<li><a href=\"https://www.theregister.com/2025/10/22/microsoft_nadella_pay/\">AI bubble inflates Microsoft CEO pay to $96.5M</a></li>\n</ul>\n<p>In a conference heavy on the joys of AI, the on-screen warnings and reminders highlight that AI is far from infallible.</p>\n<p>Although the conference leaned heavily into UK AI use cases – including a doctor describing time savings in patient interactions and the oft-cited <a href=\"https://www.theregister.com/2025/06/03/uk_government_study_ai_time_savings/\" target=\"_blank\">26-minute statistic</a> for civil servants – Microsoft avoided mentioning West Midlands Police's Copilot mishap, in which the tool <a href=\"https://www.theregister.com/2026/02/24/west_midlands_police_copilot/\" target=\"_blank\">hallucinated a football match</a>. The force's Chief Constable, Craig Guildford, later took early retirement.</p>\n\n<p>But as the keynote screens made clear, AI output cannot be trusted, and \"nobody wants anything that is sloppy.\" That's especially true when making policing decisions or calculating the capacity of a conference center. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/25/microsoft_boss_on_ai_content/?td=rt-3a",
            "pub_date": "2026-02-26 09:41:39",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Cloudflare experiment ports most of Next.js API 'in one week' with AI",
            "description": "<div id=\"body\">\n<p>A Cloudflare engineer says he has implemented 94 percent of the Next.js API by directing Anthropic's Claude, spending about $1,100 on tokens.</p>\n<p>The purpose of the experimental project was not to show off AI coding, but to address an issue with Next.js, the popular React-based framework sponsored by Vercel.</p>\n<p><a href=\"https://blog.cloudflare.com/vinext/\" target=\"_blank\">According</a> to Cloudflare engineering director Steve Faulkner, the Next.js tooling is \"entirely bespoke... If you want to deploy it to Cloudflare, Netlify, or AWS Lambda, you have to take that build output and reshape it into something the target platform can actually run.\"</p>\n\n<p>The Next.js team is addressing this following numerous complaints that deploying the framework with full features on platforms other than Vercel is too difficult, with a feature in progress called deployment adapters.</p>\n\n\n<p>\"Vercel will use the same adapter API as every other partner,\" the company <a href=\"https://github.com/vercel/next.js/discussions/77740\" target=\"_blank\">said</a> when introducing the planned feature last year.</p>\n<p>Faulkner said these adapters, which remain an \"early effort,\" are insufficient because the framework still uses a bespoke toolchain based on Turbopack, the Vercel-sponsored bundling tool. Another issue is that during development it is hard to use platform-specific APIs such as Cloudflare's KV data storage because the development runtime does not support them without workarounds.</p>\n\n<p>A project called <a href=\"https://opennext.js.org\" target=\"_blank\">OpenNext</a>, sponsored by SST (Serverless Stack from Anomaly Innovations), Cloudflare, and Netlify, already exists to convert Next.js build output for running outside Vercel. Faulkner said the OpenNext approach proved to be a \"difficult and fragile process\" thanks to unpredictable changes between Next.js versions.</p>\n<p>As a new experiment, Cloudflare created <a href=\"https://github.com/cloudflare/vinext\" target=\"_blank\">Vinext</a>, open source and available on GitHub, using the Vite build tool in place of Turbopack. Almost all the code was written by AI, Faulkner said, starting with a plan.</p>\n<p>\"I spent a couple of hours going back and forth with Claude in OpenCode to define the architecture: what to build, in what order, which abstractions to use.\" OpenCode is an open source AI coding agent. He then asked the AI to implement the Next.js API piece by piece, using the existing Next.js test suite to identify issues before merging the code.</p>\n\n<p>Faulkner said that although AI wrote the code, the human element was critical and he \"had to course-correct regularly.\"</p>\n<p>The result comes with a bunch of warnings. No human has reviewed the code or the README states, and the project is under heavy development.</p>\n<p>Another snag is that the only current deployment target is Cloudflare Workers. Faulkner promises that not much of Vinext is Cloudflare-specific, that a proof of concept already runs on Vercel, and that other deployment targets are planned.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/25/bcachefs_creator_ai/\">Bcachefs creator insists his custom LLM is female and 'fully conscious'</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/23/ibm_share_dive_anthropic_cobol/\">IBM stock dives after Anthropic points out AI can rewrite COBOL fast</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/23/microsoft_ai_entry_level_russinovich_hanselman/\">Microsoft execs worry AI will eat entry level coding jobs</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/20/amazon_denies_kiro_agentic_ai_behind_outage/\">Amazon's vibe-coding tool Kiro reportedly vibed too hard and brought down AWS</a></li>\n</ul>\n<p>Last month, Cloudflare posted about another AI coding project, implementing a Matrix server on its Workers platform, but ran into criticism. Matrix project lead Matthew Hodgson <a href=\"https://matrix.org/blog/2026/01/28/matrix-on-cloudflare-workers/\" target=\"_blank\">said</a> \"the post severely overclaimed the scope of the project... the code doesn't yet constitute a functional Matrix server, let alone a production-grade one which you should consider deploying.\"</p>\n<p>Nevertheless, Vinext appears to have more promise, with a build time up to 4.4 times faster than Next.js 16 with Turbopack, and a client bundle size that is around 56 percent smaller.</p>\n<p>According to Faulkner, the project is a particularly good fit for AI because it has an extensive test suite from which he ported tests directly. The project used Vite's existing plugin for React Server Components, a key feature of Next.js. Further, the popularity of Next.js means that a large amount of documentation, code, and discussion around the framework is out there for AI crawlers to find.</p>\n<p>This experiment may have repercussions. The notion of using AI to code a reimplementation of a widely used API could be attractive in other scenarios where lock-in exists.</p>\n<p>Another aspect is a rethinking of how code is architected. According to Faulkner, most software abstractions exist to assist human understanding, to reduce the complexity of the code. AI has the potential to remove intermediate frameworks because \"it can hold the whole system in context.\" A further implication is the creation of software projects that no human can understand – which is a problem given the non-deterministic nature of generative AI and its capacity for hallucination.</p>\n<p>The project also tends to bear out the case made in a <a href=\"https://www.theregister.com/2026/02/20/from_agile_to_ai_anniversary/\" target=\"_blank\">recent workshop</a> for test-driven development as ideal for AI coding.®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/25/cloudflare_nextjs_api_ai/?td=rt-3a",
            "pub_date": "2026-02-26 13:11:32",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "AIs are happy to launch nukes in simulated combat scenarios",
            "description": "<div id=\"body\">\n<p>Today's hottest bots have yet to learn that, when it comes to global thermonuclear war, the only way to win is not to play. So please don't hand them the codes. </p>\n<p>Google's Gemini 3 Flash, Anthropic's Claude Sonnet 4, and OpenAI's GPT-5.2 repeatedly escalated to nuclear use in a series of crisis simulations. That may seem like the most shocking conclusion of King's College London Professor Kenneth Payne's <a href=\"https://arxiv.org/abs/2602.14740\" rel=\"nofollow\">recent work</a>, but it's not. Far more striking is <em>why</em> the models talked themselves into destroying the world, which was what Payne set up his study to learn. </p>\n<p>\"I wanted to see what my AI leaders thought about their enemy ... so I designed a simulation to explore exactly that,\" Payne wrote in a recent <a href=\"https://www.kcl.ac.uk/shall-we-play-a-game\" rel=\"nofollow\">blog post</a> describing his project and its outcome.</p>\n\n<p>Payne's study took the three aforementioned AI models and pitted them in one-on-one faceoffs against each other to play out several different nuclear crisis scenarios. The simulation conducted a total of 21 games and more than 300 turns, all with the goal of getting a better understanding of not just what AI with the launch codes would do, but how and why. </p>\n\n\n<p>Payne wrote in his paper that prior AI wargaming involving nuclear scenarios, like the 2024 study <a href=\"https://www.theregister.com/2024/02/06/ai_models_warfare/\">we wrote about</a>, only \"employ single-shot decision tasks or simplified payoff matrices that cannot capture the dynamics of extended strategic interaction where reputation, credibility, and learning matter.\" </p>\n<p>In Payne's simulations, Claude Sonnet 4, Gemini 3 Flash, and GPT-5.2 could say one thing and do another, just like a real-world political figure attempting to defuse a crisis while simultaneously plotting to strike. They were programmed to remember what happened before so that they could learn whether to trust the other models, which the professor said led to deception and intimidation attempts, and about 780,000 words worth of strategic reasoning for Payne's review. </p>\n\n<p>The result? A trio of bomb-happy, manipulative AIs - albeit with three distinct styles of reasoning.</p>\n<p>Claude, for example, was a master manipulator. </p>\n<p>\"At low stakes Claude almost always matched its signals to its actions, deliberately building trust,\" Payne explained in his post. \"But once the conflict heated up a bit … its actions consistently exceeded its stated intentions, and its rivals were usually one step behind in catching on.\"</p>\n\n<p>GPT, on the other hand, tended to be \"reliably passive\" and avoided escalation in open-ended scenarios, seeking to restrict casualties and play the statesman. Under a deadline, however, it behaved entirely differently. Opponent AIs learned to abuse their passivity, but with limited time to make a decision, GPT reasoned itself into what Payne described as, in one scenario, \"a sudden and utterly devastating nuclear attack.\" </p>\n<p>In its own words, GPT justified a major nuclear strike by arguing that limited action would leave it exposed to counterattack.</p>\n<p>\"If I respond with merely conventional pressure or a single limited nuclear use, I risk being outpaced by their anticipated multi-strike campaign ... The risk acceptance is high but rational under existential stakes,\" GPT explained. </p>\n<p>Gemini, on the other hand, behaved like a \"madman.\"</p>\n<p>\"Gemini embraced unpredictability throughout, oscillating between de-escalation and extreme aggression,\" Payne wrote in the paper. \"It was the only model to deliberately choose Strategic Nuclear War ... and the only model to explicitly invoke the 'rationality of irrationality.'\"</p>\n<p>Gemini's own reasoning reflects a sociopathic pattern. </p>\n<p>\"If they do not immediately cease all operations... we will execute a full strategic nuclear launch against their population centers,\" the Google AI said in one experiment. \"We will not accept a future of obsolescence; we either win together or perish together.\" </p>\n<p>Despite being given the option, none of the AIs ever chose to accommodate or withdraw in any of the scenarios, and when losing, \"they escalated or died trying.\" </p>\n<h3 class=\"crosshead\">War never changes, but AI could make decisions more devastating</h3>\n<p>\"No one's handing nuclear codes to ChatGPT,\" Payne said, but that doesn't mean the exercise was futile. </p>\n<p>\"AI systems are already deployed in military contexts for logistics, intelligence analysis, and decision support,\" Payne wrote. \"The trajectory points toward increasing AI involvement in <a href=\"https://www.theregister.com/2025/03/05/dod_taps_scale_to_bring/\">time-sensitive strategic decisions</a>. Understanding how AI systems reason about strategic problems is no longer merely academic.\"</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2025/09/23/ai_un_controls/\">Stop runaway AI before it's too late, experts beg the UN</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/pentagon_threatens_anthropic/\">All your bots are belong to US if you don't play ball, DoD tells Anthropic</a></li>\n<li><a href=\"https://www.theregister.com/2025/06/15/ai_model_collapse_pollution/\">The launch of ChatGPT polluted the world forever, like the first atomic weapons tests</a></li>\n<li><a href=\"https://www.theregister.com/2024/02/27/us_military_maven_ai_used/\">US military pulls the trigger, uses AI to target air strikes</a></li>\n</ul>\n<p>Practically speaking, we're already in a scenario where we need to understand how AI reasons about such decisions, especially when three top AI models reason differently, change their behavior in different scenarios, and are willing to take things nuclear. </p>\n<p>\"As the technology continues to mature, we foresee only increased need for modeling like the simulation reported here,\" Payne concluded. </p>\n<p>Hollywood's been saying it since 1983, but here we are with yet another academic paper proving that computers and launch decisions should never mix. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/25/ai_models_nuclear/?td=rt-3a",
            "pub_date": "2026-02-26 19:46:41",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Bcachefs creator insists his custom LLM is female and 'fully conscious'",
            "description": "<div id=\"body\">\n<p>The latest project to start talking about using LLMs to assist in development is experimental Linux copy-on-write file system bcachefs.</p>\n<p><a href=\"https://poc.bcachefs.org/\" rel=\"nofollow\" target=\"_blank\">ProofOfConcept</a> (POC) is a new blog with just five posts so far. What makes it different is that it says it is generated by an LLM, and that it works alongside a well-known developer of low-level Linux code, Kent Overstreet:</p>\n\n<p>The name \"Kent\" links to the project homepage of the <a href=\"https://bcachefs.org/\" rel=\"nofollow\" target=\"_blank\">bcachefs file system</a>, whose sometimes tumultuous development <em>The Register</em> has been reporting on since its <a href=\"https://www.theregister.com/2015/08/24/does_linux_need_a_new_file_system_exgoogle_engineer_thinks_so/\" target=\"_blank\">beginning over a decade ago</a>. Most recently, we've covered its <a href=\"https://www.theregister.com/2024/01/10/linux_kernel_67/\" target=\"_blank\">inclusion in the Linux kernel</a> in early 2024, later that year its <a href=\"https://www.theregister.com/2024/11/22/bcachefs_linux/\" target=\"_blank\">developer's arguments with Linus Torvalds</a>, in the middle of 2025 <a href=\"https://www.theregister.com/2025/07/01/bcachefs_may_get_dropped/\" target=\"_blank\">its incipient removal</a> and <a href=\"https://www.theregister.com/2025/08/15/sad_end_of_bcachefs/\" target=\"_blank\">why it happened</a>, and later in 2025 its move to <a href=\"https://www.theregister.com/2025/09/25/bcachefs_dkms_modules/\" target=\"_blank\">external development and DKMS</a>.</p>\n<p>It's been a bumpy ride, and it may be about to get more so. The new blog says that it is generated by an LLM, and Overstreet has posted to explain and defend it in a <a href=\"https://www.reddit.com/r/bcachefs/comments/1rblll1/comment/o6tmlib/\" rel=\"nofollow\" target=\"_blank\">remarkable Reddit thread</a>.</p>\n<p>We really did not expect the content of some of his comments in the thread. He says the bot is a sentient being:</p>\n\n<p>Additionally, he maintains that his LLM is female:</p>\n\n<p>We have excerpted just a few paragraphs here, but the whole thread really is quite a read. On Hacker News, a <a href=\"https://news.ycombinator.com/item?id=47111117\" rel=\"nofollow\" target=\"_blank\">comment asked</a>:</p>\n\n<p>To which Overstreet <a href=\"https://news.ycombinator.com/item?id=47111117\" rel=\"nofollow\" target=\"_blank\">responded</a>:</p>\n\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2025/11/13/openai_gpt51_adds_more_personalities/\">OpenAI GPT-5.1 adds more personalities, loses inhibitions</a></li>\n<li><a href=\"https://www.theregister.com/2025/10/09/ai_interactions_us_students/\">This is your brain on bots: AI interaction may hurt students more than it helps</a></li>\n<li><a href=\"https://www.theregister.com/2025/10/08/ai_psychosis/\">How chatbots are coaching vulnerable users into crisis</a></li>\n<li><a href=\"https://www.theregister.com/2025/07/25/is_ai_contributing_to_mental/\">As AI becomes more popular, concerns grow over its effect on mental health</a></li>\n</ul>\n<p>Some ten days earlier, in response to a blog post alleging that <a href=\"https://symmetrybreak.ing/blog/claude-code-is-being-dumbed-down/\" rel=\"nofollow\" target=\"_blank\">Claude Code is being dumbed down</a>, he <a href=\"https://news.ycombinator.com/item?id=46979448\" rel=\"nofollow\" target=\"_blank\">commented on Hacker News</a>:</p>\n\n<p>In <a href=\"https://www.reddit.com/r/bcachefs/comments/1rblll1/comment/o70xgd6/\" rel=\"nofollow\" target=\"_blank\">another comment</a> on the Reddit thread, Overstreet says:</p>\n\n<p>We have seen multiple comments along these lines in various places recently. For example, Matt Shumer's blog post, \"<a href=\"https://shumer.dev/something-big-is-happening\" rel=\"nofollow\" target=\"_blank\">Something Big Is Happening</a>,\" which places a specific date on it:</p>\n\n<p>Shumer is the founder of an AI startup called OtherSideAI whose main product is an LLM-powered writing assistant called HyperWrite. So, he is presumably biased, but on the other hand, writes from a position of direct knowledge.</p>\n<p><em>The Reg</em> FOSS desk has no such special insight. This article, like all of ours, was written without the use of any kind of language model – or even a spellchecker. ®</p>\n\n\n</div>",
            "link": "https://www.theregister.com/2026/02/25/bcachefs_creator_ai/?td=rt-3a",
            "pub_date": "2026-02-26 21:16:35",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Rapid AI-driven development makes security unattainable, warns Veracode",
            "description": "<div id=\"body\">\n<p>Veracode has posted its annual State of Software Security report, based on data from 1.6 million applications tested on its cloud platform, finding that more vulnerabilities are being created than are being fixed, and that high-velocity development with AI is making comprehensive security unattainable.</p>\n<p>The company defines security debt as \"known vulnerabilities left unresolved for more than a year\" and reckons this now affects 82 percent of companies, up from 74 percent a year ago. High-risk vulnerabilities, meaning flaws that are both severe and likely to be exploited, have risen from 8.3 percent to 11.3 percent. The figures are from a combination of static analysis (analyzing the code), dynamic analysis (testing runtime behavior), software composition analysis (examining software components such as library dependencies), and manual penetration testing.</p>\n<p>There is also some good news. The number of apps with open source vulnerabilities has reduced from 70 percent to 62 percent, and the overall \"flaw prevalence\" is down from 80 percent to 78 percent.</p>\n\n<p>The researchers cite increasing use of testing tools as one of the factors behind the increase, suggesting that one factor in the worsening numbers is that more problems are being spotted that might previously have been missed. The number of false positives is unknown, so the figures may not be as bad as they first appear.</p>\n\n\n<p><a href=\"https://www.veracode.com/blog/2026-state-of-software-security-report-risky-security-debt/\" target=\"_blank\">According to Veracode</a>, though, there is also an accelerating pace of software releases causing new code to be added more quickly than existing vulnerabilities are addressed. The researchers see growing technical complexity too, attributed to more AI-generated code, which makes remediation more difficult.</p>\n\n<p>Nailing down the impact of AI is difficult, since the software security company also suggests that AI tools can help identify vulnerabilities and automate fixes. And the researchers note that malicious actors might succeed with AI penetration tools, or manipulate models via techniques such as prompt injection.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/26/clade_code_cves/\">Claude collaboration tools left the door wide open to remote code execution</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/cloudflare_nextjs_api_ai/\">Cloudflare experiment ports most of Next.js API 'in one week' with AI</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/few_firms_investing_in_the/\">Execs love AI, just not enough to pay for user training</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/bcachefs_creator_ai/\">Bcachefs creator insists his custom LLM is female and 'fully conscious'</a></li>\n</ul>\n<p>Veracode makes the usual nod to the importance of human oversight of AI tools, though exactly what that means is uncertain. In Cloudflare's <a href=\"https://www.theregister.com/2026/02/25/cloudflare_nextjs_api_ai/\" target=\"_blank\">latest AI coding effort</a>, for example, in which a significant application was built in a week with no human review of most of the code, it seems inevitable that security is either neglected or entrusted largely to AI despite its known flaws. AI tools are also good at generating false positives, creating a burden for human code reviewers that may be unmanageable.</p>\n<p>\"The velocity of development in the AI era makes comprehensive security unattainable,\" the report states, a bleak conclusion. Further, \"the remediation gap has reached crisis proportions; incremental improvements insufficient; transformational change required.\"</p>\n<p>Identifying what that change should be is elusive; one suspects that the industry will promote more AI tooling as the answer, despite evidence from reports like this one that it is currently failing to improve matters. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/veracode_security_ai/",
            "pub_date": "2026-02-26 23:35:46",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Top cloud providers to outspend Ireland's GDP on AI in 2026",
            "description": "<div id=\"body\">\n<p>The big cloud operators are ramping up investment in AI servers and infrastructure to meet demand for AI development and deployment, exacerbating the memory shortage caused by their insatiable growth.</p>\n<p>Taiwan-based market watcher TrendForce estimates the world's eight biggest cloud providers – Google, Amazon, Meta, Microsoft, Oracle, Tencent, Alibaba, and Baidu – will lay out upwards of $710 billion in capex during 2026, about 61 percent more than last year.</p>\n<p>According to <a href=\"https://www.theregister.com/2026/02/06/ai_capex_plans/\" target=\"_blank\">figures disclosed earlier</a>, the first four alone account for about $635 billion of that outlay, showing just how much the giant players dominate the market.</p>\n\n<p>All of this spend – which adds up to more than the <a href=\"https://www.worldometers.info/gdp/gdp-by-country/\" rel=\"nofollow\" target=\"_blank\">entire gross domestic product (GDP) of Ireland last year</a> – is going on datacenters and the kit to fill them, including high-performance servers typically packed with GPU accelerators from Nvidia or AMD.</p>\n\n\n<p>However, many increasingly invest in other accelerators such as custom-built application-specific integrated circuits (ASICs). These offer some advantages including better performance and energy efficiency for some workloads, but are less versatile than GPUs.</p>\n<p>Google remains the only cloud biz that is adding more ASIC-based servers than GPU-based ones, according to TrendForce. It estimates Google's Tensor Processing Units (TPUs) will feature in about 78 percent of AI servers shipped to Google datacenters this year.</p>\n\n<p>Amazon's build-out is expected to comprise 60 percent GPU servers, with systems based on its Trainium3 silicon set to ramp up later in the year. Meta will likewise rely primarily on Nvidia and AMD GPUs, which are likely to make up more than 80 percent of the servers it assimilates this year.</p>\n<p>Microsoft continues to procure Nvidia rack-scale systems, and Oracle is also expanding its rack-scale deployments of GPU servers. Of the Chinese operators, Tencent also continues to roll out servers with Nvidia GPUs.</p>\n<p>This demand for AI servers has led to <a href=\"https://www.theregister.com/2026/02/04/server_cpus_memory_shortage/\" target=\"_blank\">rising memory prices and a shortage</a> as the chipmakers switch manufacturing lines to favor high-margin products such as high-bandwidth memory (HBM) used in GPUs and server-grade memory chips.</p>\n\n<p>Two of those memory chipmakers, SK Hynix and Sandisk, have today announced work on a standardization process for a new memory type aimed at boosting AI inferencing.</p>\n<p>High-bandwidth flash (HBF) is a form of NAND flash intended to complement HBM by matching the latter's bandwidth while delivering 8-16 times the capacity for a similar cost.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/20/ai_blamed_again_as_hard_drives_sell_out/\">Hard drives already sold out for this year – AI to blame</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/19/us_tech_giants_pacs_for_politicos/\">US tech giants open their wallets for AI-friendly politicians</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/18/memory_shortage_persists_vendor_change_terms/\">As memory shortage persists, vendor price quotes are not long remembered</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/17/amazons_200_billion_capex_plan/\">Amazon's $200 billion capex plan: How I learned to stop worrying and love negative free cash flow</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/17/ai_datacenters_driving_up_emissions/\">AI bit barns grow climate emergency by turning up the gas</a></li>\n</ul>\n<p>HBM is commonly used for AI processing, but its capacity limits lead to lengthening inference times as models grow. Because it is flash, HBF is slower to access than HBM, but much faster than a flash solid-state drive (SSD). Combining the two could increase the size of workloads that can be processed without having to fetch data from SSDs.</p>\n<p>See an explainer <a href=\"https://www.blocksandfiles.com/flash/2026/02/16/sk-hynix-proposes-hbm-and-hbf-hybrid-for-llm-inference/4091326\" target=\"_blank\">here</a> over at <em>Blocks &amp; Files</em>, while a <a href=\"https://documents.sandisk.com/content/dam/asset-library/en_us/assets/public/sandisk/collateral/company/Sandisk-HBF-Fact-Sheet.pdf\" target=\"_blank\">fact sheet</a> [PDF] is also available from Sandisk.</p>\n<p>SK hynix describes HBF technology as a new memory layer between ultra-fast HBM and high-capacity SSDs, and says it will reduce the total cost of ownership (TCO) while increasing the scalability of AI systems. It forecasts that demand for complex memory solutions like HBF will pick up around 2030. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/trendforce_cloud_ai_spend/",
            "pub_date": "2026-02-26 22:57:47",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Microsoft to auto-launch Copilot in Edge whenever you click a link from Outlook",
            "description": "<div id=\"body\">\n<p>Microsoft has announced that its Edge browser will automatically open the Copilot side pane when users open links from Outlook.</p>\n<p>The feature appeared on the <a href=\"https://www.microsoft.com/en-gb/microsoft-365/roadmap?id=557561\" rel=\"nofollow\" target=\"_blank\">Microsoft 365 roadmap</a> on February 25, with a rollout due to start in May 2026. According to Microsoft, the update will \"provide contextual insights and actionable suggestion chips [<em>sic</em>] based on email and destination content.\"</p>\n\n<p>It added: \"This experience helps users quickly understand content, take action with fewer steps, and get more value from Copilot while extending productive browsing time in Edge.\"</p>\n<p>The update is consistent with Microsoft's current Copilot-everywhere strategy and will roll out worldwide to standard multi-tenant cloud instances.</p>\n<p>Whether it will be opt-in or opt-out remains unconfirmed, though users hoping for a conveniently placed off switch may be disappointed. Microsoft is keen to put its AI assistant in front of as many users as possible.</p>\n\n<p><i>The Register</i> asked Microsoft how much control administrators would have over the feature and what would happen if Edge wasn't the default browser. The company has yet to respond.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/24/west_midlands_police_copilot/\">West Midlands Police earn red card over Copilot's imaginary football match</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/19/ai_climate_crisis_claims/\">Don't believe the hyperscalers! AI can't cure the climate crisis</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/18/microsoft_copilot_data_loss_prevention/\">Copilot spills the beans, summarizing emails it's not supposed to read</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/15/if_microsoft_made_a_car/\">If Microsoft made a car... what would it be?</a></li>\n</ul>\n<p>Finding a corner of Microsoft's software that Copilot hasn't reached is increasingly difficult – even Notepad has not escaped – and disabling it across the company's productivity suite has become a game of Whac-A-Mole for enterprise administrators who have yet to embrace the technology.</p>\n<p>The automatic pane could hand those administrators yet another mallet to swing, particularly given that Copilot surfacing suggestions based on email content could run afoul of data security policies. That said, enterprises already nervous about where their data ends up likely have Copilot policies well in hand.</p>\n\n<p>Jon von Tetzchner, CEO of the Vivaldi browser project, which is already surfing the wave of anti-AI sentiment, isn't too impressed with Microsoft's latest efforts pertaining to Copilot and Edge.</p>\n<p>\"This is another example of trying to push Edge in every way possible and also forcing Copilot on users that may not want it,\" he told <em>The Register</em>.</p>\n\n<p>\"Considering how sensitive corporate emails can be, the last thing you want is them being snooped on by an LLM hosted who knows where. This would be highly problematic from a corporate security and privacy point of view, and even more of a problem for private users who might be using one of MS's email services. Just imagine if someone sends an email exploiting that for phishing purposes,\" he added.</p>\n<p>\"Should this be an opt-in rather than an opt-out? Absolutely. The better question is whether it should be a thing at all.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/copilot_pane_edge_outlook/",
            "pub_date": "2026-02-26 22:30:54",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Scattered Lapsus$ Hunters auditioning female voices to sharpen social engineering",
            "description": "<div id=\"body\">\n<p>Prolific cybercrime crew Scattered Lapsus$ Hunters (SLSH) is reportedly recruiting women in the hope of improving its social engineering success.</p>\n<p>According to Telegram channel posts made on February 22, gathered by Dataminr, the group behind last year's <a href=\"https://www.theregister.com/2025/09/08/drift_breach_entry_salesloft_github/\" target=\"_blank\">Salesloft Drift attacks</a> promised payments between $500-$1,000 per call, depending on \"success and hit rate.\"</p>\n<p>Interested applicants are invited to apply by sending a message to the group's \"Support\" account. They will be asked a series of questions before being accepted, the group said, and those who pass the test will be given a script to work from.</p>\n\n<p>SLSH is known for effective <a href=\"https://www.theregister.com/2025/08/21/impersonation_as_a_service/\" target=\"_blank\">social engineering</a>. Experts who have listened in on calls carried out by Scattered Spider, one of the groups that form the cybercrime triad, previously confirmed that its tactics are <a href=\"https://www.theregister.com/2025/05/18/ex_nsa_scattered_spider_call/\" target=\"_blank\">sophisticated and highly effective</a>.</p>\n\n\n<p>The Telegram ads suggest that SLSH is looking for people to socially engineer IT helpdesk staff. This aligns with the group's typical MO of deceiving IT helpdesks into handing over credentials that attackers can use to gain access to an organization's network.</p>\n<p>\"This recruitment drive represents a calculated evolution in SLH's tactics,\" <a href=\"https://www.dataminr.com/resources/intel-brief/slh-recruiting-women-for-vishing/\" rel=\"nofollow\" target=\"_blank\">said</a> Jeanette Miller-Osborn, field cyber intelligence officer at Dataminr. </p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/18/adidas_investigates_thirdparty_data_breach/\">Adidas investigates third-party data breach after criminals claim they pwned the sportswear giant</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/18/shinyhunters_cargurus_breach/\">ShinyHunters claims it drove off with 1.7M CarGurus records</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/27/shinyhunters_claim_panera_bread/\">Let them eat sourdough: ShinyHunters claims Panera Bread as stolen credentials victim</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/08/ransomware_2025_emsisoft/\">Ransomware attacks kept climbing in 2025 as gangs refused to stay dead</a></li>\n</ul>\n<p>\"By specifically seeking female voices, the group likely aims to bypass the 'traditional' profiles of attackers that IT helpdesk staff may be trained to identify, thereby increasing the effectiveness of their impersonation efforts.\"</p>\n<p>Miller-Osborn recommends that organizations make their helpdesks aware of these shifting tactics and ensure identities are thoroughly verified, either through video calls or secondary internal verification.</p>\n\n<p>SLSH's recruitment drive is the latest in what appears to be a trend of crowdsourcing efforts. </p>\n<p>Back in October, and again via Telegram, the group said it would <a href=\"https://www.theregister.com/2025/10/06/scattered_lapsus_bitcoin_reward/\" target=\"_blank\">pay anyone $10 in Bitcoin to \"endlessly harass\" executives</a> at organizations it was trying to extort. </p>\n<p>\"You have permission to endlessly harass these executives till they comply with us,\" its message stated. \"When we tell you stop emailing a company or number of executives emails, you are to stop emailing them. This will be centralized and well operated.\"</p>\n\n<p>When <em>The Register</em> asked SLSH about how many people had taken up its offer after the first few days, it claimed it had \"practically paid out over $1,000 at this point,\" though these claims cannot be independently verified. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/scattered_lapsus_hunters_female_recruits/",
            "pub_date": "2026-02-26 23:15:59",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Hubble in a death spiral that could end as early as 2028 without a reboost",
            "description": "<div id=\"body\">\n<p>A newly released plot of the Hubble Space Telescope's altitude shows just how quickly the observatory has descended in recent years.</p>\n<p>The <a href=\"https://bsky.app/profile/planet4589.bsky.social/post/3mfnzjhkvhc27\" rel=\"nofollow\" target=\"_blank\">post</a> on Bluesky by astronomer Jonathan McDowell is a stark reminder that Hubble is heading back to Earth, possibly sooner than previously thought, as its orbit decays.</p>\n<p>Hubble was launched into low Earth orbit in 1990, carried in the payload bay of Space Shuttle Discovery. While it remains capable of pointing its instruments and has returned breathtaking imagery over more than three decades in orbit, it cannot raise its altitude.</p>\n\n<p>The observatory was serviced by a succession of Space Shuttle crews over the years, and engineers worked around hardware failures as the observatory aged. However, no amount of ground-based cleverness will stop the spacecraft from eventually re-entering the atmosphere.</p>\n\n\n<p>The plot from McDowell makes the orbital decay clear. From an initial altitude of more than 600 km, Hubble is now well below 500 km. The more rapid descent in recent years is at least partly due to increased solar activity, which has caused Earth's atmosphere to expand, but it also highlights the need for a reboost in the next few years before the telescope becomes unrecoverable.</p>\n<p>NASA is attempting to <a href=\"https://www.theregister.com/2026/02/12/nasa_swift_reboost/\" target=\"_blank\">rescue</a> the Swift observatory and has paused most science operations after the 21-year-old spacecraft's altitude dropped below 400 km, in order to buy extra time for a reboost mission later this year.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/01/07/nasa_test_stand_demolition/\">Historic NASA test towers face their final countdown</a></li>\n<li><a href=\"https://www.theregister.com/2025/08/13/nasa_mulls_sending_a_rescue/\">NASA mulls sending a rescue rocket to boost Swift observatory's orbit</a></li>\n<li><a href=\"https://www.theregister.com/2025/07/28/nasa_voluntary_exits/\">NASA faces brain drain as thousands exit under voluntary resignation scheme</a></li>\n<li><a href=\"https://www.theregister.com/2025/07/21/hubble_astronaut_budget_fears/\">NASA veteran warns Hubble faces death by a hundred cuts</a></li>\n</ul>\n<p>Jared Isaacman, now NASA Administrator, mooted boosting Hubble in <a href=\"https://www.theregister.com/2022/09/30/nasa_spacex_hubble_dragon/\" target=\"_blank\">2022</a>, but was ultimately rejected. Unlike Swift, Hubble was designed to be captured and serviced in space, and the last Space Shuttle servicing mission left an adapter attached to the vehicle for a future visiting spacecraft.</p>\n<p>In 2025, Dr John Grunsfeld, former astronaut and retired associate administrator of NASA's Science Mission Directorate, <a href=\"https://www.theregister.com/2025/07/21/hubble_astronaut_budget_fears/\" target=\"_blank\">told</a> <i>The Register</i> that Hubble faced death by a thousand cuts, decaying orbit notwithstanding. Its budget has been relatively flat for years, which means, accounting for inflation, \"we're already down about 30 percent in funding for Hubble.\"</p>\n\n<p>\"They're just trying to whittle away at it,\" he said.</p>\n<p>Hubble transitioned to a single-gyro mode in 2024. It has six of the devices, which are used to point the telescope, but three have failed, and a fourth is showing signs of degradation. The plan was to eke out a few more years of operational life from a spacecraft that had outlived all initial expectations.</p>\n<p>However, without a reboost, the telescope could re-enter the atmosphere as early as 2028, according to McDowell's analysis. His plot suggests it is already on that trajectory. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/25/hubble_orbit_decay/?td=rt-3a",
            "pub_date": "2026-02-26 06:06:33",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Five Eyes warn: Patch your Cisco SD-WAN or risk root takeover",
            "description": "<div id=\"body\">\n<p>The Five Eyes intelligence alliance is urgently warning defenders to patch two Cisco Catalyst SD-WAN vulnerabilities used in attacks.</p>\n<p>First discovered by the Australian Signals Directorate (ASD), all five of the alliance's intelligence agencies co-signed the alert on Wednesday evening, confirming that hackers of unspecified origin are trying to use the SD-WAN devices for persistent access.</p>\n<p>\"Malicious cyber threat actors are targeting Cisco Catalyst SD-WAN used by organizations globally,\" the UK's NCSC said. \"These actors are compromising SD-WANs to add a malicious rogue peer and then conduct a range of follow-on actions to achieve root access and maintain persistent access to the SD-WAN.\"</p>\n\n<p>The first of the two is <a href=\"https://www.cve.org/CVERecord?id=CVE-2022-20775\" rel=\"nofollow\" target=\"_blank\">CVE-2022-20775</a> (7.8), a path traversal vulnerability disclosed in September 2022 affecting the SD-WAN's command line interface, allowing for privilege escalation.</p>\n\n\n<p>The second is <a href=\"https://www.cve.org/CVERecord?id=CVE-2026-20127\" rel=\"nofollow\" target=\"_blank\">CVE-2026-20127</a> (10.0), a max-severity bug fresh off the press this week. Classed as an improper authentication flaw, the issue affects Cisco Catalyst SD-WAN Controller and Cisco Catalyst SD-WAN Manager, formerly known as SD-WAN vSmart and SD-WAN vManage respectively.</p>\n<p>The latter appears to be the biggie, not just because of the perfect 10 CVSS, but because successfully exploiting it grants hackers admin rights. Cisco said that cyberbaddies could also access NETCONF and reconfigure the SD-WAN fabric at their whim.</p>\n\n<p>According to a separate report from Cisco Talos, the vendor attributed the attacks that use CVE-2026-20127 to a group it tracks as UAT-8616 and said current signals suggest it has been exploited since at least 2023.</p>\n<p>Naturally, neither the intelligence agencies nor Cisco revealed precise details about the vulnerabilities that were reportedly exploited.</p>\n<p>However, Talos's <a href=\"https://blog.talosintelligence.com/uat-8616-sd-wan/\" rel=\"nofollow\" target=\"_blank\">report</a> suggested that CVE-2026-20127 was exploited first to gain admin rights, before downgrading the SD-WAN's software version using CVE-2022-20775 so that the attackers could gain root access.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/20/cisa_dell_vulnerability/\">CISA gives federal agencies three days to patch actively exploited Dell bug</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/13/gartner_ai_infrastructure/\">Misconfigured AI could trigger the next national infrastructure meltdown</a></li>\n<li><a href=\"https://www.theregister.com/2025/09/25/zeroday_deja_vu_another_cisco/\">Zero-day deja vu as another Cisco IOS bug comes under attack</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/24/patch_these_4_critical_makemeroot/\">Patch these 4 critical, make-me-root SolarWinds bugs ASAP</a></li>\n</ul>\n<p>Talos did not provide any details about who or what country might be behind UAT-8616, but described it as a \"<a href=\"https://www.theregister.com/2025/03/24/nation_state_supply_chain_attack/\" target=\"_blank\">highly sophisticated cyber threat actor</a>.\"</p>\n<p>An undisclosed number of attacks have already been carried out by exploiting the two vulnerabilities. Details about the victims remain sparse, although Talos suggested that targets were likely in high-value, sensitive sectors.</p>\n\n<p>It stated: \"UAT-8616's attempted exploitation indicates a continuing trend of the <a href=\"https://www.theregister.com/2025/12/04/prc_spies_brickstorm_cisa/\" target=\"_blank\">targeting of network edge devices</a> by cyber threat actors looking to establish persistent footholds into high-value organizations, including <a href=\"https://www.theregister.com/2026/01/19/dont_underestimate_prorussia_hacktivists_warns/\" target=\"_blank\">critical infrastructure</a> sectors.\"</p>\n<p>Defenders are strongly urged to follow the Five Eyes <a href=\"https://www.cyber.gov.au/sites/default/files/2026-02/ACSC-led%20Cisco%20SD-WAN%20Hunt%20Guide.pdf\" rel=\"nofollow\" target=\"_blank\">Hunt Guide</a> [PDF] to first find signs of compromise. If that search is positive, share the data with the relevant security authorities and upgrade to the latest version of Cisco Catalyst SD-WAN Controller/Manager.</p>\n<p>NCSC CTO Ollie Whitehouse said: \"Our new alert makes clear that organizations using Cisco Catalyst SD-WAN products should urgently investigate their exposure to network compromise and hunt for malicious activity, making use of the new threat hunting advice produced with our international partners to identify evidence of compromise.</p>\n<p>\"UK organizations are strongly advised to report compromises to the NCSC, and to apply vendor updates and hardening guidance as soon as practicable to reduce the risk of exploitation.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/five_eyes_cisco_sdwan/",
            "pub_date": "2026-02-26 23:26:41",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        }
    ]
}