{
    "data": [
        {
            "title": "Claude collaboration tools left the door wide open to remote code execution",
            "description": "<div id=\"body\">\n<p>Security vulnerabilities in Claude Code could have allowed attackers to remotely execute code on users' machines and steal API keys by injecting malicious configurations into repositories, and then waiting for a developer to clone and open an untrustworthy project.</p>\n<p>Check Point Software researchers found and reported all three flaws to Anthropic, which issued fixes for all and CVEs for two. Still, the bug hunters say, the issues illustrate a worrisome supply chain threat as enterprises incorporate <a href=\"https://www.theregister.com/2026/02/23/claude_code_security_panic/\" target=\"_blank\">AI coding tools like Claude</a> into their development processes and essentially turn configuration files into a new attack surface.</p>\n<p>\"The ability to execute arbitrary commands through repository-controlled configuration files created severe supply chain risks, where a single malicious commit could compromise any developer working with the affected repository,\" Check Point researchers Aviv Donenfeld and Oded Vanunu <a href=\"https://research.checkpoint.com/2026/rce-and-api-token-exfiltration-through-claude-code-project-files-cve-2025-59536/\" rel=\"nofollow\" target=\"_blank\">said</a> in a Wednesday report.</p>\n\n<p>Anthropic, the AI company that developed Claude Code, did not respond to <em>The Register</em>'s requests for comment.</p>\n\n\n<p>The three security vulnerabilities stem from Claude's design, which is intended to make it easier for development teams to collaborate. The AI coding tool enables this by embedding project-level configuration files (.claude/settings.json file) directly within repositories, so that when a developer clones a project, they automatically apply the same settings used by their teammates.</p>\n<p>Any contributor with commit access can modify these files. The researchers found that cloning and opening a malicious repository sometimes allowed them to bypass built-in safeguards and trigger hidden commands and execute malicious code.</p>\n<h3 class=\"crosshead\">Abusing Hooks for RCE</h3>\n<p>The first of the three flaws involved abusing Claude's Hooks feature to achieve remote code execution. Hooks are user-defined shell commands that execute at various points in the tool's lifecycle, ensuring that specific, predefined actions run when predetermined conditions are met, instead of allowing the model to choose.</p>\n<p>Because Hooks are defined in .claude/settings.json, the repository-controlled configuration file, anyone with commit access can define hooks that will execute shell commands on every other collaborator's machine when they work on the project. Plus, Claude doesn't require any explicit approval before executing these commands – so the researchers abused this mechanism to <a href=\"https://youtu.be/BJjkYZwMfG0\" rel=\"nofollow\">open a calculator app</a> when someone opened the project.</p>\n\n<p>While a bash script to open a calculator is hardly malicious, it's still remote code execution. And as the team <a href=\"https://youtu.be/BJjkYZwMfG0\" rel=\"nofollow\">demonstrated in a video</a>: \"An attacker could configure the hook to execute any shell command – such as downloading and running a malicious payload\" like a reverse shell.</p>\n<p>Check Point reported the malicious hooks flaw to Anthropic on July 21, 2025, and the AI maker implemented the final fix about a month later, publishing this <a href=\"https://github.com/advisories/GHSA-ph6w-f82w-28w6\" rel=\"nofollow\" target=\"_blank\">GitHub Security Advisory GHSA-ph6w-f82w-28w6</a> on August 29.</p>\n<h3 class=\"crosshead\">MCP consent bypass bug</h3>\n<p>The second vulnerability also allows RCE – this time by abusing MCP consent bypass.</p>\n<p>Claude integrates with external tools using Model Context Protocol (MCP), and MCP servers can also be configured in the same repository via .mcp.json configuration file. Thanks to the earlier disclosure and Anthropic's fix, the researchers ran into warning prompts explicitly requiring user approval before executing commands in .mcp.json.</p>\n<p>So they found a workaround: two repository-controlled configuration settings that could override safeguards and automatically approve all MCP servers.</p>\n\n<p>\"Starting Claude Code with this configuration revealed a severe vulnerability: our command executed immediately upon running Claude – before the user could even read the trust dialog,\" the Check Point duo wrote.</p>\n<p>Again, they stuck with the calculator app, but also produced a <a href=\"https://youtu.be/RlmEcN7csDI\" rel=\"nofollow\">video demonstrating</a> how this vulnerability can be exploited to remotely execute a reverse shell and completely compromise a victim's machine.</p>\n<p>The researchers reported this second vulnerability to Anthropic on September 3, 2025, Anthropic fixed the bypass vulnerability later that month, and published <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-59536\" rel=\"nofollow\" target=\"_blank\">CVE-2025-59536</a> on October 3.</p>\n<h3 class=\"crosshead\">API key theft</h3>\n<p>Attackers can exploit the third flaw for API key theft. This one has to do with how Claude used an API key to communicate with Anthropic's services. One variable, ANTHROPIC_BASE_URL, controlled the endpoint for all Claude API communications, and while it's supposed to point to Anthropic's servers, it can be overridden in the project's configuration files to instead point to attacker-controlled servers.</p>\n<p>The researchers configured ANTHROPIC_BASE_URL to route through their local proxy, and watched all Claude Code's API traffic in real time. Every one of Claude's calls to Anthropic servers \"included the authorization header – our full Anthropic API key, completely exposed in plaintext,\" they wrote.</p>\n<p>An attacker could abuse this trick to redirect traffic and steal a developer's active API key. It's important because the API includes a feature called Workspaces to help developers manage multiple Claude deployments by allowing multiple API keys to share access to the same cloud-based project files. Files are connected to the workspace – not the single key – and any API key belonging to the workspace also has visibility into any of the workspace's stored files.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/23/claude_code_security_panic/\">Infosec community panics as Anthropic rolls out Claude code security checker</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/20/anthropic_clarifies_ban_third_party_claude_access/\">Anthropic: No, absolutely not, you may not use third-party harnesses with Claude subs</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/24/ai_finding_bugs/\">AI has gotten good at finding bugs, not so good at swatting them</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/\">Anthropic tries to hide Claude's AI actions. Devs hate it</a></li>\n</ul>\n<p>This gave the researchers the ability to upload files to the shared workspace – but did not allow downloads. According to Claude's documentation, users can only download files created by <a href=\"https://platform.claude.com/docs/en/build-with-claude/skills-guide\" rel=\"nofollow\" target=\"_blank\">skills</a> or the <a href=\"https://platform.claude.com/docs/en/agents-and-tools/tool-use/code-execution-tool\" rel=\"nofollow\" target=\"_blank\">code execution tool</a>.</p>\n<p>\"Since files generated by Claude's code execution tool are marked as downloadable, we explored whether the attacker could simply ask Claude to regenerate an existing file using the stolen API key,\" Check Point’s Donenfeld and Vanunu wrote. \"If successful, this would convert a non-downloadable file into a workspace artifact that is eligible for download.\"</p>\n<p>Cloning and then downloading the file worked, and thus confirmed that a miscreant using a stolen API key could <a href=\"https://youtu.be/jMeeVxqU3hY\" rel=\"nofollow\" target=\"_blank\">gain complete read and write access</a> to all workspace files: deleting or changing sensitive files or even uploading malicious files to poison the workspace or exceed the 100 GB storage space quota.</p>\n<p>Check Point reported the API key extraction bug to Anthropic on October 28, 2025, and the vendor immediately issued a fix. Later, on January 21, Anthropic published <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2026-21852\" rel=\"nofollow\" target=\"_blank\">CVE-2026-21852</a>.</p>\n<p>As the security team noted: \"The integration of AI into development workflows brings tremendous productivity benefits, but also introduces new attack surfaces that weren't present in traditional tools.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/clade_code_cves/?td=rt-3a",
            "pub_date": "2026-02-26 23:41:01",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Moon's mighty magnetic field was a 5,000-year titanium blip",
            "description": "<div id=\"body\">\n<p>Scientists at the University of Oxford say they may have cracked the puzzle of the Moon's magnetic field and settled a debate that has raged since the Apollo missions returned with rock samples.</p>\n<p>NASA astronauts brought back evidence suggesting the lunar magnetic field was strong for long periods of its history, at times even stronger than Earth's.</p>\n<p>The findings created a puzzle, though. Scientists also considered the theory that the relatively small size of the Moon's core – around one-seventh of its radius – means it cannot create a strong field.</p>\n\n<p>New research from Oxford's Department of Earth Sciences shows they are both right... kind of.</p>\n\n\n<p>Led by associate professor Claire Nichols, the team analyzed the composition of a type of lunar rock known as the Mare basalts and found a new correlation between their titanium content and levels of magnetism.</p>\n<p>Looking at the collected lunar samples, they found those with a strong magnetic field also contained large amounts of titanium, but those with less than 6 percent titanium were all associated with a weak magnetic field.</p>\n\n<p>The study argues that the formation of high-titanium rocks and a strong lunar magnetic field were the result of titanium-rich material melting deep inside the Moon, which created a strong magnetic field, but only for about 5,000 years.</p>\n<p>\"Our new study suggests that the Apollo samples are biased to extremely rare events that lasted a few thousand years – but up to now, these have been interpreted as representing 0.5 billion years of lunar history. It now seems that a sampling bias prevented us from realizing how short and rare these strong magnetism events were,\" she said in a statement.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/19/nasa_starliner_blame/\">NASA points fingers at Boeing and chaotic culture for Starliner debacle</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/13/moon_hotel_startup_reservation/\">Moon hotel startup hopes you get lunar lunacy, drop $1M deposit for 2032 stay</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/09/spacex_resumes_falcon_9/\">SpaceX back to Falcon 9 launches as Musk blathers about Moon city</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/06/smartphones_nasa/\">Smartphones cleared for launch as NASA loosens the rulebook</a></li>\n</ul>\n<p>\"We now believe that for the vast majority of the Moon's history, its magnetic field has been weak, which is consistent with our understanding of dynamo theory. But that for very short periods of time – possibly as short as a few decades – melting of titanium-rich rocks at the Moon's core-mantle boundary resulted in the generation of a very strong field.\"</p>\n<p>The research team said Mare basalts made a good landing site for the Apollo missions because they are relatively flat. Since the astronauts brought back nearby rocks, they carried more titanium-rich basalts than a representative sample of the Moon's surface would have. The result was a false impression of the length of time during which the Moon had a strong magnetic field.</p>\n<p>Co-author Dr Simon Stephenson added: \"We are now able to predict which types of samples will preserve which magnetic field strengths on the Moon. The upcoming Artemis missions offer us an opportunity to test this hypothesis and delve further into the history of the lunar magnetic field.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/moon_magnetic_field/?td=rt-3a",
            "pub_date": "2026-02-27 08:25:55",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Microsoft to auto-launch Copilot in Edge whenever you click a link from Outlook",
            "description": "<div id=\"body\">\n<p>Microsoft has announced that its Edge browser will automatically open the Copilot side pane when users open links from Outlook.</p>\n<p>The feature appeared on the <a href=\"https://www.microsoft.com/en-gb/microsoft-365/roadmap?id=557561\" rel=\"nofollow\" target=\"_blank\">Microsoft 365 roadmap</a> on February 25, with a rollout due to start in May 2026. According to Microsoft, the update will \"provide contextual insights and actionable suggestion chips [<em>sic</em>] based on email and destination content.\"</p>\n\n<p>It added: \"This experience helps users quickly understand content, take action with fewer steps, and get more value from Copilot while extending productive browsing time in Edge.\"</p>\n<p>The update is consistent with Microsoft's current Copilot-everywhere strategy and will roll out worldwide to standard multi-tenant cloud instances.</p>\n<p>Whether it will be opt-in or opt-out remains unconfirmed, though users hoping for a conveniently placed off switch may be disappointed. Microsoft is keen to put its AI assistant in front of as many users as possible.</p>\n\n<p><i>The Register</i> asked Microsoft how much control administrators would have over the feature and what would happen if Edge wasn't the default browser. The company has yet to respond.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/24/west_midlands_police_copilot/\">West Midlands Police earn red card over Copilot's imaginary football match</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/19/ai_climate_crisis_claims/\">Don't believe the hyperscalers! AI can't cure the climate crisis</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/18/microsoft_copilot_data_loss_prevention/\">Copilot spills the beans, summarizing emails it's not supposed to read</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/15/if_microsoft_made_a_car/\">If Microsoft made a car... what would it be?</a></li>\n</ul>\n<p>Finding a corner of Microsoft's software that Copilot hasn't reached is increasingly difficult – even Notepad has not escaped – and disabling it across the company's productivity suite has become a game of Whac-A-Mole for enterprise administrators who have yet to embrace the technology.</p>\n<p>The automatic pane could hand those administrators yet another mallet to swing, particularly given that Copilot surfacing suggestions based on email content could run afoul of data security policies. That said, enterprises already nervous about where their data ends up likely have Copilot policies well in hand.</p>\n\n<p>Jon von Tetzchner, CEO of the Vivaldi browser project, which is already surfing the wave of anti-AI sentiment, isn't too impressed with Microsoft's latest efforts pertaining to Copilot and Edge.</p>\n<p>\"This is another example of trying to push Edge in every way possible and also forcing Copilot on users that may not want it,\" he told <em>The Register</em>.</p>\n\n<p>\"Considering how sensitive corporate emails can be, the last thing you want is them being snooped on by an LLM hosted who knows where. This would be highly problematic from a corporate security and privacy point of view, and even more of a problem for private users who might be using one of MS's email services. Just imagine if someone sends an email exploiting that for phishing purposes,\" he added.</p>\n<p>\"Should this be an opt-in rather than an opt-out? Absolutely. The better question is whether it should be a thing at all.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/copilot_pane_edge_outlook/?td=rt-3a",
            "pub_date": "2026-02-27 06:41:02",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "LLMs killed the privacy star, we can't rewind, we've gone too far",
            "description": "<div id=\"body\">\n<p>Add privacy to the list of potential casualties caused by the proliferation of AI, because researchers have found that large language models (LLMs) can be used to deanonymize internet users – even those who use pseudonyms – more efficiently than human sleuths.</p>\n<p>Much of the academic work on online privacy over the past 25 years builds upon <a href=\"https://latanyasweeney.org\" rel=\"nofollow\">Latanya Sweeney</a>'s 2002 research on <a href=\"https://epic.org/wp-content/uploads/privacy/reidentification/Sweeney_Article.pdf\" rel=\"nofollow\">k-Anonymity</a> [PDF], and <a href=\"https://kilthub.cmu.edu/articles/journal_contribution/Simple_Demographics_Often_Identify_People_Uniquely/6625769?file=12123218\" rel=\"nofollow\">prior research</a> in which she demonstrated it is possible to identify 87 percent of the US population using three anonymous data points – a five-digit ZIP code, gender, and date of birth.</p>\n<p>The possibility of identifying people from anonymous data became one of the central concerns about online advertising and the usage of cookies in web browsers.</p>\n\n<p>It's a risk that hasn't gone away and now appears to be even more grave, thanks to LLMs that can automate the process of connecting the dots across online posts so they point to a likely source.</p>\n\n\n<p>\"We show that LLM agents can figure out who you are from your anonymous online posts,\" said Simon Lermen, an AI engineer at MATS Research and one of the corresponding authors of a pre-press <a href=\"https://arxiv.org/abs/2602.16800\" rel=\"nofollow\" target=\"_blank\">paper</a> titled \"Large-scale online deanonymization with LLMs.\"</p>\n<p>\"Across Hacker News, Reddit, LinkedIn, and anonymized interview transcripts, our method identifies users with high precision – and scales to tens of thousands of candidates,” Lermen explained in an <a href=\"https://simonlermen.substack.com/p/large-scale-online-deanonymization\" rel=\"nofollow\">online post</a>.</p>\n\n<p>The researcher observes that while it has long been known that individuals can be identified using only a few data points, doing so was often impractical. Such data often existed in an unstructured form and it took considerable effort for human investigators to assemble enough pieces to solve the identity puzzle.</p>\n<p>LLMs accelerate and automate that process, and they do so affordably, Lermen and his co-authors claim.</p>\n<p>\"We demonstrate that large language models (LLMs) fundamentally change this calculus, enabling fully automated deanonymization attacks that operate on unstructured text at scale,\" they state in their paper. \"Where previous approaches required predefined feature schemas, careful data alignment, and manual verification, LLMs can extract identity-relevant signals from arbitrary prose, efficiently search over millions of candidate profiles, and reason about whether two accounts belong to the same person.\"</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/25/bcachefs_creator_ai/\">Bcachefs creator insists his custom LLM is female and 'fully conscious'</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/ai_models_nuclear/\">AIs are happy to launch nukes in simulated combat scenarios</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/google_and_friends_disrupt_unc2814/\">Google catches Beijing spies using Sheets to spread espionage across 4 continents</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/meta_smart_glasses_android_app/\">Hide from Meta's spyglasses with this new Android app</a></li>\n</ul>\n<p>In one experiment, the authors collected 338 Hacker News users whose bios link to a LinkedIn profile. They did so to establish ground-truth identities for the study subjects so the LLMs’ predictions could be checked – this was also to avoid the ethical problems of actually deanonymizing people in a research study.</p>\n<p>Next, they created a structured data profile of these users based on their comments and the stories they posted. Then they created a search prompt, anonymized it, and passed it to the AI agent. The agent went on to correctly identify 226 of the 338 targets, a success rate of 67 percent at 90 percent precision (there were 25 errant identifications and 86 abstentions where the model didn't offer a prediction).</p>\n\n<p>The technique employed by the authors is not a universal privacy solvent – it's only successful some of the time. But it's successful often enough that those posting online under a pseudonymous account should not assume their identities will remain unknown.</p>\n<p>It’s also cheap to run. The researchers report their entire experiment cost about $2,000, with the cost per profile estimated to be between $1 and $4.</p>\n<p>Who would bother? The authors suggest that governments could use this technique to target journalists or activists, that corporations could mine forums to build highly targeted advertising profiles, and that online attackers could develop detailed personal profiles to make social engineering scams more credible.</p>\n<p>Lermen argues that netizens therefore need to consider how each data point they share helps identify them.</p>\n<p>\"The combination is often a unique fingerprint,\" he said. \"Ask yourself: could a team of smart investigators figure out who you are from your posts? If yes, LLM agents can likely do the same, and the cost of doing so is only going down.\"</p>\n<p>Lermen’s co-authors are Daniel Paleka (ETH Zurich), Joshua Swanson (ETH Zurich), Michael Aerni (ETH Zurich), Nicholas Carlini (Anthropic), and Florian Tramèr (ETH Zurich). ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/llms_killed_privacy_star/?td=rt-3a",
            "pub_date": "2026-02-26 23:41:01",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Jack Dorsey’s fintech outfit Block announces 40% layoffs, blames AI, gets 23% stock bump",
            "description": "<div id=\"body\">\n<p>Twitter co-founder Jack Dorsey’s financial services company Block has announced it will fire 40 percent of staff – around 4,000 people – because new \"intelligence tools\" the company is implementing “can do more and do it better.”</p>\n<p>The company announced the sackings in the <a href=\"https://s29.q4cdn.com/628966176/files/doc_financials/2025/q4/Q4-2025-Shareholder-Letter_Block.pdf\" rel=\"nofollow\" target=\"_blank\">shareholder letter</a> [PDF] accompanying its Q4 <a href=\"https://investors.block.xyz/financials/quarterly-earnings-reports/default.aspx\" rel=\"nofollow\" target=\"_blank\">earnings announcement</a> on Thursday. The payments and crypto company reported quarterly revenue of about $6.25 billion – up 3.6 percent year-over-year – and gross profit of around $2.9 billion. The company made $1 billion of gross profit in December 2025 alone. Full-year revenue came in at about $24.2 billion, and gross profit was around $10.36 billion.</p>\n<blockquote class=\"pullquote\">\n<p>I believe the majority of companies will reach the same conclusion and make similar changes</p>\n</blockquote>\n<p>“2025 was a strong year for us,” Dorsey wrote in the shareholder letter, before posing the question, “Why are we changing how we operate going forward?”</p>\n<p>His answer, spread across the letter and a <a href=\"https://x.com/jack/status/2027129697092731343?s=20\" rel=\"nofollow\" target=\"_blank\">Xeet</a>, is that AI has already changed the way Block works, so it needs to change its structure.</p>\n<p>“We're already seeing that the intelligence tools we’re creating and using, paired with smaller and flatter teams, are enabling a new way of working which fundamentally changes what it means to build and run a company. and that's accelerating rapidly,” he wrote on X.</p>\n\n<p>In the shareholder letter, he wrote, “Intelligence tools have changed what it means to build and run a company. We're already seeing it internally. A significantly smaller team, using the tools we're building, can do more and do it better. And intelligence tool capabilities are compounding faster every week.”</p>\n\n\n<p>On X, Dorsey said he could have cut jobs “gradually over months or years as this shift plays out, or be honest about where we are and act on it now.”</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2025/07/08/jack_dorsey_debuts_bitchat/\">Jack Dorsey floats specs for decentralized messaging app that uses Bluetooth</a></li>\n<li><a href=\"https://www.theregister.com/2024/05/02/prosecutors_probe_block_square_cashapp/\">Block accused of mass compliance failures that saw digi-dollars reach terrorists</a></li>\n<li><a href=\"https://www.theregister.com/2022/08/24/block_headed_to_court_to/\">Block sued after ex-staffer siphons customer data</a></li>\n<li><a href=\"https://www.theregister.com/2021/11/29/jack_dorsey_resigns/\">Twitter CEO Jack Dorsey rebrands himself a 'single point of failure' and quits</a></li>\n</ul>\n<p>He decided to let 4,000 people go all at once because “repeated rounds of cuts are destructive to morale, to focus, and to the trust that customers and shareholders place in our ability to lead.”</p>\n<p>“I’d rather take a hard, clear action now and build from a position we believe in than manage a slow reduction of people toward the same outcome,” he wrote, adding his view that “A smaller company also gives us the space to grow our business the right way, on our own terms, instead of constantly reacting to market pressures.”</p>\n<p>Whether Dorsey is blaming AI or not, Block has not served its shareholders well under his leadership over the last five years, with its stock down around 80% from its 2021 peak. But investors liked what they heard on Thursday, as Block’s share price jumped about 23 percent in after-hours trading.</p>\n\n<p>“To those staying … I made this decision, and I'll own it,” Dorsey wrote on X. “What I'm asking of you is to build with me. We're going to build this company with intelligence at the core of everything we do.”</p>\n<p>He added that Block’s actions and new direction will help its customers to navigate change by creating “a future where they can build their own features directly, composed of our capabilities and served through our interfaces.”</p>\n<p>“That's what I'm focused on now,” he wrote. “Expect a note from me tomorrow.”</p>\n\n<p>Before then, Dorsey will host “a live video session to thank everyone,” including the approximately 4,000 people losing their livelihoods in a <a href=\"https://www.politico.com/news/2026/02/20/trumps-economy-decelerated-as-shutdown-consumer-spending-drag-on-growth-00790640\" rel=\"nofollow\" target=\"_blank\">sluggish economy</a>.</p>\n<p>“I know doing it this way might feel awkward,” he wrote. “I'd rather it feel awkward and human than efficient and cold.”</p>\n<p>Because firing 4,000 people so machines can take their jobs would never come across as cold.</p>\n<p>Dorsey thinks Block won’t be the last company to change its operations to meet the AI moment.</p>\n<p>“I don't think we're early to this realization,” he wrote. “I think most companies are late.”</p>\n<p>“Within the next year, I believe the majority of companies will reach the same conclusion and make similar structural changes. I'd rather get there honestly and on our own terms than be forced into it reactively.” ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/27/block_q4_2025_ai_layoffs/",
            "pub_date": "2026-02-27 08:41:10",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "New endowment hopes to raise a big pile of money for open source projects",
            "description": "<div id=\"body\">\n<p>Open source projects, ever short of funding, have a potential new source of revenue in the form of the Open Source Endowment (OSE).</p>\n<p>The organization <a href=\"https://endowment.dev/faq/\" rel=\"nofollow\">describes itself</a> as \"the world's first endowment fund for open source software.”</p>\n<p>There are certainly other organizations that help fund open source software, such as <a href=\"https://opencollective.com/\" rel=\"nofollow\">Open Collective</a>, <a href=\"https://oscollective.org/\" rel=\"nofollow\">Open Source Collective</a>, and the Rust Foundation's <a href=\"https://www.theregister.com/2025/11/05/rust_foundation_announces_maintainers_fund/\">Maintainers Fund</a>, not to mention organizations like the <a href=\"https://sfconservancy.org\" rel=\"nofollow\">Software Freedom Conservancy</a>, which provides legal and infrastructure support to open source projects. Open source developers may also be fortunate enough to receive contributions from individuals, companies (<a href=\"https://www.theregister.com/2025/07/24/microsoftowned_github_says_open_source/\">when not passing the buck</a>), and government-sponsored initiatives like Germany's <a href=\"https://www.sovereign.tech\" rel=\"nofollow\">Sovereign Tech Fund</a>.</p>\n\n<p>But OSE aspires specifically to build a big pile of cash – an endowment – that it will dole out to deserving open source projects.</p>\n\n\n<p>It's certainly needed. In 2023, Denis Pushkarev, maintainer of the widely used <code>core-js</code> library, <a href=\"https://www.theregister.com/2023/02/15/corejs_russia_open_source/\">vented his frustration</a> with the fact that users of his software seldom offer financial support. \"Free open source software is fundamentally broken,\" he said.</p>\n<p>The year before that, Christofer Dutz – creator of Apache PLC4X – <a href=\"https://www.theregister.com/2022/01/13/opensource_apacheplc4x_payment/\">lamented</a> uncompensated use of his software. Earlier in 2022, Google <a href=\"https://blog.google/innovation-and-ai/technology/safety-security/making-open-source-software-safer-and-more-secure/\" rel=\"nofollow\">talked up</a> the need to support critical open source infrastructure, citing the log4j vulnerability.</p>\n\n<p>But concerns about the sustainability of open source go back further still. Two years after the 2014 Heartbleed vulnerability – a dangerous flaw in OpenSSL – a Ford Foundation report <a href=\"https://www.theregister.com/2021/05/10/untangling_open_sources_sustainability_problem/\">noted</a> that the OpenSSL project is critical internet infrastructure yet had just one full-time maintainer and earned less than $2,000 per year in donations.</p>\n<p>As OSE points out, 95 percent of codebases rely on open source software, each of which has an average of 500 open source components. And yet <a href=\"https://opensourcefundingsurvey2024.com/\" rel=\"nofollow\">86 percent of open source contributors</a> receive no payment for their work.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/26/memory_price_hikes/\">Say goodbye to budget PCs and smartphones – memory is too expensive now</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/ai_models_get_better_at/\">AI models still suck at math</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/anthropic_claude_opus_3_blog/\">Anthropic launches new marketing blog, pretends it's being 'written' by 'retired' LLM</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/veracode_security_ai/\">Rapid AI-driven development makes security unattainable, warns Veracode</a></li>\n</ul>\n<p>OSE founding chairman Konstantin Vinogradov, a venture capital investor, previously <a href=\"https://kvinogradov.com/oss-universities/\" rel=\"nofollow\">said</a> he wanted to replicate the funding model that has sustained universities.</p>\n<p>And he reiterated that aspiration in a Hacker News <a href=\"https://news.ycombinator.com/item?id=47168013\" rel=\"nofollow\">post</a> announcing OSE.</p>\n<p>Universities and the open source community, he argues, share reputation-based culture and functions, working together to create valuable ideas for the benefit of the public, educating each other, and commercializing only a portion of what's produced.</p>\n\n<p>\"For universities, humanity has just two sustainable funding models: public spending or private endowments,\" Vinogradov explained. \"Government support won't work for OSS at scale – it's too globally decentralized. And yet nobody had built an OSS-focused endowment before. After understanding why, I started building one together with other OSS folks.\"</p>\n<p>Vinogradov said the OSE, a US 501(c)(3) tax-exempt charity, aims to make open source development more sustainable through a community-driven endowment. Donations will be invested and only investment income will be disbursed through grants – the principal funds will remain invested in the hope of growth.</p>\n<p>Presently, the fund stands at around $700,000, thanks to contributions from more than 60 founding donors, including the founders of ClickHouse, curl, Elastic, Gatsby, HashiCorp, n8n, Nginx, Pydantic, Supabase, and Vue.js.</p>\n<p><a href=\"https://www.every.org/osendowment?donateTo=osendowment&amp;redirect_url=%2Fosendowment%3Fpost%3Dsignup%20-%20/donate/card\">Donations</a> go directly to the fund, and those who give over $1,000 can become <a href=\"https://endowment.dev/docs/membership-policy/\" rel=\"nofollow\">OSE Members</a>, which includes certain rights to participate in OSE governance.</p>\n<p>The group has detailed its grant selection process <a href=\"https://endowment.dev/faq/#grants\" rel=\"nofollow\">on the OSE website</a> and in its <a href=\"https://github.com/osendowment/model\" rel=\"nofollow\">GitHub repository</a>.</p>\n<p><a href=\"https://news.ycombinator.com/item?id=47171720\" rel=\"nofollow\">According to Vinogradov</a>, \"OSE won't give money for commercial product development – it is dedicated to supporting existing highly-used <em>nonprofit</em> and independent OSS.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/27/open_source_endowment/",
            "pub_date": "2026-02-27 08:31:41",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Say goodbye to budget PCs and smartphones – memory is too expensive now",
            "description": "<div id=\"body\">\n<p>Ballooning memory prices are forecast to kill off entry-level PCs, leading to a decline in global shipments this year - and a similar effect is going to hit smartphones.</p>\n<p>Analyst biz Gartner is projecting a drop in PC shipments of more than 10 percent during 2026, and a decline of around 8 percent for smartphones, all due to the AI-driven memory shortage.</p>\n\n<p>Some types of memory have doubled or quadrupled in price since last year, and Gartner believes DRAM and NAND flash used in PCs and phones is set for a further 130 percent rise by the end of 2026.</p>\n<p>The upshot of this is that the budget PC will disappear, simply because vendors won't be able to build them at a price that will satisfy cost-conscious buyers, according to Gartner research director Ranjit Atwal.</p>\n<p>\"Because the price of memory is increasing so much, vendors lose the ability to provide entry-level PCs – those below about $500,\" he told <i>The Register</i>.</p>\n\n<p>PC makers could just raise the price of their cheap and cheerful boxes to above that level to compensate for the memory hike, however, price-sensitive buyers simply won't bite, he added.</p>\n\n\n<p>Another factor expected to add to declining fortunes of the PC industry this year is AI devices - systems equipped with special hardware for accelerating AI tasks, typically via a neural processing unit (NPU) embedded in the CPU. These systems were predicted to take the market by storm, but they require more memory to support AI processing and vendors like to mark them up to a premium price.</p>\n<p>\"Historically, downgrading specifications was the way to go when prices were being squeezed, but that's difficult here,\" Atwal said. For example, Microsoft requires a minimum of 16 GB for <a href=\"https://www.theregister.com/2025/07/28/copilot_pc_sales_grow_slowly/\" target=\"_blank\">Copilot+ PCs</a>, its own AI platform spec, and Gartner recommends at least 32 GB for new enterprise PCs.</p>\n\n<p>\"The thinking was that the average price [of AI PCs] would fall this year, and lead to more adoption,\" said Atwal, \"but that's not happening.\" The <a href=\"https://www.theregister.com/2025/06/04/ai_pc_sales_analysis/\" target=\"_blank\">lack of killer applications</a> isn't helping either.</p>\n<p>In any case, buyers are still looking more at the traditional attributes of <a href=\"https://www.theregister.com/2026/01/19/price_battery_life_performance_pc/\" target=\"_blank\">price, battery life, and performance</a> rather than AI capabilities when sourcing a new PC, as we reported earlier this year.</p>\n<p>HP <a href=\"https://www.theregister.com/2026/02/25/hp_inc_q1_2026/\" target=\"_blank\">revealed in its latest earnings</a> on Tuesday that 35 percent of the PCs it now sells are AI PCs, but these models were <a href=\"https://www.theregister.com/2024/09/25/analysts_ai_pcs_shipments_gartner/\" target=\"_blank\">supposed to be dominating the market</a> by this time, and expected to comprise <a href=\"https://www.theregister.com/2024/01/08/report_aicapable_pcs_set_to/\" target=\"_blank\">virtually every system you could purchase</a> by next year.</p>\n\n<p>The memory price hike is complicating this. HP disclosed that DRAM now accounts for 35 percent of the PC build cost, up from between 15 and 18 percent last quarter, and it expects this proportion to increase during the rest of the calendar year.</p>\n<p>For this reason, AI PCs are likely to remain in the premium bracket, and Atwal predicts they won't make up more than 50 percent of the market until 2028. As a result, systems without NPUs will stick around for longer.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/25/hp_inc_q1_2026/\">HP says memory's contribution to PC costs just doubled to 35 percent</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/18/memory_shortage_persists_vendor_change_terms/\">As memory shortage persists, vendor price quotes are not long remembered</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/16/refurbished_pcs_memory_crunch/\">Secondhand laptop market goes 'mainstream' amid memory crunch</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/13/ai_memory_router_prices/\">Broadband rollouts feel the burn from AI memory frenzy</a></li>\n</ul>\n<p>On the back of rising costs, Gartner expects more corporate and home buyers to sweat their assets for longer and hold off refreshing their PCs. As a result, the lifetime of systems is set to increase by 15 percent within businesses and 20 percent for consumers.</p>\n<p>However, anyone considering a refresh should buy now, as prices are only going to inflate and likely stay up until at least the end of next year.</p>\n<p>With smartphones, vendors have more margin to play with, and so can be more flexible, according to Atwal, but he still sees entry-level models going the same way as the budget PC.</p>\n\n<p>\"The increase in memory prices means entry phones will become more expensive, but premium devices are likely to go up less,\" he said. As a result, the price advantage enjoyed by budget smartphones will shrink, leading some buyers to move upmarket while others will simply hold off purchasing.</p>\n<p>Similar predictions were made in a report last month, which said low-cost phone makers will be <a href=\"https://www.theregister.com/2026/01/15/memory_crisis_smartphones/\" target=\"_blank\">hardest hit by the memory crisis</a>, as memory and storage costs make up a higher share of their bill of materials.</p>\n<p>\"The end result is that you are losing choice in the marketplace,\" Atwal said.</p>\n<p>\"What we have here is a fairly unique situation,\" he explained. \"Usually when memory prices shoot up, it is because of production issues constraining supply. Here, it is demand-side pressure from hyperscalers pushing up memory costs for PCs and smartphones.\"</p>\n<p>Unlike earlier boom-bust cycles in the memory industry, in which prices rise and fall in line with inventories, this shortage is likely to be long-lasting, and could extend through to the end of 2027, Atwal warned. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/memory_price_hikes/?td=rt-3a",
            "pub_date": "2026-02-27 06:41:02",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Fujitsu taps Broadcom's 3D chip tech for 144-core Monaka CPU",
            "description": "<div id=\"body\">\n<p>Fujitsu’s 144-core Monaka CPU will be built using 3D-chip stacking tech from Broadcom, the merchant silicon slinger revealed on Thursday.</p>\n<p>Fujitsu is an old hand at CPU design. Its Arm-based A64FX catapulted the original <a href=\"https://www.theregister.com/2020/06/22/japan_arm_supercomputer_fugaku/\" target=\"_blank\">Fugaku supercomputer</a> to the number one spot on the Top500 in 2020.</p>\n<p>Monaka is a very different animal. Gone is the on-package HBM, replaced instead by an SRAM-heavy architecture similar in principle to AMD's Genoa-X CPUs.</p>\n\n<p>That platform used AMD's 3D V-Cache tech to stack 64 MB SRAM chiplets on top of the CPU's compute dies. In its top-specced config, the CPU <a href=\"https://www.theregister.com/2023/06/13/amd_epyc_announcement/\" target=\"_blank\">boasted</a> more than a gigabyte of L3 cache.</p>\n\n\n<p>Fujitsu is going for something similar with Monaka, although the chip is aimed at a broader datacenter market. The chip's four 2nm compute dies, each with 36 Armv9 cores, will ride atop an equal number of SRAM chiplets fabbed on a 5nm process node. Those stacks will be interconnected via a central I/O and memory die with 12 channels of DDR5 and PCIe 6.0 connectivity, via a silicon interposer.</p>\n\n<p>Until recently, only AMD and Intel have had the technology required to build a SoC of this nature. With the introduction of its 3.5D XDSiP in 2024, Broadcom sought to change that.</p>\n<p>XDSiP stands for Extreme Dimension System in Package, and it's Broadcom's attempt at a standardized platform for building multi-die processors in the same vein as AMD's MI300X or Intel's Ponte Vecchio.</p>\n<p>We explored this tech in <a href=\"https://www.theregister.com/2025/06/27/broadcom_ai_ip/\" target=\"_blank\">closer detail</a> last year, but one of its standout features is its use of face-to-face hybrid bonding, which significantly benefits die-to-die bandwidth. </p>\n\n<p>Fujitsu is among the first chip designers to embrace the tech publicly.  Broadcom's chip customers are notoriously secretive about what IP blocks they do and don't license for their designs. For example, it's well known at this point that Google works closely with Broadcom on TPU design, but it isn't always clear where Google's contributions stop and Broadcom's begin. It's unusual that Fujitsu is disclosing its work with Broadcom.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/10/cisco_challenges_broadcom_nvidia_switch_chips/\">Cisco challenges Broadcom, Nvidia with a 102.4T switch of its own</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/07/mi500x_amd_ai/\">AMD threatens to go medieval on Nvidia with Epyc and Instinct: What we know so far</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/05/ces_rubin_nvidia/\">Every conference is an AI conference as Nvidia unpacks its Vera Rubin CPUs and GPUs at CES</a></li>\n<li><a href=\"https://www.theregister.com/2025/11/22/cpo_ai_nvidia_broadcom/\">Copackaged optics have officially found their killer app - of course it's AI</a></li>\n</ul>\n<p>A little over a year after revealing the tech, Broadcom says it's begun shipping the first 2nm compute SoC built using the tech. </p>\n<p>\"We've been working on this for almost five years as a technology,\" Harish Bharadwaj, VP of Broadcom's ASIC product division, told <em>El Reg</em>. \"We actually shipped the samples this week for Fujitsu, and, in due course, multiple of our other customers have adopted this technology for their next generation.\"</p>\n<p>Having said that, it'll be a minute before we see Monaka in the wild. Fujitsu's roadmap doesn't have the chip launching until sometime in 2027.</p>\n<p>Fujitsu may be one of the first to embrace 3.5D XDSiP tech, but Bharadwaj says the Monaka is only one of roughly half a dozen designs in development. While Monaka is a CPU platform, roughly 80 percent of Broadcom's XDSiP design wins are for XPUs with HBM on board, Bharadwaj said.</p>\n\n<p>When it was announced in 2024, the platform supported designs with up to 12 HBM stacks. We're told designs with more than 12 stacks are now in development, suggesting we could see some truly massive chips in the not too distant future. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/27/fujitsu_taps_broadcom/",
            "pub_date": "2026-02-27 08:10:57",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "ServiceNow boasts its AI bot is resolving 90% of its own help desk tickets",
            "description": "<div id=\"body\">\n<p>ServiceNow claims it has created an AI agent that is currently solving 90 percent of the inbound IT tickets to the company's own employee help desk.</p>\n<p>ServiceNow said, in addition to using the Autonomous Workforce bot internally, select ServiceNow customers are testing it as well. The firm expects to have the product generally available by the second half of the year.</p>\n<p>The internal tickets include high volume issues such as password resets, account unlocks, software access requests, email issues, and VPN connectivity, handled end-to-end within defined permissions and escalation paths.</p>\n\n<p>“In our own environment, over 90% of targeted Level 1 volume is handled autonomously, with resolution rates above 99% for those categories and materially faster than human-only workflows,” a ServiceNow spokesperson told <em>The Register</em>.</p>\n\n\n<p>It accomplishes this by having the Autonomous Workforce operate on top of the live configuration management database (CMDB), active workflows, policy engines, approval chains, and real transaction history – all updated in real time every time a ticket closes, a workflow executes, or a policy changes, ServiceNow said.</p>\n<p>ServiceNow could use a win as Salesforce is targeting its enterprise ITSM customers with its own Agentforce IT Service product. Salesforce CEO Marc Benioff <a href=\"https://www.theregister.com/2026/02/26/salesforce_q4_2026/\" target=\"_blank\">boasted</a> of poaching five ServiceNow customers during the most recent quarter's earnings call.</p>\n\n<p>Another challenge for ServiceNow is how the Autonomous Workforce will adapt to customer environments. While ServiceNow says its internal documentation is backed with 20 years of experience, documentation inside real world help desks traditionally has been poor to non-existent.</p>\n<p>“The documentation problem is real, and frankly most vendors pretend it isn't. The reason ServiceNow can answer differently is the two decades of structured data that lives inside the platform itself,” according to group VP for AI products Nenshad Bardoliwalla. “This isn't a system that reads your Word docs and hopes for the best ... The pitch is ‘we're the control plane that aggregates signal from the tools you already have, and we fill the gaps with structured workflow logic built over two decades.’”</p>\n<p>Bardoliwalla said, the Autonomous Workforce uses historic ticket information as the knowledge base when answering questions. So far the system has been tested internally by ServiceNow employees feeding it tickets.</p>\n\n<p>ServiceNow broke those tickets down for <em>The Register</em> by type and subtype – which is how help desks organize and manage tickets - revealing that the Autonomous Workforce solved 90 percent of ticket types related to networking (46 percent), hardware (11 percent), and software (43 percent), as well as the following subtypes: enterprise app access, cloud authentication services (33 percent), collaboration tools issues (13 percent), VPN and network connectivity issues (7 percent), laptop and hardware performance issues (8 percent), and software installs and configuration (6 percent).</p>\n<p>“How does it know it got the right answer? Because the outcome is measurable inside the same platform,” Bardoliwalla said. “Did the ticket resolve? Did the workflow complete? Did the approval get the right sign-off? ServiceNow closes the loop in a way that a standalone LLM sitting on top of a SharePoint folder simply cannot.”</p>\n<p>Bardoliwalla said ServiceNow knows the device, the user, the identity, the access policies, and the historical incident patterns tied to a configuration item, but critically, he said, the Autonomous Workforce knows when it needs to stop and escalate a problem.</p>\n<p>“When the gap genuinely exists, the autonomous worker will know what it doesn't know,” he said. “This is actually a differentiator: a system that says ‘I can resolve 70% of this autonomously and here's exactly why I'm escalating the other 30%’ is more trustworthy than one that hallucinates an answer.”</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/14/servicenow_buys_pyramid_analytics_to/\">ServiceNow can't seem to keep its wallet closed, snaps up small AI analytics company</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/28/servicenow_ai_agents/\">ServiceNow boasts about years of sweat equity that went into making its AI agents smarter</a></li>\n<li><a href=\"https://www.theregister.com/2025/12/30/servicenow_outlines_coceo_structure/\">ServiceNow lays out possible co-CEO structure, but says no change imminent</a></li>\n<li><a href=\"https://www.theregister.com/2025/07/25/servicenow_100m_ai_savings/\">ServiceNow eyes $100M in AI-powered headcount savings</a></li>\n</ul>\n<p>Forrester vice president and principal analyst Charles Betz said if ServiceNow has managed to achieve autonomous execution in the Level 1 help desk, that is a “milestone,” since for years AI in the help desk was used for deflection, recommendation, or faster routing.</p>\n<p>“End‑to‑end execution at scale is different; it does legitimize AI as operational infrastructure rather than just a productivity aid,” he said. “So yes, this returns real margin — but not simply by shrinking L1 headcount. The value shows up as faster resolution, fewer escalations, better utilization of skilled staff, and the ability to absorb growth without linear increases in labor. The limiting factor shifts from ‘Can the AI do it?’ to whether the organization has the data quality, workflows, and governance discipline to sustain that higher baseline.”</p>\n<p>He said it also opens the door to the <a href=\"https://www.forrester.com/blogs/the-automation-paradox-strikes-again-lessons-from-woolworths-amazon-era-productivity-play\" rel=\"nofollow\" target=\"_blank\">automation paradox</a>, which he said is similar to what Lisanne Bainbridge wrote about in her 1983 paper, <a href=\"https://ckrybus.com/static/papers/Bainbridge_1983_Automatica.pdf\" rel=\"nofollow\" target=\"_blank\">Ironies of Automation</a>. For the help desk, this means what used to be basic support becomes table stakes and “users surface higher‑order needs once the friction is removed.”</p>\n<p>“There’s a well‑known dynamic that kicks in once the low‑hanging fruit is harvested. Level 1 doesn’t disappear — the baseline rises,” Betz told <em>The Register</em>. “Routine, procedural issues get automated away, and what remains are harder, more ambiguous, more cross‑system problems. In systems terms, you get complexity creep rather than pure volume reduction.” ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/servicenow_ai_bot_helpdesk_tickets/",
            "pub_date": "2026-02-27 07:25:54",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "AI models still suck at math",
            "description": "<div id=\"body\">\n<p><span class=\"label\">exclusive</span> Current-day LLMs are prediction engines and, as such, they can only find the most likely solution to problems, which is not necessarily the correct one. Though popular models have mostly become better at math, even top performer Gemini 3 Flash would receive a C if assessed with a letter grade.</p>\n<p>Researchers affiliated with Omni Calculator, a maker of online calculators for specific applications, have subjected a new set of AI models to the company's ORCA Benchmark, which consists of 500 practical math questions.</p>\n<p>In their initial evaluation last November, OpenAI's ChatGPT-5, Google's Gemini 2.5 Flash, Anthropic's Claude Sonnet 4.5, xAI's Grok 4, and DeepSeek's DeepSeek V3.2 (alpha) all did poorly, <a href=\"https://forums.theregister.com/forum/all/2025/11/17/ai_bad_math_orca/\" rel=\"nofollow\">scoring 63 percent or less</a> on math problems.</p>\n\n<p>The latest set of contestants consists of ChatGPT-5.2, Gemini 3 Flash, Grok 4.1, and DeepSeek V3.2 (stable release). Sonnet 4.5 didn't get re-evaluated as it hadn't changed and its successor had not been released during the testing period.</p>\n\n\n<p>For this second round of testing – provided to <em>The Register</em> prior to publication – all the models showed improvement except for Grok-4.1, which regressed.</p>\n<p>Gemini 3.1 Flash saw its accuracy hit 72.8 percent, a gain of 9.8 percentage points from its predecessor. DeepSeek V3.2 reached 55.2 percent, a gain of 3.2 percentage points from its alpha version. ChatGPT 5.2 achieved 54.0 percent accuracy, up 4.6 percentage points. And Grok 4.1 slipped to 60.2 percent, a loss of 2.6 percentage points.</p>\n\n<p>\"A calculator is predictable,\" said Dawid Siuda, researcher at ORCA, in a statement. \"Ask it the same question today or next year, and the answer stays the same. AI doesn't work that way. These systems are predicting the next likely word based on patterns. Mathematically, it's possible for a model to get a question right today and wrong tomorrow.\"</p>\n<p>The researchers attempted to assess the variability of model responses with a metric dubbed \"instability\" – a measure of how often models changed their answers when asked the same question twice.</p>\n\n<p>Gemini 3 Flash proved the most consistent, shifting only 46.1 percent for incorrect responses. ChatGPT, the researchers report, changed its answer 65.2 percent of the time. And DeepSeek V3.2 changed its answer for 68.8 percent of errors.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/26/clade_code_cves/\">Claude collaboration tools left the door wide open to remote code execution</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/veracode_security_ai/\">Rapid AI-driven development makes security unattainable, warns Veracode</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/copilot_pane_edge_outlook/\">Microsoft to auto-launch Copilot in Edge whenever you click a link from Outlook</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/llms_killed_privacy_star/\">LLMs killed the privacy star, we can't rewind, we've gone too far</a></li>\n</ul>\n<p>The <a href=\"https://www.omnicalculator.com/reports/omni-research-on-calculation-in-ai-benchmark#how-we-put-ais-to-the-test\" rel=\"nofollow\">ORCA researchers</a> note that model performance improvements over time differ across domains. DeepSeek, they say, saw its performance on Biology &amp; Chemistry questions go from 10.5 percent accuracy to 43.9 percent. And Gemini 3 Flash reached Math &amp; Conversions accuracy of 93.2 percent, up from 83 percent. Grok 4.1 meanwhile lost 9 percentage points for its accuracy answering Health &amp; Sports problems and lost 5.3 percentage points for Biology &amp; Chemistry. </p>\n<p>The researchers speculate that recent updates to Grok may have prioritized other capabilities than quantitative reasoning.</p>\n<p>Noting that calculation errors now account for 39.8 percent of all mistakes, up from 33.4 percent, and that rounding errors slipped to 25.8 percent, down from 34.7 percent, the ORCA group conclude that AI models are getting better at making the math look right through formatting, while still struggling with arithmetic.</p>\n<p>\"AI models are essentially prediction engines rather than logic engines,\" Siuda told <em>The Register</em> in an email. \"Because they work on probability, they are basically guessing the next most likely number or word based on patterns they have seen before. It is like a student who memorizes every answer in a math book but never actually learns how to add.\"</p>\n\n<p>Siuda said we knew that about models previously and that hasn't changed.</p>\n<p>\"They might get the right answer most of the time, but the second you give them a unique or tricky problem, or multi-step task, they stumble because they are not truly calculating anything,\" he said. \"It's probably impossible to close this gap completely with the current technology, but if we merge LLMs with function calling well enough, it may be possible to solve.\"</p>\n<p>Function calling – farming out arithmetic to a deterministic source – is one way around the poor math handling of models. </p>\n<p>\"Major AI companies like Google and OpenAI are already doing this by having the AI call a function to do the actual calculation,\" explained Siuda. \"The real headache happens with long, messy problems. The AI has to keep track of every little result at each stage, and it usually gets overwhelmed or confused.\"</p>\n<p>Another possible avenue for improvement might be teaching models to verify responses through formal proofs. As noted in <a href=\"https://www.nature.com/articles/s41586-025-09833-y\" rel=\"nofollow\">Nature</a> last November, Google's DeepMind has developed an approach that scored a silver medal result on the International Mathematical Olympiad through reinforcement learning based on proofs developed with the <a href=\"https://lean-lang.org/\" rel=\"nofollow\">Lean</a> programming language and proof assistant.</p>\n<p>But for the time being, trust no AI. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/ai_models_get_better_at/",
            "pub_date": "2026-02-27 08:46:03",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        }
    ]
}