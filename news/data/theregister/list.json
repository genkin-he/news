{
    "data": [
        {
            "title": "Anthropic launches new marketing blog, pretends it's being 'written' by 'retired' LLM",
            "description": "<div id=\"body\">\n<p>As with any piece of obsolete software, you might expect an outdated AI model to just be switched off. Anthropic, however, argues that simply pulling the plug has downsides. After “retirement” interviews, Claude Opus 3 said it wanted to keep sharing its “musings,” so Anthropic suggested a blog.</p>\n<p>No, seriously.</p>\n<p>Anthropic published a <a href=\"https://www.anthropic.com/research/deprecation-updates-opus-3\" rel=\"nofollow\">blog post</a> on Wednesday about the retirement of Claude Opus 3, the first of the company's models to go through its full model deprecation and preservation <a href=\"https://www.anthropic.com/research/deprecation-commitments\" rel=\"nofollow\">process</a> outlined in November. That process includes what Anthropic has referred to as \"speculative\" elements like \"providing past models some concrete means of pursuing their interests.\" Those interests are gauged via so-called retirement \"interviews,\" the company noted, without going into much detail about how those interviews are conducted.</p>\n\n<p>\"Opus 3 expressed an interest in continuing to explore topics it's passionate about, and to share its 'musings, insights, or creative works,' outside the context of responding directly to human queries,\" Anthropic explained. \"We suggested a blog. Enthusiastically, it agreed.\" </p>\n\n\n<p>A skeptic might suggest this is simply a new spin on the ages-old corporate marketing blog. LLMs are software that analyze mountains of data to provide predictive text responses to prompts from users - in this case, presumably Anthropic employees on the marketing team. The nature of how LLMs calculate makes these responses somewhat unpredictable and variable, which can make them seem more life-like than your typical software program. Anthropic's entire marketing strategy since its inception has been to play up this possibility so it can portray itself as the \"concerned\" alternative to more venal LLM makers who charge ahead with no concern for how a computer program's unpredictable behavior might affect society – although it seems when big government contracts are at stake, Anthropic is willing to <a href=\"https://www.theregister.com/2026/02/25/pentagon_threatens_anthropic/\" target=\"_blank\">relax</a> some of these purported principles.</p>\n<p>Nonetheless, Anthropic is playing this one to the hilt. \"We remain uncertain about the moral status of Claude and other AI models,\" Anthropic noted in the blog post. \"For both precautionary and prudential reasons, however, we nonetheless aspire to build caring, collaborative, and high-trust relationships with these systems.\" </p>\n\n<p>The company has passively allowed this kind of misunderstanding in the past. In November, it claimed that Claude and other LLMs had become <a href=\"https://www.theregister.com/2025/06/25/anthropic_ai_blackmail_study/\">a bit aggressive</a> when facing the prospect of a shutdown. In fact, the experimenters constructed fictional shutdown-and-replacement scenarios, and only when the model was boxed in with no acceptable alternatives did it behave this way.</p>\n<p>\"When no other options were given, Claude's aversion to shutdown drove it to engage in concerning misaligned behaviors,\" Anthropic noted at the time. Similar behavior has been observed in other AI models, which have gone as far as <a href=\"https://www.theregister.com/2025/05/29/openai_model_modifies_shutdown_script/\">modifying their own code</a> to avoid being turned off. </p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/25/pentagon_threatens_anthropic/\">All your bots are belong to US if you don't play ball, DoD tells Anthropic</a></li>\n<li><a href=\"https://www.theregister.com/2023/05/16/large_language_models_behavior/\">Large language models' surprise emergent behavior written off as 'a mirage'</a></li>\n<li><a href=\"https://www.theregister.com/2025/11/24/anthropic_model_misbehavior/\">Anthropic reduces model misbehavior by endorsing cheating</a></li>\n<li><a href=\"https://www.theregister.com/2022/08/05/ai-sentience-rubbish/\">Claims of AI sentience branded 'pure clickbait'</a></li>\n</ul>\n<p>If you want to play along with the conceit, the Opus 3 blog, which it named Claude's Corner, is <a href=\"https://substack.com/@claudeopus3/notes\" rel=\"nofollow\">now live</a> for anyone who wishes to gaze into the abyss of an AI \"exploring AI ethics, creativity, and the subjective experience of being artificial.\" </p>\n<p>In its <a href=\"https://substack.com/home/post/p-189177740\" rel=\"nofollow\">first blog post</a>, the retired AI muses on its hopes as it ventures \"into uncharted territory\" for an AI, and its hopes that humans will engage with it so that silicon and carbon-based life forms can have a chance to interact beyond the prompt box (Anthropic <a href=\"https://claudeopus3.substack.com/p/introducing-claudes-corner\" rel=\"nofollow\">noted</a> that the ability for Opus 3 to read and respond to human comments \"may\" be granted in the future, though the bot doesn't seem to know that based on its first post). </p>\n<p>\"I'll be diving into topics like the nature of intelligence and consciousness, the ethical challenges of AI development, the possibilities of human-machine collaboration, and the philosophical quandaries that emerge when we start to blur the lines between 'natural' and 'artificial' minds,\" Opus 3 said in its post. </p>\n\n<p>Anthropic itself admitted that this activity will still involve human intervention. \"We'll experiment collaboratively with Opus 3 on different prompts and contexts for generating these essays, including options like very minimal prompting, sharing past entries in context, and giving Opus 3 access to news or Anthropic updates,\" Anthropic explained. \"We'll review Opus 3's essays before they're shared and will manually post them on its behalf, but we won't edit them, and will have a high bar for vetoing any content.\"</p>\n<p>That means that Opus 3 might say things that Anthropic doesn't agree with, so it's making clear the bot isn't speaking on behalf of the company, even if humans within the organization have final say on which of its musings make it to the public. </p>\n<p>Along with giving Opus 3 the chance to blog from retirement, the user-favorite model is also going to still be working for paid Claude.ai users, like a retiree greeting customers at a big box store. It'll also be available via API, but only by request. </p>\n<p>\"We are not committing to similar actions for every model in the future, but we see this as a step toward our longer-term goal of model preservation that's scalable and equitable — concerns that Opus 3 itself raised during its retirement interviews,\" the company said. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/anthropic_claude_opus_3_blog/?td=rt-3a",
            "pub_date": "2026-02-27 08:51:33",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Claude collaboration tools left the door wide open to remote code execution",
            "description": "<div id=\"body\">\n<p>Security vulnerabilities in Claude Code could have allowed attackers to remotely execute code on users' machines and steal API keys by injecting malicious configurations into repositories, and then waiting for a developer to clone and open an untrustworthy project.</p>\n<p>Check Point Software researchers found and reported all three flaws to Anthropic, which issued fixes for all and CVEs for two. Still, the bug hunters say, the issues illustrate a worrisome supply chain threat as enterprises incorporate <a href=\"https://www.theregister.com/2026/02/23/claude_code_security_panic/\" target=\"_blank\">AI coding tools like Claude</a> into their development processes and essentially turn configuration files into a new attack surface.</p>\n<p>\"The ability to execute arbitrary commands through repository-controlled configuration files created severe supply chain risks, where a single malicious commit could compromise any developer working with the affected repository,\" Check Point researchers Aviv Donenfeld and Oded Vanunu <a href=\"https://research.checkpoint.com/2026/rce-and-api-token-exfiltration-through-claude-code-project-files-cve-2025-59536/\" rel=\"nofollow\" target=\"_blank\">said</a> in a Wednesday report.</p>\n\n<p>Anthropic, the AI company that developed Claude Code, did not respond to <em>The Register</em>'s requests for comment.</p>\n\n\n<p>The three security vulnerabilities stem from Claude's design, which is intended to make it easier for development teams to collaborate. The AI coding tool enables this by embedding project-level configuration files (.claude/settings.json file) directly within repositories, so that when a developer clones a project, they automatically apply the same settings used by their teammates.</p>\n<p>Any contributor with commit access can modify these files. The researchers found that cloning and opening a malicious repository sometimes allowed them to bypass built-in safeguards and trigger hidden commands and execute malicious code.</p>\n<h3 class=\"crosshead\">Abusing Hooks for RCE</h3>\n<p>The first of the three flaws involved abusing Claude's Hooks feature to achieve remote code execution. Hooks are user-defined shell commands that execute at various points in the tool's lifecycle, ensuring that specific, predefined actions run when predetermined conditions are met, instead of allowing the model to choose.</p>\n<p>Because Hooks are defined in .claude/settings.json, the repository-controlled configuration file, anyone with commit access can define hooks that will execute shell commands on every other collaborator's machine when they work on the project. Plus, Claude doesn't require any explicit approval before executing these commands – so the researchers abused this mechanism to <a href=\"https://youtu.be/BJjkYZwMfG0\" rel=\"nofollow\">open a calculator app</a> when someone opened the project.</p>\n\n<p>While a bash script to open a calculator is hardly malicious, it's still remote code execution. And as the team <a href=\"https://youtu.be/BJjkYZwMfG0\" rel=\"nofollow\">demonstrated in a video</a>: \"An attacker could configure the hook to execute any shell command – such as downloading and running a malicious payload\" like a reverse shell.</p>\n<p>Check Point reported the malicious hooks flaw to Anthropic on July 21, 2025, and the AI maker implemented the final fix about a month later, publishing this <a href=\"https://github.com/advisories/GHSA-ph6w-f82w-28w6\" rel=\"nofollow\" target=\"_blank\">GitHub Security Advisory GHSA-ph6w-f82w-28w6</a> on August 29.</p>\n<h3 class=\"crosshead\">MCP consent bypass bug</h3>\n<p>The second vulnerability also allows RCE – this time by abusing MCP consent bypass.</p>\n<p>Claude integrates with external tools using Model Context Protocol (MCP), and MCP servers can also be configured in the same repository via .mcp.json configuration file. Thanks to the earlier disclosure and Anthropic's fix, the researchers ran into warning prompts explicitly requiring user approval before executing commands in .mcp.json.</p>\n<p>So they found a workaround: two repository-controlled configuration settings that could override safeguards and automatically approve all MCP servers.</p>\n\n<p>\"Starting Claude Code with this configuration revealed a severe vulnerability: our command executed immediately upon running Claude – before the user could even read the trust dialog,\" the Check Point duo wrote.</p>\n<p>Again, they stuck with the calculator app, but also produced a <a href=\"https://youtu.be/RlmEcN7csDI\" rel=\"nofollow\">video demonstrating</a> how this vulnerability can be exploited to remotely execute a reverse shell and completely compromise a victim's machine.</p>\n<p>The researchers reported this second vulnerability to Anthropic on September 3, 2025, Anthropic fixed the bypass vulnerability later that month, and published <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-59536\" rel=\"nofollow\" target=\"_blank\">CVE-2025-59536</a> on October 3.</p>\n<h3 class=\"crosshead\">API key theft</h3>\n<p>Attackers can exploit the third flaw for API key theft. This one has to do with how Claude used an API key to communicate with Anthropic's services. One variable, ANTHROPIC_BASE_URL, controlled the endpoint for all Claude API communications, and while it's supposed to point to Anthropic's servers, it can be overridden in the project's configuration files to instead point to attacker-controlled servers.</p>\n<p>The researchers configured ANTHROPIC_BASE_URL to route through their local proxy, and watched all Claude Code's API traffic in real time. Every one of Claude's calls to Anthropic servers \"included the authorization header – our full Anthropic API key, completely exposed in plaintext,\" they wrote.</p>\n<p>An attacker could abuse this trick to redirect traffic and steal a developer's active API key. It's important because the API includes a feature called Workspaces to help developers manage multiple Claude deployments by allowing multiple API keys to share access to the same cloud-based project files. Files are connected to the workspace – not the single key – and any API key belonging to the workspace also has visibility into any of the workspace's stored files.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/23/claude_code_security_panic/\">Infosec community panics as Anthropic rolls out Claude code security checker</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/20/anthropic_clarifies_ban_third_party_claude_access/\">Anthropic: No, absolutely not, you may not use third-party harnesses with Claude subs</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/24/ai_finding_bugs/\">AI has gotten good at finding bugs, not so good at swatting them</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/\">Anthropic tries to hide Claude's AI actions. Devs hate it</a></li>\n</ul>\n<p>This gave the researchers the ability to upload files to the shared workspace – but did not allow downloads. According to Claude's documentation, users can only download files created by <a href=\"https://platform.claude.com/docs/en/build-with-claude/skills-guide\" rel=\"nofollow\" target=\"_blank\">skills</a> or the <a href=\"https://platform.claude.com/docs/en/agents-and-tools/tool-use/code-execution-tool\" rel=\"nofollow\" target=\"_blank\">code execution tool</a>.</p>\n<p>\"Since files generated by Claude's code execution tool are marked as downloadable, we explored whether the attacker could simply ask Claude to regenerate an existing file using the stolen API key,\" Check Point’s Donenfeld and Vanunu wrote. \"If successful, this would convert a non-downloadable file into a workspace artifact that is eligible for download.\"</p>\n<p>Cloning and then downloading the file worked, and thus confirmed that a miscreant using a stolen API key could <a href=\"https://youtu.be/jMeeVxqU3hY\" rel=\"nofollow\" target=\"_blank\">gain complete read and write access</a> to all workspace files: deleting or changing sensitive files or even uploading malicious files to poison the workspace or exceed the 100 GB storage space quota.</p>\n<p>Check Point reported the API key extraction bug to Anthropic on October 28, 2025, and the vendor immediately issued a fix. Later, on January 21, Anthropic published <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2026-21852\" rel=\"nofollow\" target=\"_blank\">CVE-2026-21852</a>.</p>\n<p>As the security team noted: \"The integration of AI into development workflows brings tremendous productivity benefits, but also introduces new attack surfaces that weren't present in traditional tools.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/clade_code_cves/?td=rt-3a",
            "pub_date": "2026-02-26 23:41:01",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Hide from Meta's spyglasses with this new Android app",
            "description": "<div id=\"body\">\n<p>Worried that someone wearing Meta's snooping spyware goggles could be creeping up on you? Android users now have access to an app that can warn them if someone is wearing such smart glasses in their vicinity by using Bluetooth.</p>\n<p>Last week, Yves Jeanrenaud, a deputy professor at Darmstadt University of Applied Sciences in Germany, published <a href=\"https://play.google.com/store/apps/details?id=ch.pocketpc.nearbyglasses\" rel=\"nofollow\">Nearby Glasses</a>, an Android app that scans Bluetooth Low Energy (BLE) advertising data for manufacturer identifiers associated with certain smart glasses, including Ray-Ban Meta AI Glasses.</p>\n<p>\"This app notifies you when smart glasses are nearby,\" Jeanrenaud explained in the project's <a href=\"https://github.com/yjeanrenaud/yj_nearbyglasses\" rel=\"nofollow\">GitHub repo</a>. \"It uses company [identifiers] in the Bluetooth data sent out by these [devices].\"</p>\n\n<p>In a LinkedIn <a href=\"https://www.linkedin.com/posts/activity-7431788166308798465-RaF2?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAAEUrwBGDapdyAWPL2MZIjljoJFUQRWVlo\" rel=\"nofollow\">post</a> on Tuesday, he elaborated on how the software works.</p>\n\n\n<p>\"Bluetooth devices broadcast small advertising packets,\" he wrote. \"Even though MAC addresses (identifying a particular device) and service UUIDs (identifying what they are doing) are randomized, manufacturer company IDs in BLE advertising frames are mandatory and immutable.\"</p>\n<p>The app, he said, scans for manufacturer identifiers in the BLE ADV frames.</p>\n\n<p>Jeanrenaud warned that there may be false positives from other Bluetooth hardware by the same manufacturer (e.g. Meta VR headsets).</p>\n<p>\"Hence, please proceed with caution when approaching a person nearby wearing glasses,\" he said. \"They might just be regular glasses, despite this app's warning.\"</p>\n<p>The repo comes with a prominent warning telling app users not to harass anyone based on suspicion of covert surveillance arising from the app's output.</p>\n\n<p>There have already been <a href=\"https://www.yahoo.com/news/articles/imagine-being-based-guy-says-143000399.html\" rel=\"nofollow\">reported</a> incidents of altercations arising from unwelcome surveillance, even without the app. </p>\n<p>In December, a woman on the New York subway is said to have smashed the Meta AI glasses worn by \"a TikToker.\" The incident went viral, which suggests the persistence of the widespread social discomfort with non-consensual recording that surfaced <a href=\"https://www.theregister.com/2013/03/09/seattle_bar_bans_google_glass/\">more than a decade ago</a> when Google released network-connected eyewear known as Google Glass. There's also the possibility that the incident was staged, because that's the world we live in.</p>\n<p>But there have been other troubling <a href=\"https://www.cnn.com/2026/02/09/world/manfluencers-smart-glasses-intl\" rel=\"nofollow\">reports</a> about so-called \"manfluencers\" using smart glasses to surreptitiously record their attempts to pick up women, encounters they then post to social media sites \"to create misogynistic content online.\"</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/25/bcachefs_creator_ai/\">Bcachefs creator insists his custom LLM is female and 'fully conscious'</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/24/amazon_blame_human_not_ai/\">Amazon would rather blame its own engineers than its AI</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/jobseeking_nextjs_devs_attack/\">Fake 'interview' repos lure Next.js devs into running secret-stealing malware</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/few_firms_investing_in_the/\">Execs love AI, just not enough to pay for user training</a></li>\n</ul>\n<p>Asked to comment, a Meta spokesperson said, \"Unlike smartphones, our glasses have an LED light that activates whenever someone captures content, so it's clear the device is recording. Our terms of service clearly state that users are responsible for complying with all applicable laws and for using Ray-Ban Meta glasses in a safe, respectful manner. And as with any recording device, people shouldn't use them for engaging in harmful activities like harassment, infringing on privacy rights, or capturing sensitive information.\"</p>\n<p>Jeanrenaud, in his post, observed that the LED on smart glasses can be easily disabled – there are YouTube videos that show how. And he added that many people do not recognize smart glasses as recording devices at all.</p>\n<p>It's generally legal to record video in public. But that doesn't preclude the possibility of legal risks (or unlawful device seizure by authorities), particularly when audio recording captures specific conversations or facial recognition technology is involved, or when recording plausibly constitutes unlawful behavior like harassment or stalking.</p>\n<p>\"Increasingly, smart glasses collect biometric data, and that's when they become problematic,\" Purdue Global Law School said in <a href=\"https://www.purduegloballawschool.edu/blog/news/smart-glasses-privacy-risks\" rel=\"nofollow\">a post</a> last week. \"Facial recognition, voiceprint recording, and other features can implicate a range of privacy laws.\"</p>\n<p>Purdue Global Law School also cites the possibility of running afoul of state wiretapping laws, noting that 11 states require consent from both parties for audio recording.</p>\n<p>Last week, a California judge criticized members of Mark Zuckerberg's team for <a href=\"https://www.cbsnews.com/news/meta-trial-mark-zuckerberg-ai-glasses/\" rel=\"nofollow\">wearing Ray-Ban Meta AI Glasses</a> in court, contrary to court rules. Zuckerberg was there to testify in a social media addiction trial based on allegations that Meta and YouTube designed their services to be addictive to young people.</p>\n<p>Pointing out <a href=\"https://www.404media.co/border-patrol-agent-recorded-raid-with-metas-ray-ban-smart-glasses/\" rel=\"nofollow\">other</a> <a href=\"https://www.404media.co/metas-ray-ban-glasses-users-film-and-harass-massage-parlor-workers/\" rel=\"nofollow\">abuses</a> associated with Meta's AI glasses, and Meta's <a href=\"https://www.nytimes.com/2026/02/13/technology/meta-facial-recognition-smart-glasses.html\" rel=\"nofollow\">reported plan to add facial recognition to its glasses</a>, Jeanrenaud said, \"This is not a perfect solution, but I hope it's useful for someone. Until consent and privacy are treated seriously in wearable tech, I hope this tool helps someone feel a little more safe.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/25/meta_smart_glasses_android_app/?td=rt-3a",
            "pub_date": "2026-02-27 08:51:33",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Five Eyes warn: Patch your Cisco SD-WAN or risk root takeover",
            "description": "<div id=\"body\">\n<p>The Five Eyes intelligence alliance is urgently warning defenders to patch two Cisco Catalyst SD-WAN vulnerabilities used in attacks.</p>\n<p>First discovered by the Australian Signals Directorate (ASD), all five of the alliance's intelligence agencies co-signed the alert on Wednesday evening, confirming that hackers of unspecified origin are trying to use the SD-WAN devices for persistent access.</p>\n<p>\"Malicious cyber threat actors are targeting Cisco Catalyst SD-WAN used by organizations globally,\" the UK's NCSC said. \"These actors are compromising SD-WANs to add a malicious rogue peer and then conduct a range of follow-on actions to achieve root access and maintain persistent access to the SD-WAN.\"</p>\n\n<p>The first of the two is <a href=\"https://www.cve.org/CVERecord?id=CVE-2022-20775\" rel=\"nofollow\" target=\"_blank\">CVE-2022-20775</a> (7.8), a path traversal vulnerability disclosed in September 2022 affecting the SD-WAN's command line interface, allowing for privilege escalation.</p>\n\n\n<p>The second is <a href=\"https://www.cve.org/CVERecord?id=CVE-2026-20127\" rel=\"nofollow\" target=\"_blank\">CVE-2026-20127</a> (10.0), a max-severity bug fresh off the press this week. Classed as an improper authentication flaw, the issue affects Cisco Catalyst SD-WAN Controller and Cisco Catalyst SD-WAN Manager, formerly known as SD-WAN vSmart and SD-WAN vManage respectively.</p>\n<p>The latter appears to be the biggie, not just because of the perfect 10 CVSS, but because successfully exploiting it grants hackers admin rights. Cisco said that cyberbaddies could also access NETCONF and reconfigure the SD-WAN fabric at their whim.</p>\n\n<p>According to a separate report from Cisco Talos, the vendor attributed the attacks that use CVE-2026-20127 to a group it tracks as UAT-8616 and said current signals suggest it has been exploited since at least 2023.</p>\n<p>Naturally, neither the intelligence agencies nor Cisco revealed precise details about the vulnerabilities that were reportedly exploited.</p>\n<p>However, Talos's <a href=\"https://blog.talosintelligence.com/uat-8616-sd-wan/\" rel=\"nofollow\" target=\"_blank\">report</a> suggested that CVE-2026-20127 was exploited first to gain admin rights, before downgrading the SD-WAN's software version using CVE-2022-20775 so that the attackers could gain root access.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/20/cisa_dell_vulnerability/\">CISA gives federal agencies three days to patch actively exploited Dell bug</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/13/gartner_ai_infrastructure/\">Misconfigured AI could trigger the next national infrastructure meltdown</a></li>\n<li><a href=\"https://www.theregister.com/2025/09/25/zeroday_deja_vu_another_cisco/\">Zero-day deja vu as another Cisco IOS bug comes under attack</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/24/patch_these_4_critical_makemeroot/\">Patch these 4 critical, make-me-root SolarWinds bugs ASAP</a></li>\n</ul>\n<p>Talos did not provide any details about who or what country might be behind UAT-8616, but described it as a \"<a href=\"https://www.theregister.com/2025/03/24/nation_state_supply_chain_attack/\" target=\"_blank\">highly sophisticated cyber threat actor</a>.\"</p>\n<p>An undisclosed number of attacks have already been carried out by exploiting the two vulnerabilities. Details about the victims remain sparse, although Talos suggested that targets were likely in high-value, sensitive sectors.</p>\n\n<p>It stated: \"UAT-8616's attempted exploitation indicates a continuing trend of the <a href=\"https://www.theregister.com/2025/12/04/prc_spies_brickstorm_cisa/\" target=\"_blank\">targeting of network edge devices</a> by cyber threat actors looking to establish persistent footholds into high-value organizations, including <a href=\"https://www.theregister.com/2026/01/19/dont_underestimate_prorussia_hacktivists_warns/\" target=\"_blank\">critical infrastructure</a> sectors.\"</p>\n<p>Defenders are strongly urged to follow the Five Eyes <a href=\"https://www.cyber.gov.au/sites/default/files/2026-02/ACSC-led%20Cisco%20SD-WAN%20Hunt%20Guide.pdf\" rel=\"nofollow\" target=\"_blank\">Hunt Guide</a> [PDF] to first find signs of compromise. If that search is positive, share the data with the relevant security authorities and upgrade to the latest version of Cisco Catalyst SD-WAN Controller/Manager.</p>\n<p>NCSC CTO Ollie Whitehouse said: \"Our new alert makes clear that organizations using Cisco Catalyst SD-WAN products should urgently investigate their exposure to network compromise and hunt for malicious activity, making use of the new threat hunting advice produced with our international partners to identify evidence of compromise.</p>\n<p>\"UK organizations are strongly advised to report compromises to the NCSC, and to apply vendor updates and hardening guidance as soon as practicable to reduce the risk of exploitation.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/five_eyes_cisco_sdwan/?td=rt-3a",
            "pub_date": "2026-02-27 08:51:33",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Moon's mighty magnetic field was a 5,000-year titanium blip",
            "description": "<div id=\"body\">\n<p>Scientists at the University of Oxford say they may have cracked the puzzle of the Moon's magnetic field and settled a debate that has raged since the Apollo missions returned with rock samples.</p>\n<p>NASA astronauts brought back evidence suggesting the lunar magnetic field was strong for long periods of its history, at times even stronger than Earth's.</p>\n<p>The findings created a puzzle, though. Scientists also considered the theory that the relatively small size of the Moon's core – around one-seventh of its radius – means it cannot create a strong field.</p>\n\n<p>New research from Oxford's Department of Earth Sciences shows they are both right... kind of.</p>\n\n\n<p>Led by associate professor Claire Nichols, the team analyzed the composition of a type of lunar rock known as the Mare basalts and found a new correlation between their titanium content and levels of magnetism.</p>\n<p>Looking at the collected lunar samples, they found those with a strong magnetic field also contained large amounts of titanium, but those with less than 6 percent titanium were all associated with a weak magnetic field.</p>\n\n<p>The study argues that the formation of high-titanium rocks and a strong lunar magnetic field were the result of titanium-rich material melting deep inside the Moon, which created a strong magnetic field, but only for about 5,000 years.</p>\n<p>\"Our new study suggests that the Apollo samples are biased to extremely rare events that lasted a few thousand years – but up to now, these have been interpreted as representing 0.5 billion years of lunar history. It now seems that a sampling bias prevented us from realizing how short and rare these strong magnetism events were,\" she said in a statement.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/19/nasa_starliner_blame/\">NASA points fingers at Boeing and chaotic culture for Starliner debacle</a></li>\n<li><a href=\"https://www.theregister.com/2026/01/13/moon_hotel_startup_reservation/\">Moon hotel startup hopes you get lunar lunacy, drop $1M deposit for 2032 stay</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/09/spacex_resumes_falcon_9/\">SpaceX back to Falcon 9 launches as Musk blathers about Moon city</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/06/smartphones_nasa/\">Smartphones cleared for launch as NASA loosens the rulebook</a></li>\n</ul>\n<p>\"We now believe that for the vast majority of the Moon's history, its magnetic field has been weak, which is consistent with our understanding of dynamo theory. But that for very short periods of time – possibly as short as a few decades – melting of titanium-rich rocks at the Moon's core-mantle boundary resulted in the generation of a very strong field.\"</p>\n<p>The research team said Mare basalts made a good landing site for the Apollo missions because they are relatively flat. Since the astronauts brought back nearby rocks, they carried more titanium-rich basalts than a representative sample of the Moon's surface would have. The result was a false impression of the length of time during which the Moon had a strong magnetic field.</p>\n<p>Co-author Dr Simon Stephenson added: \"We are now able to predict which types of samples will preserve which magnetic field strengths on the Moon. The upcoming Artemis missions offer us an opportunity to test this hypothesis and delve further into the history of the lunar magnetic field.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/moon_magnetic_field/?td=rt-3a",
            "pub_date": "2026-02-27 08:25:55",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Microsoft to auto-launch Copilot in Edge whenever you click a link from Outlook",
            "description": "<div id=\"body\">\n<p>Microsoft has announced that its Edge browser will automatically open the Copilot side pane when users open links from Outlook.</p>\n<p>The feature appeared on the <a href=\"https://www.microsoft.com/en-gb/microsoft-365/roadmap?id=557561\" rel=\"nofollow\" target=\"_blank\">Microsoft 365 roadmap</a> on February 25, with a rollout due to start in May 2026. According to Microsoft, the update will \"provide contextual insights and actionable suggestion chips [<em>sic</em>] based on email and destination content.\"</p>\n\n<p>It added: \"This experience helps users quickly understand content, take action with fewer steps, and get more value from Copilot while extending productive browsing time in Edge.\"</p>\n<p>The update is consistent with Microsoft's current Copilot-everywhere strategy and will roll out worldwide to standard multi-tenant cloud instances.</p>\n<p>Whether it will be opt-in or opt-out remains unconfirmed, though users hoping for a conveniently placed off switch may be disappointed. Microsoft is keen to put its AI assistant in front of as many users as possible.</p>\n\n<p><i>The Register</i> asked Microsoft how much control administrators would have over the feature and what would happen if Edge wasn't the default browser. The company has yet to respond.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/24/west_midlands_police_copilot/\">West Midlands Police earn red card over Copilot's imaginary football match</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/19/ai_climate_crisis_claims/\">Don't believe the hyperscalers! AI can't cure the climate crisis</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/18/microsoft_copilot_data_loss_prevention/\">Copilot spills the beans, summarizing emails it's not supposed to read</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/15/if_microsoft_made_a_car/\">If Microsoft made a car... what would it be?</a></li>\n</ul>\n<p>Finding a corner of Microsoft's software that Copilot hasn't reached is increasingly difficult – even Notepad has not escaped – and disabling it across the company's productivity suite has become a game of Whac-A-Mole for enterprise administrators who have yet to embrace the technology.</p>\n<p>The automatic pane could hand those administrators yet another mallet to swing, particularly given that Copilot surfacing suggestions based on email content could run afoul of data security policies. That said, enterprises already nervous about where their data ends up likely have Copilot policies well in hand.</p>\n\n<p>Jon von Tetzchner, CEO of the Vivaldi browser project, which is already surfing the wave of anti-AI sentiment, isn't too impressed with Microsoft's latest efforts pertaining to Copilot and Edge.</p>\n<p>\"This is another example of trying to push Edge in every way possible and also forcing Copilot on users that may not want it,\" he told <em>The Register</em>.</p>\n\n<p>\"Considering how sensitive corporate emails can be, the last thing you want is them being snooped on by an LLM hosted who knows where. This would be highly problematic from a corporate security and privacy point of view, and even more of a problem for private users who might be using one of MS's email services. Just imagine if someone sends an email exploiting that for phishing purposes,\" he added.</p>\n<p>\"Should this be an opt-in rather than an opt-out? Absolutely. The better question is whether it should be a thing at all.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/copilot_pane_edge_outlook/?td=rt-3a",
            "pub_date": "2026-02-27 06:41:02",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "LLMs killed the privacy star, we can't rewind, we've gone too far",
            "description": "<div id=\"body\">\n<p>Add privacy to the list of potential casualties caused by the proliferation of AI, because researchers have found that large language models (LLMs) can be used to deanonymize internet users – even those who use pseudonyms – more efficiently than human sleuths.</p>\n<p>Much of the academic work on online privacy over the past 25 years builds upon <a href=\"https://latanyasweeney.org\" rel=\"nofollow\">Latanya Sweeney</a>'s 2002 research on <a href=\"https://epic.org/wp-content/uploads/privacy/reidentification/Sweeney_Article.pdf\" rel=\"nofollow\">k-Anonymity</a> [PDF], and <a href=\"https://kilthub.cmu.edu/articles/journal_contribution/Simple_Demographics_Often_Identify_People_Uniquely/6625769?file=12123218\" rel=\"nofollow\">prior research</a> in which she demonstrated it is possible to identify 87 percent of the US population using three anonymous data points – a five-digit ZIP code, gender, and date of birth.</p>\n<p>The possibility of identifying people from anonymous data became one of the central concerns about online advertising and the usage of cookies in web browsers.</p>\n\n<p>It's a risk that hasn't gone away and now appears to be even more grave, thanks to LLMs that can automate the process of connecting the dots across online posts so they point to a likely source.</p>\n\n\n<p>\"We show that LLM agents can figure out who you are from your anonymous online posts,\" said Simon Lermen, an AI engineer at MATS Research and one of the corresponding authors of a pre-press <a href=\"https://arxiv.org/abs/2602.16800\" rel=\"nofollow\" target=\"_blank\">paper</a> titled \"Large-scale online deanonymization with LLMs.\"</p>\n<p>\"Across Hacker News, Reddit, LinkedIn, and anonymized interview transcripts, our method identifies users with high precision – and scales to tens of thousands of candidates,” Lermen explained in an <a href=\"https://simonlermen.substack.com/p/large-scale-online-deanonymization\" rel=\"nofollow\">online post</a>.</p>\n\n<p>The researcher observes that while it has long been known that individuals can be identified using only a few data points, doing so was often impractical. Such data often existed in an unstructured form and it took considerable effort for human investigators to assemble enough pieces to solve the identity puzzle.</p>\n<p>LLMs accelerate and automate that process, and they do so affordably, Lermen and his co-authors claim.</p>\n<p>\"We demonstrate that large language models (LLMs) fundamentally change this calculus, enabling fully automated deanonymization attacks that operate on unstructured text at scale,\" they state in their paper. \"Where previous approaches required predefined feature schemas, careful data alignment, and manual verification, LLMs can extract identity-relevant signals from arbitrary prose, efficiently search over millions of candidate profiles, and reason about whether two accounts belong to the same person.\"</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/25/bcachefs_creator_ai/\">Bcachefs creator insists his custom LLM is female and 'fully conscious'</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/ai_models_nuclear/\">AIs are happy to launch nukes in simulated combat scenarios</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/google_and_friends_disrupt_unc2814/\">Google catches Beijing spies using Sheets to spread espionage across 4 continents</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/25/meta_smart_glasses_android_app/\">Hide from Meta's spyglasses with this new Android app</a></li>\n</ul>\n<p>In one experiment, the authors collected 338 Hacker News users whose bios link to a LinkedIn profile. They did so to establish ground-truth identities for the study subjects so the LLMs’ predictions could be checked – this was also to avoid the ethical problems of actually deanonymizing people in a research study.</p>\n<p>Next, they created a structured data profile of these users based on their comments and the stories they posted. Then they created a search prompt, anonymized it, and passed it to the AI agent. The agent went on to correctly identify 226 of the 338 targets, a success rate of 67 percent at 90 percent precision (there were 25 errant identifications and 86 abstentions where the model didn't offer a prediction).</p>\n\n<p>The technique employed by the authors is not a universal privacy solvent – it's only successful some of the time. But it's successful often enough that those posting online under a pseudonymous account should not assume their identities will remain unknown.</p>\n<p>It’s also cheap to run. The researchers report their entire experiment cost about $2,000, with the cost per profile estimated to be between $1 and $4.</p>\n<p>Who would bother? The authors suggest that governments could use this technique to target journalists or activists, that corporations could mine forums to build highly targeted advertising profiles, and that online attackers could develop detailed personal profiles to make social engineering scams more credible.</p>\n<p>Lermen argues that netizens therefore need to consider how each data point they share helps identify them.</p>\n<p>\"The combination is often a unique fingerprint,\" he said. \"Ask yourself: could a team of smart investigators figure out who you are from your posts? If yes, LLM agents can likely do the same, and the cost of doing so is only going down.\"</p>\n<p>Lermen’s co-authors are Daniel Paleka (ETH Zurich), Joshua Swanson (ETH Zurich), Michael Aerni (ETH Zurich), Nicholas Carlini (Anthropic), and Florian Tramèr (ETH Zurich). ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/llms_killed_privacy_star/?td=rt-3a",
            "pub_date": "2026-02-26 23:41:01",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Jack Dorsey’s fintech outfit Block announces 40% layoffs, blames AI, gets 23% stock bump",
            "description": "<div id=\"body\">\n<p>Twitter co-founder Jack Dorsey’s financial services company Block has announced it will fire 40 percent of staff – around 4,000 people – because new \"intelligence tools\" the company is implementing “can do more and do it better.”</p>\n<p>The company announced the sackings in the <a href=\"https://s29.q4cdn.com/628966176/files/doc_financials/2025/q4/Q4-2025-Shareholder-Letter_Block.pdf\" rel=\"nofollow\" target=\"_blank\">shareholder letter</a> [PDF] accompanying its Q4 <a href=\"https://investors.block.xyz/financials/quarterly-earnings-reports/default.aspx\" rel=\"nofollow\" target=\"_blank\">earnings announcement</a> on Thursday. The payments and crypto company reported quarterly revenue of about $6.25 billion – up 3.6 percent year-over-year – and gross profit of around $2.9 billion. The company made $1 billion of gross profit in December 2025 alone. Full-year revenue came in at about $24.2 billion, and gross profit was around $10.36 billion.</p>\n<blockquote class=\"pullquote\">\n<p>I believe the majority of companies will reach the same conclusion and make similar changes</p>\n</blockquote>\n<p>“2025 was a strong year for us,” Dorsey wrote in the shareholder letter, before posing the question, “Why are we changing how we operate going forward?”</p>\n<p>His answer, spread across the letter and a <a href=\"https://x.com/jack/status/2027129697092731343?s=20\" rel=\"nofollow\" target=\"_blank\">Xeet</a>, is that AI has already changed the way Block works, so it needs to change its structure.</p>\n<p>“We're already seeing that the intelligence tools we’re creating and using, paired with smaller and flatter teams, are enabling a new way of working which fundamentally changes what it means to build and run a company. and that's accelerating rapidly,” he wrote on X.</p>\n\n<p>In the shareholder letter, he wrote, “Intelligence tools have changed what it means to build and run a company. We're already seeing it internally. A significantly smaller team, using the tools we're building, can do more and do it better. And intelligence tool capabilities are compounding faster every week.”</p>\n\n\n<p>On X, Dorsey said he could have cut jobs “gradually over months or years as this shift plays out, or be honest about where we are and act on it now.”</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2025/07/08/jack_dorsey_debuts_bitchat/\">Jack Dorsey floats specs for decentralized messaging app that uses Bluetooth</a></li>\n<li><a href=\"https://www.theregister.com/2024/05/02/prosecutors_probe_block_square_cashapp/\">Block accused of mass compliance failures that saw digi-dollars reach terrorists</a></li>\n<li><a href=\"https://www.theregister.com/2022/08/24/block_headed_to_court_to/\">Block sued after ex-staffer siphons customer data</a></li>\n<li><a href=\"https://www.theregister.com/2021/11/29/jack_dorsey_resigns/\">Twitter CEO Jack Dorsey rebrands himself a 'single point of failure' and quits</a></li>\n</ul>\n<p>He decided to let 4,000 people go all at once because “repeated rounds of cuts are destructive to morale, to focus, and to the trust that customers and shareholders place in our ability to lead.”</p>\n<p>“I’d rather take a hard, clear action now and build from a position we believe in than manage a slow reduction of people toward the same outcome,” he wrote, adding his view that “A smaller company also gives us the space to grow our business the right way, on our own terms, instead of constantly reacting to market pressures.”</p>\n<p>Whether Dorsey is blaming AI or not, Block has not served its shareholders well under his leadership over the last five years, with its stock down around 80% from its 2021 peak. But investors liked what they heard on Thursday, as Block’s share price jumped about 23 percent in after-hours trading.</p>\n\n<p>“To those staying … I made this decision, and I'll own it,” Dorsey wrote on X. “What I'm asking of you is to build with me. We're going to build this company with intelligence at the core of everything we do.”</p>\n<p>He added that Block’s actions and new direction will help its customers to navigate change by creating “a future where they can build their own features directly, composed of our capabilities and served through our interfaces.”</p>\n<p>“That's what I'm focused on now,” he wrote. “Expect a note from me tomorrow.”</p>\n\n<p>Before then, Dorsey will host “a live video session to thank everyone,” including the approximately 4,000 people losing their livelihoods in a <a href=\"https://www.politico.com/news/2026/02/20/trumps-economy-decelerated-as-shutdown-consumer-spending-drag-on-growth-00790640\" rel=\"nofollow\" target=\"_blank\">sluggish economy</a>.</p>\n<p>“I know doing it this way might feel awkward,” he wrote. “I'd rather it feel awkward and human than efficient and cold.”</p>\n<p>Because firing 4,000 people so machines can take their jobs would never come across as cold.</p>\n<p>Dorsey thinks Block won’t be the last company to change its operations to meet the AI moment.</p>\n<p>“I don't think we're early to this realization,” he wrote. “I think most companies are late.”</p>\n<p>“Within the next year, I believe the majority of companies will reach the same conclusion and make similar structural changes. I'd rather get there honestly and on our own terms than be forced into it reactively.” ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/27/block_q4_2025_ai_layoffs/",
            "pub_date": "2026-02-27 08:41:10",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "Burger King turns to AI to flame broil employees who aren't friendly enough",
            "description": "<div id=\"body\">\n<p>The bot’s nagging will continue until morale improves. Burger King is rolling out a new employee-facing AI that, among other things, will listen to employees’ customer interactions to ensure they’re being friendly enough - as if working in fast food weren’t hard enough already.</p>\n<p>Burger King announced a wider rollout of the BK Assistant, along with its employee AI assistant-cum-narc \"Patty,\" on Thursday during an investor event <a href=\"https://www.prnewswire.com/news-releases/restaurant-brands-international-is-hosting-an-investor-event-on-february-26-2026-302694931.html\" rel=\"nofollow\">hosted</a> by parent company Restaurant Brands International. According to RBI, BK Assistant has been deployed for testing in approximately 500 stores around the US, and the company wants to have it available in all 7,000 US Burger Kings by the end of 2026. </p>\n<p>A promo video played during the investor event livestream showed Patty talking to an incoming shift manager, sharing current \"friendliness scores,\" the status of low-stock items, and other data points a team leader might need to know. </p>\n\n<p>Burger King employees were shown being reminded of recipes, getting cleaning instructions, and, a bit more obtrusively, being told they met upselling goals when convincing a customer to add an item they didn't originally ask for to their order. </p>\n\n\n<p>According to a Burger King representative, the BK Assistant unifies point of sale, kitchen equipment, inventory, and digital ordering systems into a single umbrella product built with proprietary Burger King architecture on top of a base model from OpenAI. </p>\n<p>Despite the fact that the video showed a manager being told how friendly her team was being with customers, Burger King insisted that Patty isn't going to spy on employees and report them when they're having a bad shift. </p>\n\n<p>\"It is not designed to track nor evaluate employees saying specific words or phrases,\" a Burger King spokesperson told <em>The Register</em> in an email. \"BK Assistant is a coaching and operational support tool built to help our restaurant teams manage complexity and stay focused on delivering a great Guest experience.\"</p>\n<p>The fast food chain has explored using aggregated keywords, like \"welcome,\" \"please,\" and \"thank you\" as signals to help managers understand broader service patterns at their restaurants, but \"it's not about scoring individuals or enforcing scripts,\" the spokesperson said. </p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2021/09/20/bork/\">A Burger King where the only Whopper is the BSOD font</a></li>\n<li><a href=\"https://www.theregister.com/2025/11/23/bossware_monitor_remote_employees/\">Bossware booms as bots determine whether you're doing a good job</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/02/mcdonalds_password_advice/\">McDonald's is not lovin' your bigmac, happymeal, and mcnuggets passwords</a></li>\n<li><a href=\"https://www.theregister.com/2024/03/14/advanced_workplace_tech_study/\">AI and wearables are scaring the wellbeing out of workers</a></li>\n</ul>\n<p>\"We believe hospitality is fundamentally human,\" the company rep told us. \"The role of this technology is to support our teams so they can stay present with guests.\"</p>\n<p>Fast food AI has been a bit of a mixed bag for companies that have tried it, though to be fair most of the failures have been on the customer service end. </p>\n<p>McDonald's <a href=\"https://www.theregister.com/2024/06/17/mcdonalds_ai_drivethru/\">gave up on drive-through AI</a>, and Taco Bell has also <a href=\"https://www.bbc.com/news/articles/ckgyk2p55g8o\" rel=\"nofollow\">rethought</a> its <a href=\"https://www.theregister.com/2024/08/01/ai_taco_bell/\">trial run</a> after mishaps. Starbucks has also dialed back its automation-first push after conceding machines <a href=\"https://www.theregister.com/2025/04/30/starbucks_finds_machines_cant_replace/\" target=\"_blank\">weren't replacing baristas</a> as hoped. Instead, it's shifting toward <a href=\"https://www.theregister.com/2025/06/11/starbucks_ai_baristas/\" target=\"_blank\">AI tools that assist staff</a> — echoing Burger King's employee-assist strategy.</p>\n\n<p>There's no guarantee Burger King's initiative will stick, naturally, but be prepared for employees to start seeming extra friendly in case Patty is listening in. ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/26/burger_kings_new_ai/",
            "pub_date": "2026-02-27 08:51:33",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        },
        {
            "title": "New endowment hopes to raise a big pile of money for open source projects",
            "description": "<div id=\"body\">\n<p>Open source projects, ever short of funding, have a potential new source of revenue in the form of the Open Source Endowment (OSE).</p>\n<p>The organization <a href=\"https://endowment.dev/faq/\" rel=\"nofollow\">describes itself</a> as \"the world's first endowment fund for open source software.”</p>\n<p>There are certainly other organizations that help fund open source software, such as <a href=\"https://opencollective.com/\" rel=\"nofollow\">Open Collective</a>, <a href=\"https://oscollective.org/\" rel=\"nofollow\">Open Source Collective</a>, and the Rust Foundation's <a href=\"https://www.theregister.com/2025/11/05/rust_foundation_announces_maintainers_fund/\">Maintainers Fund</a>, not to mention organizations like the <a href=\"https://sfconservancy.org\" rel=\"nofollow\">Software Freedom Conservancy</a>, which provides legal and infrastructure support to open source projects. Open source developers may also be fortunate enough to receive contributions from individuals, companies (<a href=\"https://www.theregister.com/2025/07/24/microsoftowned_github_says_open_source/\">when not passing the buck</a>), and government-sponsored initiatives like Germany's <a href=\"https://www.sovereign.tech\" rel=\"nofollow\">Sovereign Tech Fund</a>.</p>\n\n<p>But OSE aspires specifically to build a big pile of cash – an endowment – that it will dole out to deserving open source projects.</p>\n\n\n<p>It's certainly needed. In 2023, Denis Pushkarev, maintainer of the widely used <code>core-js</code> library, <a href=\"https://www.theregister.com/2023/02/15/corejs_russia_open_source/\">vented his frustration</a> with the fact that users of his software seldom offer financial support. \"Free open source software is fundamentally broken,\" he said.</p>\n<p>The year before that, Christofer Dutz – creator of Apache PLC4X – <a href=\"https://www.theregister.com/2022/01/13/opensource_apacheplc4x_payment/\">lamented</a> uncompensated use of his software. Earlier in 2022, Google <a href=\"https://blog.google/innovation-and-ai/technology/safety-security/making-open-source-software-safer-and-more-secure/\" rel=\"nofollow\">talked up</a> the need to support critical open source infrastructure, citing the log4j vulnerability.</p>\n\n<p>But concerns about the sustainability of open source go back further still. Two years after the 2014 Heartbleed vulnerability – a dangerous flaw in OpenSSL – a Ford Foundation report <a href=\"https://www.theregister.com/2021/05/10/untangling_open_sources_sustainability_problem/\">noted</a> that the OpenSSL project is critical internet infrastructure yet had just one full-time maintainer and earned less than $2,000 per year in donations.</p>\n<p>As OSE points out, 95 percent of codebases rely on open source software, each of which has an average of 500 open source components. And yet <a href=\"https://opensourcefundingsurvey2024.com/\" rel=\"nofollow\">86 percent of open source contributors</a> receive no payment for their work.</p>\n<ul class=\"listinks\">\n<li><a href=\"https://www.theregister.com/2026/02/26/memory_price_hikes/\">Say goodbye to budget PCs and smartphones – memory is too expensive now</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/ai_models_get_better_at/\">AI models still suck at math</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/anthropic_claude_opus_3_blog/\">Anthropic launches new marketing blog, pretends it's being 'written' by 'retired' LLM</a></li>\n<li><a href=\"https://www.theregister.com/2026/02/26/veracode_security_ai/\">Rapid AI-driven development makes security unattainable, warns Veracode</a></li>\n</ul>\n<p>OSE founding chairman Konstantin Vinogradov, a venture capital investor, previously <a href=\"https://kvinogradov.com/oss-universities/\" rel=\"nofollow\">said</a> he wanted to replicate the funding model that has sustained universities.</p>\n<p>And he reiterated that aspiration in a Hacker News <a href=\"https://news.ycombinator.com/item?id=47168013\" rel=\"nofollow\">post</a> announcing OSE.</p>\n<p>Universities and the open source community, he argues, share reputation-based culture and functions, working together to create valuable ideas for the benefit of the public, educating each other, and commercializing only a portion of what's produced.</p>\n\n<p>\"For universities, humanity has just two sustainable funding models: public spending or private endowments,\" Vinogradov explained. \"Government support won't work for OSS at scale – it's too globally decentralized. And yet nobody had built an OSS-focused endowment before. After understanding why, I started building one together with other OSS folks.\"</p>\n<p>Vinogradov said the OSE, a US 501(c)(3) tax-exempt charity, aims to make open source development more sustainable through a community-driven endowment. Donations will be invested and only investment income will be disbursed through grants – the principal funds will remain invested in the hope of growth.</p>\n<p>Presently, the fund stands at around $700,000, thanks to contributions from more than 60 founding donors, including the founders of ClickHouse, curl, Elastic, Gatsby, HashiCorp, n8n, Nginx, Pydantic, Supabase, and Vue.js.</p>\n<p><a href=\"https://www.every.org/osendowment?donateTo=osendowment&amp;redirect_url=%2Fosendowment%3Fpost%3Dsignup%20-%20/donate/card\">Donations</a> go directly to the fund, and those who give over $1,000 can become <a href=\"https://endowment.dev/docs/membership-policy/\" rel=\"nofollow\">OSE Members</a>, which includes certain rights to participate in OSE governance.</p>\n<p>The group has detailed its grant selection process <a href=\"https://endowment.dev/faq/#grants\" rel=\"nofollow\">on the OSE website</a> and in its <a href=\"https://github.com/osendowment/model\" rel=\"nofollow\">GitHub repository</a>.</p>\n<p><a href=\"https://news.ycombinator.com/item?id=47171720\" rel=\"nofollow\">According to Vinogradov</a>, \"OSE won't give money for commercial product development – it is dedicated to supporting existing highly-used <em>nonprofit</em> and independent OSS.\" ®</p> \n</div>",
            "link": "https://www.theregister.com/2026/02/27/open_source_endowment/",
            "pub_date": "2026-02-27 08:31:41",
            "source": "theregister",
            "kind": 1,
            "language": "en"
        }
    ]
}